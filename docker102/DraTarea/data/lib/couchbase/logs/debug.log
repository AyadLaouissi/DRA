[ns_server:info,2019-03-19T15:50:27.210Z,nonode@nohost:<0.89.0>:ns_server:init_logging:150]Started & configured logging
[ns_server:info,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_access,info},
 {disk_sink_opts,[{rotation,[{compress,true},
                             {size,41943040},
                             {num_files,10},
                             {buffer_size_max,52428800}]}]},
 {disk_sink_opts_json_rpc,[{rotation,[{compress,true},
                                      {size,41943040},
                                      {num_files,2},
                                      {buffer_size_max,52428800}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.229Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_json_rpc, which is given from command line
[ns_server:warn,2019-03-19T15:50:27.230Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2019-03-19T15:50:27.251Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.138.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:27.258Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,9,125}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-6d69bef] [64-bit] [smp:2:2] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2019,3,19},{15,50,27}}},
               {memory,
                   [{total,110178664},
                    {processes,9329616},
                    {processes_used,9328528},
                    {system,100849048},
                    {atom,339441},
                    {atom_used,322567},
                    {binary,54560},
                    {code,7796127},
                    {ets,2241552}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,path_config,calendar,
                    ale_default_formatter,'ale_logger-metakv',
                    'ale_logger-rebalance','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-json_rpc',
                    'ale_logger-access',io_lib_fread,'ale_logger-ns_server',
                    'ale_logger-user','ale_logger-ns_doctor',
                    'ale_logger-cluster','ale_logger-xdcr',otp_internal,
                    ns_log_sink,ale_disk_sink,misc,couch_util,ns_server,
                    cpu_sup,filelib,memsup,disksup,os_mon,io,release_handler,
                    overload,alarm_handler,sasl,timer,tftp_sup,httpd_sup,
                    httpc_handler_sup,httpc_cookie,inets_trace,httpc_manager,
                    httpc,httpc_profile_sup,httpc_sup,ftp_sup,inets_sup,
                    inets_app,ssl,lhttpc_manager,lhttpc_sup,lhttpc,
                    tls_connection_sup,ssl_session_cache,ssl_pkix_db,
                    ssl_manager,ssl_sup,ssl_app,crypto_server,crypto_sup,
                    crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_io,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","6.0.1-2037-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","6.0.1-2037-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,105},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [lhttpc_sup,code_server,ale_stats_events,
                    ns_server_cluster_sup,lhttpc_manager,
                    application_controller,ale,'sink-ns_log',httpd_sup,
                    release_handler,kernel_safe_sup,standard_error,ale_sup,
                    overload,error_logger,'sink-disk_json_rpc',alarm_handler,
                    ale_dynamic_sup,'sink-disk_metakv',timer_server,
                    standard_error_sup,'sink-disk_access_int',
                    'sink-disk_access',crypto_server,'sink-disk_reports',
                    crypto_sup,sasl_safe_sup,'sink-disk_stats',tftp_sup,
                    'sink-disk_xdcr',inet_db,init,os_mon_sup,rex,
                    'sink-disk_debug',tls_connection_sup,user,ssl_sup,
                    kernel_sup,cpu_sup,'sink-disk_error',global_name_server,
                    memsup,disksup,'sink-disk_default',httpc_sup,
                    file_server_2,ssl_manager,local_tasks,global_group,
                    httpc_profile_sup,httpc_manager,httpc_handler_sup,ftp_sup,
                    sasl_sup,erl_prim_loader,inets_sup]},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,2}]
[ns_server:info,2019-03-19T15:50:27.266Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:27]Manifest:
["<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\" />",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\" />",
 "  ","  <default remote=\"couchbase\" revision=\"master\" />","  ",
 "  <project groups=\"kv\" name=\"HdrHistogram_c\" path=\"third_party/HdrHistogram_c\" remote=\"couchbasedeps\" revision=\"d200fc0f68695d4aef1fad5c3c8cc55f8c033014\" upstream=\"refs/tags/0.9.7\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"analytics-dcp-client\" path=\"analytics/java-dcp-client\" revision=\"a5567811193b0cc3571fe94e42fc1b8a6a80bc5b\" upstream=\"alice\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"asterixdb\" path=\"analytics/asterixdb\" revision=\"5363b3338ac5886a3260d7eb2a9be250088ca07e\" upstream=\"alice\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"8b892819df78d1c34166a52eb076668e17ea3127\" upstream=\"alice\" />",
 "  <project groups=\"kv\" name=\"benchmark\" remote=\"couchbasedeps\" revision=\"9e3465560240ffb242b50a47cb7f19251a12ee42\" />",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\" />",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5cd1345cca3ed72f1e63d41d622fcda73e63fea8\" />",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"5d4917326972a5fe6f1e094ec439f66f69c92c3f\" />",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"f551b6d4f32bb920a83dd28c705bddd5de0d03b2\" />",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"4b158bb555a3297565afecf6fae675c74f1e47df\" />",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\" />",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\" />",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"39057a59b788c50aa32a5102a718ef910e893a59\" upstream=\"alice\">",
 "    <annotation name=\"RELEASE\" value=\"alice\" />",
 "    <annotation name=\"PRODUCT\" value=\"couchbase-server\" />",
 "    <annotation name=\"BLD_NUM\" value=\"2037\" />",
 "    <annotation name=\"VERSION\" value=\"6.0.1\" />","  </project>",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas\" path=\"goproj/src/github.com/couchbaselabs/cbas\" remote=\"couchbase-priv\" revision=\"cd8ad4f69909d3b804b1e2602045a1637e0316d7\" upstream=\"alice\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas-core\" path=\"analytics\" remote=\"couchbase-priv\" revision=\"f6eed2e053c11ee5fd0cd83122001dc2a56450df\" upstream=\"alice\" />",
 "  <project groups=\"analytics\" name=\"cbas-ui\" revision=\"a1c61e411517bbc2517401f636523dcc76d1e18d\" upstream=\"alice\" />",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"0df84c7e3c6d95ff435c12a3c08c6f064db11e97\" />",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"80d2ad8892d806f5103f602fec0d80adaa4b628f\" />",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"a33ad7b7000a9d8d237ba273c47cc100401a0fb0\" />",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"0a94f40b9080e0ecb11d3b7531a58c5e6a4a4465\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"19fecfe58921c162a31c156781bd2a512711f14d\" />",
 "  <project name=\"cbsummary\" path=\"goproj/src/github.com/couchbase/cbsummary\" revision=\"dbfa1c0d73f0e49f6f04e390f03de8f9a6cee769\" />",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"dcae66272b24600ae0005fa06b511cfae8914d3d\" />",
 "  <project name=\"cobra\" path=\"godeps/src/github.com/spf13/cobra\" remote=\"couchbasedeps\" revision=\"0f056af21f5f368e5b0646079d0094a2c64150f7\" />",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\" />",
 "  <project groups=\"notdefault,kv_ee,enterprise\" name=\"couch_rocks\" remote=\"couchbase-priv\" revision=\"75f37fa46bfe5e445dee077157303968a3e09126\" />",
 "  <project name=\"couchbase-cli\" revision=\"0db2826a55fa2fd6625a46422425427b8863403a\" upstream=\"alice\" />",
 "  <project name=\"couchdb\" revision=\"3c4ad2b96fd21587c9effdd4b663bb30a75ae455\" upstream=\"alice\" />",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"2ce6ce3597dd9437210446a861a3a881ca4bb248\" />",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"884e9b80cd388d56353e1282f26d79dd6a592f23\" upstream=\"vulcan\" />",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\" />",
 "  <project name=\"cuckoofilter\" path=\"godeps/src/github.com/seiflotfy/cuckoofilter\" remote=\"couchbasedeps\" revision=\"d04838794ab86926d32b124345777e55e6f43974\" />",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\" />",
 "  <project name=\"docloader\" path=\"goproj/src/github.com/couchbase/docloader\" revision=\"05067021a042a1b63e100a486afd7ebddab4c535\" />",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\" />",
 "  <project name=\"errors\" path=\"godeps/src/github.com/pkg/errors\" remote=\"couchbasedeps\" revision=\"30136e27e2ac8d167177e8a583aa4c3fea5be833\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"eventing\" path=\"goproj/src/github.com/couchbase/eventing\" revision=\"f6a7443859b5213ff4dfcdef7bb0bcd37363b9eb\" upstream=\"alice\" />",
 "  <project name=\"flatbuffers\" path=\"godeps/src/github.com/google/flatbuffers\" remote=\"couchbasedeps\" revision=\"1a8968225130caeddd16e227678e6f8af1926303\" />",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"562366039e50730282548b02c1a30d73f97cba27\" upstream=\"vulcan\" />",
 "  <project name=\"fwd\" path=\"godeps/src/github.com/philhofer/fwd\" remote=\"couchbasedeps\" revision=\"bb6d471dc95d4fe11e432687f8b70ff496cf3136\" />",
 "  <project name=\"geocouch\" revision=\"2a0e73f43451045f157640eec59ced72da18471f\" />",
 "  <project name=\"ghistogram\" path=\"godeps/src/github.com/couchbase/ghistogram\" revision=\"d910dd063dd68fb4d2a1ba344440f834ebb4ef62\" />",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\" />",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"9c0fc1f8003c1fb6b9bd6aec686eb6774d7e06ce\" upstream=\"alice\" />",
 "  <project name=\"go-curl\" path=\"godeps/src/github.com/andelf/go-curl\" remote=\"couchbasedeps\" revision=\"3b0453ce6faae42ab4d8cdb9ac1f93919c9d8d69\" upstream=\"20161221-couchbase\" />",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\" />",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\" />",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\" />",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\" />",
 "  <project name=\"go-sqlite3\" path=\"godeps/src/github.com/mattn/go-sqlite3\" remote=\"couchbasedeps\" revision=\"47fc4e5e9153645da45af6a86a5bce95e63a0f9e\" />",
 "  <project name=\"go-unsnap-stream\" path=\"godeps/src/github.com/glycerine/go-unsnap-stream\" remote=\"couchbasedeps\" revision=\"62a9a9eb44fd8932157b1a8ace2149eff5971af6\" />",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\" />",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"d2f15a425a9c8e4d8447e5f5b89ce14845f7fa05\" upstream=\"vulcan\" />",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\" />",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"699b13a51af5dd4f80ff3deedf41bba60debad32\" upstream=\"refs/tags/v1.3.7\" />",
 "  <project name=\"gocbconnstr\" path=\"godeps/src/gopkg.in/couchbaselabs/gocbconnstr.v1\" remote=\"couchbaselabs\" revision=\"710456e087a6d497e87f41d0a9d98d6a75672186\" />",
 "  <project name=\"gocbcore\" path=\"godeps/src/gopkg.in/couchbase/gocbcore.v7\" revision=\"a0d26c2d6f5de912499d35a5aba573006e5e036f\" upstream=\"refs/tags/v7.1.7\" />",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"aecdbe5a5a91f0688df7bdf260ca962178c06828\" upstream=\"vulcan\" />",
 "  <project name=\"gofarmhash\" path=\"godeps/src/github.com/leemcloughlin/gofarmhash\" remote=\"couchbasedeps\" revision=\"0a055c5b87a8c55ce83459cbf2776b563822a942\" />",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\" />",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\" />",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\" />",
 "  <project name=\"golang-tools\" path=\"godeps/src/golang.org/x/tools\" remote=\"couchbasedeps\" revision=\"a28dfb48e06b2296b66678872c2cb638f0304f20\" />",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\" />",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"e05ec3550789be1da2981787ef6444fef75e10bc\" upstream=\"vulcan\" />",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"c995daf62dbcd6da60d6a868bfeb0faf69ddadf5\" upstream=\"alice\" />",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\" />",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\" />",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\" />",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"f98adca8eb365032cab838ef4d99453931afa112\" upstream=\"vulcan\" />",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"bdc8bc82b7847138a59f27fd5cc6ce2d1d8f01c4\" upstream=\"alice\" />",
 "  <project groups=\"kv\" name=\"gsl-lite\" path=\"third_party/gsl-lite\" remote=\"couchbasedeps\" revision=\"57542c7e7ced375346e9ac55dad85b942cfad556\" upstream=\"refs/tags/v0.25.0\" />",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\" />",
 "  <project name=\"httprouter\" path=\"godeps/src/github.com/julienschmidt/httprouter\" remote=\"couchbasedeps\" revision=\"975b5c4c7c21c0e3d2764200bf2aa8e34657ae6e\" />",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"8443db9caeab1a2ab54ffb69130453e546cbd597\" upstream=\"alice\" />",
 "  <project name=\"json-iterator-go\" path=\"godeps/src/github.com/json-iterator/go\" remote=\"couchbasedeps\" revision=\"f7279a603edee96fe7764d3de9c6ff8cf9970994\" />",
 "  <project name=\"jsonx\" path=\"godeps/src/gopkg.in/couchbaselabs/jsonx.v1\" remote=\"couchbaselabs\" revision=\"5b7baa20429a46a5543ee259664cc86502738cad\" />",
 "  <project groups=\"kv\" name=\"kv_engine\" revision=\"94a16e416b1d1c1f744478b55ad278372e6bbfaf\" upstream=\"alice\" />",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"libcouchbase\" revision=\"081e8b16b991bf706eb77f8243935c6fba31b895\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"3681c2a912330352991ecdd642f257efe5b85518\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\" />",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\" />",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\" />",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"956632ec1bc3e28276d00ee2f22c3202f06efb12\" />",
 "  <project name=\"mossScope\" path=\"godeps/src/github.com/couchbase/mossScope\" revision=\"abd3b58b422dbc2e9463a589d0f3d93441726e23\" />",
 "  <project name=\"mousetrap\" path=\"godeps/src/github.com/inconshreveable/mousetrap\" remote=\"couchbasedeps\" revision=\"76626ae9c91c4f2a10f34cad8ce83ea42c93bb75\" />",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"cd8da46b9b953800d430c8b0aa4667790727ed6f\" />",
 "  <project name=\"msgp\" path=\"godeps/src/github.com/tinylib/msgp\" remote=\"couchbasedeps\" revision=\"5bb5e1aed7ba5bcc93307153b020e7ffe79b0509\" />",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"043ee6597c29786140136a5747b6a886364f5282\" />",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"62685c2d7ca23c807425dca88b11a3e2323dab41\" />",
 "  <project name=\"nitro\" path=\"goproj/src/github.com/couchbase/nitro\" revision=\"f3bef3551997be504612a2d05a8b324b3bfdfe1b\" />",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\" />",
 "  <project name=\"ns_server\" revision=\"e6b9cafa227bcf74bc11550be5e3450cc9fc48ec\" upstream=\"alice\" />",
 "  <project name=\"opentracing-go\" path=\"godeps/src/github.com/opentracing/opentracing-go\" remote=\"couchbasedeps\" revision=\"1949ddbfd147afd4d964a9f00b24eb291e0e7c38\" />",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\" />",
 "  <project name=\"pflag\" path=\"godeps/src/github.com/spf13/pflag\" remote=\"couchbasedeps\" revision=\"a232f6d9f87afaaa08bafaff5da685f974b83313\" />",
 "  <project groups=\"kv\" name=\"phosphor\" revision=\"96501c57bb0fd61c85cba6f63101aed2bcf41d38\" />",
 "  <project name=\"pierrec-lz4\" path=\"godeps/src/github.com/pierrec/lz4\" remote=\"couchbasedeps\" revision=\"ed8d4cc3b461464e69798080a0092bd028910298\" />",
 "  <project name=\"pierrec-xxHash\" path=\"godeps/src/github.com/pierrec/xxHash\" remote=\"couchbasedeps\" revision=\"a0006b13c722f7f12368c00a3d3c2ae8a999a0c6\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"plasma\" path=\"goproj/src/github.com/couchbase/plasma\" remote=\"couchbase-priv\" revision=\"53c7714a7ff072a76f202bc79be77b363c78aec8\" upstream=\"alice\" />",
 "  <project groups=\"kv\" name=\"platform\" revision=\"2fbe5179a2673a9275cd0906daa4b1cab38a3eb5\" />",
 "  <project groups=\"kv\" name=\"product-texts\" revision=\"8cf7d25a1dcb5434ea44983c0bed202fb9cc8351\" />",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\" />",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"152023ba183b1b1aacd862e2b48afa2907bad508\" upstream=\"alice\" />",
 "  <project name=\"query-ui\" revision=\"15a6461f437fe810e411a6613ec7c143991cd1c6\" upstream=\"alice\" />",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\" />",
 "  <project name=\"roaring\" path=\"godeps/src/github.com/RoaringBitmap/roaring\" remote=\"couchbasedeps\" revision=\"fe09428be4c233d726797a1380f7438f4f71a31a\" />",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"762005e7a34fd909a84586299f1dd457371d36ee\" />",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"73353fe6dad8f3d67409feefb9b17f90f6de917b\" />",
 "  <project name=\"snowballstem\" path=\"godeps/src/github.com/blevesearch/snowballstem\" remote=\"blevesearch\" revision=\"26b06a2c243d4f8ca5db3486f94409dd5b2a7467\" />",
 "  <project groups=\"kv\" name=\"spdlog\" path=\"third_party/spdlog\" remote=\"couchbasedeps\" revision=\"4fba14c79f356ae48d6141c561bf9fd7ba33fabd\" upstream=\"refs/tags/v0.14.0\" />",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\" />",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"c30c3d4c250e68e81c57aa1e8ae91ffd21243cdb\" />",
 "  <project name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\" />",
 "  <project name=\"testrunner\" revision=\"31738dbd28ca8a6460b6432da1f010b311b49e17\" upstream=\"alice\" />",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\" />",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"8625abafc3a6907dd43cce621939b4a09335ceed\" upstream=\"alice\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\" />",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\" />",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\" />",
 "    <copyfile dest=\".clang-format\" src=\"dot-clang-format\" />",
 "    <copyfile dest=\"third_party/CMakeLists.txt\" src=\"third-party-CMakeLists.txt\" />",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\" />",
 "  <project name=\"uuid\" path=\"godeps/src/github.com/google/uuid\" remote=\"couchbasedeps\" revision=\"dec09d789f3dba190787f8b4454c7d3c936fed9e\" />",
 "  <project name=\"vellum\" path=\"godeps/src/github.com/couchbase/vellum\" revision=\"0ceea4a37442f76199b9259840baf48d17af3c1a\" />",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"be41d2649d616c66f8dce2d9231c4be25e91db66\" upstream=\"alice\" />",
 "  <project name=\"zstd\" path=\"godeps/src/github.com/DataDog/zstd\" remote=\"couchbasedeps\" revision=\"aebefd9fcb99f22cd691ef778a12ed68f0e6a1ab\" />",
 "</manifest>"]

[error_logger:info,2019-03-19T15:50:27.307Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.139.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:27.310Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2019-03-19T15:50:27.311Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2019-03-19T15:50:27.311Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:init:243]ip config not found. Looks like we're brand new node
[error_logger:info,2019-03-19T15:50:27.312Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.143.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2019-03-19T15:50:27.312Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.142.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:27.626Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:bringup:295]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2019-03-19T15:50:27.635Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.145.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:27.635Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.146.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:27.635Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:configure_net_kernel:339]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2019-03-19T15:50:27.635Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.147.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:27.636Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.144.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2019-03-19T15:50:27.638Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:save_node:227]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2019-03-19T15:50:27.658Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:bringup:309]Attempted to save node name to disk: ok
[ns_server:debug,2019-03-19T15:50:27.658Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:316]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2019-03-19T15:50:27.658Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T15:50:27.719Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:328]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2019-03-19T15:50:27.719Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:27.728Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:27.730Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:27.732Z,ns_1@127.0.0.1:ns_config_sup<0.154.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2019-03-19T15:50:27.732Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.155.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:27.733Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.156.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:27.787Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1095]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2019-03-19T15:50:27.791Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1109]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:info,2019-03-19T15:50:27.791Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1114]No dynamic config file found. Assuming we're brand new node
[ns_server:debug,2019-03-19T15:50:27.800Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1117]Here's full dynamic config we loaded:
[[]]
[ns_server:info,2019-03-19T15:50:27.804Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1138]Here's full dynamic config we loaded + static & default config:
[{{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   false]},
 {password_policy,[{min_length,6},{must_present,[]}]},
 {drop_request_memory_threshold_mib,undefined},
 {{request_limit,capi},undefined},
 {{request_limit,rest},undefined},
 {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
 {auto_failover_cfg,[{enabled,true},{timeout,120},{max_nodes,1},{count,0}]},
 {log_redaction_default_cfg,[{redact_level,none}]},
 {replication,[{enabled,true}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {port,11211},
   {verbosity,[]}]},
 {secure_headers,[]},
 {buckets,[{configs,[]}]},
 {cbas_memory_quota,1024},
 {fts_memory_quota,256},
 {memory_quota,304},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},
          {port,port},
          {maxconn,maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {privilege_debug,privilege_debug},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {rbac_file,{"~s",[rbac_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps},
     {tracing_enabled,tracing_enabled},
     {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
     {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
     {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
     {logger,
      {[{filename,{"~s/~s",[log_path,log_prefix]}},
        {cyclesize,log_cyclesize},
        {sleeptime,log_sleeptime}]}}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"@ns_server"},
   {other_users,
    ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
     "@cbas"]},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {privilege_debug,false},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false},
   {tracing_enabled,true},
   {datatype_snappy,true}]},
 {memcached,[]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}]},
 {audit,
  [{auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {remote_clusters,[]},
 {read_only_user_creds,null},
 {rest_creds,null},
 {{metakv,<<"/indexing/settings/config">>},
  <<"{\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912}">>},
 {{node,'ns_1@127.0.0.1',eventing_debug_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9140]},
 {{node,'ns_1@127.0.0.1',eventing_https_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   18096]},
 {{node,'ns_1@127.0.0.1',eventing_http_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   8096]},
 {{node,'ns_1@127.0.0.1',cbas_ssl_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   18095]},
 {{node,'ns_1@127.0.0.1',cbas_parent_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9122]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9121]},
 {{node,'ns_1@127.0.0.1',cbas_replication_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9120]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9119]},
 {{node,'ns_1@127.0.0.1',cbas_debug_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|-1]},
 {{node,'ns_1@127.0.0.1',cbas_messaging_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9118]},
 {{node,'ns_1@127.0.0.1',cbas_result_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9117]},
 {{node,'ns_1@127.0.0.1',cbas_data_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9116]},
 {{node,'ns_1@127.0.0.1',cbas_cluster_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9115]},
 {{node,'ns_1@127.0.0.1',cbas_console_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9114]},
 {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9113]},
 {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9112]},
 {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9111]},
 {{node,'ns_1@127.0.0.1',cbas_admin_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9110]},
 {{node,'ns_1@127.0.0.1',cbas_http_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   8095]},
 {{node,'ns_1@127.0.0.1',fts_ssl_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   18094]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_https_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   19102]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {port,8091},
   {port_meta,global}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {rest,[{port,8091}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   active]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {quorum_nodes,['ns_1@127.0.0.1']},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {max_bucket_count,10},
 {index_aware_rebalance_disabled,false},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   {5,5,3}]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   <<"9bca6fc94f10ac3edc5b102bbb4437b5">>]}]
[error_logger:info,2019-03-19T15:50:27.812Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.157.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:27.815Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.163.0>},
                       {name,ns_config_remote},
                       {mfargs,{ns_config_replica,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:27.819Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.164.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:27.819Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:27.821Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.166.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:27.824Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.167.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:27.839Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.170.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:27.843Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2019-03-19T15:50:27.843Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.171.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:27.843Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.172.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:27.849Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.173.0>},
                       {name,memcached_refresh},
                       {mfargs,{memcached_refresh,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:27.853Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.175.0>},
                       {name,ssl_service_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ssl_service_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:27.871Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:init:416]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,undefined},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[ns_server:debug,2019-03-19T15:50:28.577Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_server_cert:generate_cert_and_pkey:80]Generated certificate and private key in 702795 us
[ns_server:debug,2019-03-19T15:50:28.578Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cert_and_pkey ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229828}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFY1m8D7hCswwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA5YTE4NDJjYjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgOWExODQy\nY2IwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC+eKF5LWqGKFW4gli1\nVvKni+IUYrmY6/qUKhTwQlSYprAg7gSvzaseLfccoVJZbUu6D8O9+wn5/fM1CuJZ\njgCNaWx6D88s/oegh4eAUkqXjnivEkv"...>>,
  <<"*****">>}]
[ns_server:debug,2019-03-19T15:50:28.578Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"9bca6fc94f10ac3edc5b102bbb4437b5">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229828}}]}]
[ns_server:info,2019-03-19T15:50:28.579Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:maybe_generate_local_cert:585]Failed to read node certificate. Perhaps it wasn't created yet. Error: {error,
                                                                        {badmatch,
                                                                         {error,
                                                                          enoent}}}
[ns_server:info,2019-03-19T15:50:29.134Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:do_generate_local_cert:573]Saved local cert for node 'ns_1@127.0.0.1'
[error_logger:info,2019-03-19T15:50:29.186Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.176.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:29.205Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2019-03-19T15:50:29.206Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2019-03-19T15:50:29.207Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2019-03-19T15:50:29.208Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[ns_server:debug,2019-03-19T15:50:29.236Z,ns_1@127.0.0.1:<0.183.0>:restartable:start_child:98]Started child process <0.184.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2019-03-19T15:50:29.236Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.183.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:29.237Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.174.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:29.240Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.202.0>},
                       {name,user_storage_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,user_storage_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:29.249Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.204.0>},
                       {name,users_replicator},
                       {mfargs,{menelaus_users,start_replicator,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:29.251Z,ns_1@127.0.0.1:users_replicator<0.204.0>:replicated_storage:wait_for_startup:55]Start waiting for startup
[ns_server:debug,2019-03-19T15:50:29.255Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_storage:anounce_startup:69]Announce my startup to <0.204.0>
[ns_server:debug,2019-03-19T15:50:29.255Z,ns_1@127.0.0.1:users_replicator<0.204.0>:replicated_storage:wait_for_startup:58]Received replicated storage registration from <0.205.0>
[ns_server:debug,2019-03-19T15:50:29.260Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_dets:open:212]Opening file "/opt/couchbase/var/lib/couchbase/config/users.dets"
[error_logger:info,2019-03-19T15:50:29.260Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.205.0>},
                       {name,users_storage},
                       {mfargs,{menelaus_users,start_storage,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:29.260Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.203.0>},
                       {name,users_storage_sup},
                       {mfargs,{users_storage_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2019-03-19T15:50:29.280Z,ns_1@127.0.0.1:compiled_roles_cache<0.207.0>:versioned_cache:init:44]Starting versioned cache compiled_roles_cache
[error_logger:info,2019-03-19T15:50:29.281Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.207.0>},
                       {name,compiled_roles_cache},
                       {mfargs,{menelaus_roles,start_compiled_roles_cache,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:29.281Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.201.0>},
                       {name,users_sup},
                       {mfargs,{users_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:29.283Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.210.0>},
                       {name,dets_sup},
                       {mfargs,{dets_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:29.283Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.211.0>},
                       {name,dets},
                       {mfargs,{dets_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:29.302Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_dets:convert_docs_to_55_in_dets:243]Checking for pre 5.5 records in dets: users_storage
[ns_server:debug,2019-03-19T15:50:29.302Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,'$1','_','$2'},
                                      [],
                                      [{{'$1','$2'}}]}],
                                    100}
[ns_server:debug,2019-03-19T15:50:29.302Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_dets:init_after_ack:204]Loading 0 items, 299 words took 0ms
[ns_server:debug,2019-03-19T15:50:29.306Z,ns_1@127.0.0.1:users_replicator<0.204.0>:doc_replicator:loop:60]doing replicate_newnodes_docs
[ns_server:debug,2019-03-19T15:50:29.310Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.215.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:141]Waiting for ns_couchdb node to start
[error_logger:info,2019-03-19T15:50:29.310Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.214.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:29.310Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T15:50:29.310Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.218.0>,shutdown}}
[error_logger:info,2019-03-19T15:50:29.310Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T15:50:29.311Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T15:50:29.512Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T15:50:29.512Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.221.0>,shutdown}}
[ns_server:debug,2019-03-19T15:50:29.512Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T15:50:29.512Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T15:50:29.713Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T15:50:29.713Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.224.0>,shutdown}}
[error_logger:info,2019-03-19T15:50:29.713Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T15:50:29.713Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T15:50:29.914Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T15:50:29.914Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.227.0>,shutdown}}
[error_logger:info,2019-03-19T15:50:29.914Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T15:50:29.915Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T15:50:30.116Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T15:50:30.116Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.230.0>,shutdown}}
[error_logger:info,2019-03-19T15:50:30.116Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T15:50:30.116Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T15:50:30.317Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T15:50:30.317Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.233.0>,shutdown}}
[ns_server:debug,2019-03-19T15:50:30.317Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T15:50:30.317Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T15:50:30.518Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T15:50:30.560Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2019-03-19T15:50:30.761Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2019-03-19T15:50:30.962Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2019-03-19T15:50:31.163Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2019-03-19T15:50:31.364Z,ns_1@127.0.0.1:<0.216.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[error_logger:info,2019-03-19T15:50:32.089Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.243.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:32.290Z,ns_1@127.0.0.1:ns_couchdb_port<0.214.0>:ns_port_server:log:223]ns_couchdb<0.214.0>: Apache CouchDB v4.5.1-109-g3c4ad2b (LogLevel=info) is starting.

[error_logger:info,2019-03-19T15:50:32.634Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.215.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.96617950>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:32.642Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:ns_storage_conf:setup_db_and_ix_paths:47]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[ns_server:info,2019-03-19T15:50:32.661Z,ns_1@127.0.0.1:ns_couchdb_port<0.214.0>:ns_port_server:log:223]ns_couchdb<0.214.0>: Apache CouchDB has started. Time to relax.
ns_couchdb<0.214.0>: 180: Booted. Waiting for shutdown request

[error_logger:info,2019-03-19T15:50:32.666Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:32.668Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.247.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:32.669Z,ns_1@127.0.0.1:ns_server_sup<0.245.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2019-03-19T15:50:32.670Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.248.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:32.672Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.249.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2019-03-19T15:50:32.678Z,ns_1@127.0.0.1:ns_log<0.250.0>:ns_log:read_logs:92]Couldn't load logs from "/opt/couchbase/var/lib/couchbase/ns_log" (perhaps it's first startup): {error,
                                                                                                 enoent}
[error_logger:info,2019-03-19T15:50:32.678Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.250.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:32.678Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:32.689Z,ns_1@127.0.0.1:memcached_passwords<0.252.0>:memcached_cfg:init:62]Init config writer for memcached_passwords, "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2019-03-19T15:50:32.689Z,ns_1@127.0.0.1:memcached_passwords<0.252.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2019-03-19T15:50:33.012Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[error_logger:info,2019-03-19T15:50:33.012Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.252.0>},
                       {name,memcached_passwords},
                       {mfargs,{memcached_passwords,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.075Z,ns_1@127.0.0.1:memcached_permissions<0.255.0>:memcached_cfg:init:62]Init config writer for memcached_permissions, "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2019-03-19T15:50:33.077Z,ns_1@127.0.0.1:memcached_permissions<0.255.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:warn,2019-03-19T15:50:33.084Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:33.085Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [isasl] failed. Retry in 1000 ms.
[ns_server:debug,2019-03-19T15:50:33.089Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of rbac requested
[error_logger:info,2019-03-19T15:50:33.089Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.255.0>},
                       {name,memcached_permissions},
                       {mfargs,{memcached_permissions,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.089Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.258.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2019-03-19T15:50:33.090Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:33.090Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2019-03-19T15:50:33.092Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.260.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.093Z,ns_1@127.0.0.1:ns_node_disco<0.261.0>:ns_node_disco:init:130]Initting ns_node_disco with []
[ns_server:debug,2019-03-19T15:50:33.093Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[user:info,2019-03-19T15:50:33.093Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_init:83]Initial otp cookie generated: {sanitized,
                                  <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[ns_server:debug,2019-03-19T15:50:33.093Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"9bca6fc94f10ac3edc5b102bbb4437b5">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{2,63720229833}}]}]
[ns_server:debug,2019-03-19T15:50:33.093Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
otp ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {cookie,{sanitized,<<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}}]
[ns_server:debug,2019-03-19T15:50:33.093Z,ns_1@127.0.0.1:<0.262.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[ns_server:debug,2019-03-19T15:50:33.098Z,ns_1@127.0.0.1:<0.262.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[error_logger:info,2019-03-19T15:50:33.098Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.261.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.101Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.264.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.103Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.265.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.109Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.266.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.110Z,ns_1@127.0.0.1:ns_config_rep<0.267.0>:ns_config_rep:init:69]init pulling
[ns_server:debug,2019-03-19T15:50:33.110Z,ns_1@127.0.0.1:ns_config_rep<0.267.0>:ns_config_rep:init:71]init pushing
[ns_server:debug,2019-03-19T15:50:33.115Z,ns_1@127.0.0.1:ns_config_rep<0.267.0>:ns_config_rep:init:75]init reannouncing
[ns_server:debug,2019-03-19T15:50:33.115Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2019-03-19T15:50:33.115Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2019-03-19T15:50:33.116Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2019-03-19T15:50:33.126Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2019-03-19T15:50:33.126Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
otp ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {cookie,{sanitized,<<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}}]
[ns_server:debug,2019-03-19T15:50:33.126Z,ns_1@127.0.0.1:<0.275.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[ns_server:debug,2019-03-19T15:50:33.127Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cert_and_pkey ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229828}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFY1m8D7hCswwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA5YTE4NDJjYjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgOWExODQy\nY2IwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC+eKF5LWqGKFW4gli1\nVvKni+IUYrmY6/qUKhTwQlSYprAg7gSvzaseLfccoVJZbUu6D8O9+wn5/fM1CuJZ\njgCNaWx6D88s/oegh4eAUkqXjnivEkv"...>>,
  <<"*****">>}]
[ns_server:debug,2019-03-19T15:50:33.128Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2019-03-19T15:50:33.128Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit ->
[{auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2019-03-19T15:50:33.128Z,ns_1@127.0.0.1:<0.276.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[ns_server:debug,2019-03-19T15:50:33.129Z,ns_1@127.0.0.1:<0.275.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[ns_server:debug,2019-03-19T15:50:33.128Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{enabled,true},{timeout,120},{max_nodes,1},{count,0}]
[ns_server:debug,2019-03-19T15:50:33.129Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_reprovision_cfg ->
[{enabled,true},{max_nodes,1},{count,0}]
[ns_server:debug,2019-03-19T15:50:33.129Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2019-03-19T15:50:33.129Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
buckets ->
[[],{configs,[]}]
[ns_server:debug,2019-03-19T15:50:33.129Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cbas_memory_quota ->
1024
[ns_server:debug,2019-03-19T15:50:33.129Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2019-03-19T15:50:33.129Z,ns_1@127.0.0.1:<0.276.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[ns_server:debug,2019-03-19T15:50:33.130Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded,communication_issue]}]
[ns_server:debug,2019-03-19T15:50:33.130Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
fts_memory_quota ->
256
[ns_server:debug,2019-03-19T15:50:33.130Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2019-03-19T15:50:33.130Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
log_redaction_default_cfg ->
[{redact_level,none}]
[ns_server:debug,2019-03-19T15:50:33.130Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
max_bucket_count ->
10
[ns_server:debug,2019-03-19T15:50:33.130Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memcached ->
[]
[ns_server:debug,2019-03-19T15:50:33.130Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memory_quota ->
304
[ns_server:debug,2019-03-19T15:50:33.131Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2019-03-19T15:50:33.131Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
password_policy ->
[{min_length,6},{must_present,[]}]
[ns_server:debug,2019-03-19T15:50:33.131Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
quorum_nodes ->
['ns_1@127.0.0.1']
[ns_server:debug,2019-03-19T15:50:33.131Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
read_only_user_creds ->
null
[ns_server:debug,2019-03-19T15:50:33.131Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
remote_clusters ->
[]
[ns_server:debug,2019-03-19T15:50:33.131Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2019-03-19T15:50:33.131Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest ->
[{port,8091}]
[ns_server:debug,2019-03-19T15:50:33.131Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest_creds ->
null
[ns_server:debug,2019-03-19T15:50:33.131Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
secure_headers ->
[]
[ns_server:debug,2019-03-19T15:50:33.131Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2019-03-19T15:50:33.132Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2019-03-19T15:50:33.132Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2019-03-19T15:50:33.132Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2019-03-19T15:50:33.132Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/indexing/settings/config">>} ->
<<"{\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912}">>
[ns_server:debug,2019-03-19T15:50:33.132Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2019-03-19T15:50:33.132Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2019-03-19T15:50:33.132Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}]
[ns_server:debug,2019-03-19T15:50:33.132Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|8092]
[ns_server:debug,2019-03-19T15:50:33.133Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_admin_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9110]
[ns_server:debug,2019-03-19T15:50:33.133Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_client_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9113]
[ns_server:debug,2019-03-19T15:50:33.133Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_cluster_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9112]
[ns_server:debug,2019-03-19T15:50:33.133Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_http_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9111]
[ns_server:debug,2019-03-19T15:50:33.133Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cluster_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9115]
[ns_server:debug,2019-03-19T15:50:33.133Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_console_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9114]
[ns_server:debug,2019-03-19T15:50:33.133Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_data_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9116]
[ns_server:debug,2019-03-19T15:50:33.134Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_debug_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|-1]
[ns_server:debug,2019-03-19T15:50:33.134Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_http_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|8095]
[ns_server:debug,2019-03-19T15:50:33.134Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_messaging_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9118]
[ns_server:debug,2019-03-19T15:50:33.134Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_callback_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9119]
[ns_server:debug,2019-03-19T15:50:33.134Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9121]
[ns_server:debug,2019-03-19T15:50:33.134Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_parent_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9122]
[ns_server:debug,2019-03-19T15:50:33.134Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_replication_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9120]
[ns_server:debug,2019-03-19T15:50:33.135Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_result_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9117]
[ns_server:debug,2019-03-19T15:50:33.135Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_ssl_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|18095]
[ns_server:debug,2019-03-19T15:50:33.135Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2019-03-19T15:50:33.135Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
 {5,5,3}]
[ns_server:debug,2019-03-19T15:50:33.135Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_debug_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9140]
[ns_server:debug,2019-03-19T15:50:33.135Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_http_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|8096]
[ns_server:debug,2019-03-19T15:50:33.136Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_https_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|18096]
[ns_server:debug,2019-03-19T15:50:33.136Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|8094]
[ns_server:debug,2019-03-19T15:50:33.136Z,ns_1@127.0.0.1:compiled_roles_cache<0.207.0>:versioned_cache:handle_info:89]Flushing cache compiled_roles_cache due to version change from undefined to {undefined,
                                                                             {0,
                                                                              4241168083},
                                                                             false,
                                                                             []}
[ns_server:debug,2019-03-19T15:50:33.136Z,ns_1@127.0.0.1:memcached_passwords<0.252.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2019-03-19T15:50:33.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_ssl_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|18094]
[ns_server:debug,2019-03-19T15:50:33.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9100]
[ns_server:debug,2019-03-19T15:50:33.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9102]
[ns_server:debug,2019-03-19T15:50:33.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_https_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|19102]
[ns_server:debug,2019-03-19T15:50:33.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9101]
[ns_server:debug,2019-03-19T15:50:33.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9104]
[ns_server:debug,2019-03-19T15:50:33.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9103]
[ns_server:debug,2019-03-19T15:50:33.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9105]
[ns_server:debug,2019-03-19T15:50:33.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|true]
[ns_server:debug,2019-03-19T15:50:33.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2019-03-19T15:50:33.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|true]
[ns_server:debug,2019-03-19T15:50:33.152Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
 active]
[ns_server:debug,2019-03-19T15:50:33.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"@ns_server"},
 {other_users,["@cbq-engine","@projector","@goxdcr","@index","@fts",
               "@eventing","@cbas"]},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2019-03-19T15:50:33.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},
        {port,port},
        {maxconn,maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {privilege_debug,privilege_debug},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {rbac_file,{"~s",[rbac_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps},
   {tracing_enabled,tracing_enabled},
   {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
   {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
   {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
   {logger,
    {[{filename,{"~s/~s",[log_path,log_prefix]}},
      {cyclesize,log_cyclesize},
      {sleeptime,log_sleeptime}]}}]}]
[ns_server:debug,2019-03-19T15:50:33.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {privilege_debug,false},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false},
 {tracing_enabled,true},
 {datatype_snappy,true}]
[ns_server:debug,2019-03-19T15:50:33.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2019-03-19T15:50:33.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2019-03-19T15:50:33.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}]
[ns_server:debug,2019-03-19T15:50:33.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9999]
[ns_server:debug,2019-03-19T15:50:33.153Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|8093]
[ns_server:debug,2019-03-19T15:50:33.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2019-03-19T15:50:33.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|18092]
[ns_server:debug,2019-03-19T15:50:33.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|18093]
[ns_server:debug,2019-03-19T15:50:33.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|18091]
[ns_server:debug,2019-03-19T15:50:33.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
 <<"9bca6fc94f10ac3edc5b102bbb4437b5">>]
[ns_server:debug,2019-03-19T15:50:33.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9998]
[ns_server:debug,2019-03-19T15:50:33.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|false]
[ns_server:debug,2019-03-19T15:50:33.154Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"9bca6fc94f10ac3edc5b102bbb4437b5">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{2,63720229833}}]}]
[error_logger:info,2019-03-19T15:50:33.176Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.267.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.180Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.259.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2019-03-19T15:50:33.180Z,ns_1@127.0.0.1:ns_config_rep<0.267.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([alert_limits,audit,auto_failover_cfg,
                               auto_reprovision_cfg,autocompaction,buckets,
                               cbas_memory_quota,cert_and_pkey,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,
                               index_aware_rebalance_disabled,
                               log_redaction_default_cfg,max_bucket_count,
                               memcached,memory_quota,nodes_wanted,otp,
                               password_policy,quorum_nodes,
                               read_only_user_creds,remote_clusters,
                               replication,rest,rest_creds,secure_headers,
                               server_groups,set_view_update_daemon,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"9bca6fc94f10ac3edc5b102bbb4437b5">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {request_limit,capi},
                               {request_limit,rest},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',cbas_admin_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_client_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_http_port},
                               {node,'ns_1@127.0.0.1',cbas_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_console_port},
                               {node,'ns_1@127.0.0.1',cbas_data_port},
                               {node,'ns_1@127.0.0.1',cbas_debug_port},
                               {node,'ns_1@127.0.0.1',cbas_http_port},
                               {node,'ns_1@127.0.0.1',cbas_messaging_port},
                               {node,'ns_1@127.0.0.1',
                                   cbas_metadata_callback_port},
                               {node,'ns_1@127.0.0.1',cbas_metadata_port},
                               {node,'ns_1@127.0.0.1',cbas_parent_port},
                               {node,'ns_1@127.0.0.1',cbas_replication_port},
                               {node,'ns_1@127.0.0.1',cbas_result_port},
                               {node,'ns_1@127.0.0.1',cbas_ssl_port},
                               {node,'ns_1@127.0.0.1',compaction_daemon},
                               {node,'ns_1@127.0.0.1',config_version},
                               {node,'ns_1@127.0.0.1',eventing_debug_port},
                               {node,'ns_1@127.0.0.1',eventing_http_port},
                               {node,'ns_1@127.0.0.1',eventing_https_port},
                               {node,'ns_1@127.0.0.1',fts_http_port},
                               {node,'ns_1@127.0.0.1',fts_ssl_port},
                               {node,'ns_1@127.0.0.1',indexer_admin_port},
                               {node,'ns_1@127.0.0.1',indexer_http_port},
                               {node,'ns_1@127.0.0.1',indexer_https_port},
                               {node,'ns_1@127.0.0.1',indexer_scan_port},
                               {node,'ns_1@127.0.0.1',indexer_stcatchup_port}]..)
[error_logger:info,2019-03-19T15:50:33.206Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.283.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.228Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.285.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.228Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.288.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.228Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.289.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.235Z,ns_1@127.0.0.1:ns_log_events<0.258.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2019-03-19T15:50:33.234Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.291.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.235Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.290.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.235Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.292.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.239Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.293.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:33.296Z,ns_1@127.0.0.1:ns_couchdb_port<0.214.0>:ns_port_server:log:223]ns_couchdb<0.214.0>: working as port

[error_logger:info,2019-03-19T15:50:33.316Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.295.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.316Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.299.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.316Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.294.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.320Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.304.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.336Z,ns_1@127.0.0.1:ns_heart<0.295.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2019-03-19T15:50:33.337Z,ns_1@127.0.0.1:ns_heart<0.295.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]}]}}

[ns_server:debug,2019-03-19T15:50:33.356Z,ns_1@127.0.0.1:<0.302.0>:restartable:start_child:98]Started child process <0.303.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2019-03-19T15:50:33.356Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.306.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.357Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.302.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.357Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.309.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.362Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.310.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.362Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.311.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.362Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.312.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.362Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.313.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.366Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.315.0>},
                       {name,query_settings_manager},
                       {mfargs,{query_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.371Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.317.0>},
                       {name,eventing_settings_manager},
                       {mfargs,{eventing_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.371Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.319.0>},
                       {name,audit_events},
                       {mfargs,{gen_event,start_link,[{local,audit_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.384Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.322.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.384Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.324.0>},
                       {name,scram_sha},
                       {mfargs,{scram_sha,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.387Z,ns_1@127.0.0.1:ns_heart<0.295.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2019-03-19T15:50:33.390Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.325.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.394Z,ns_1@127.0.0.1:ns_heart<0.295.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2019-03-19T15:50:33.398Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.327.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.405Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[ns_server:warn,2019-03-19T15:50:33.406Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:33.406Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2019-03-19T15:50:33.409Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.328.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.410Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.329.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:33.413Z,ns_1@127.0.0.1:menelaus_sup<0.320.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2019-03-19T15:50:33.413Z,ns_1@127.0.0.1:menelaus_sup<0.320.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2019-03-19T15:50:33.413Z,ns_1@127.0.0.1:menelaus_sup<0.320.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2019-03-19T15:50:33.413Z,ns_1@127.0.0.1:menelaus_sup<0.320.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[error_logger:info,2019-03-19T15:50:33.414Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.330.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.418Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.299.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,244}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:debug,2019-03-19T15:50:33.419Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.299.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,244}]}]}}

[ns_server:debug,2019-03-19T15:50:33.419Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.299.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2019-03-19T15:50:33.419Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.299.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2019-03-19T15:50:33.420Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.362.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.438Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.364.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.441Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.366.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.448Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.367.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2019-03-19T15:50:33.451Z,ns_1@127.0.0.1:ns_server_sup<0.245.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "6.0.1-2037-enterprise".
[error_logger:info,2019-03-19T15:50:33.451Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.320.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.451Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.373.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.453Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.377.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.454Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.378.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.31986353>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.454Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.376.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2019-03-19T15:50:33.458Z,ns_1@127.0.0.1:ns_ports_setup<0.373.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr]
[error_logger:info,2019-03-19T15:50:33.469Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.380.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.469Z,ns_1@127.0.0.1:ns_audit_cfg<0.381.0>:ns_audit_cfg:write_audit_json:265]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{descriptors_path,
                                                                                <<"/opt/couchbase/etc/security">>},
                                                                               {version,
                                                                                1},
                                                                               {auditd_enabled,
                                                                                false},
                                                                               {disabled,
                                                                                []},
                                                                               {log_path,
                                                                                <<"/opt/couchbase/var/lib/couchbase/logs">>},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []}]
[ns_server:debug,2019-03-19T15:50:33.492Z,ns_1@127.0.0.1:ns_audit_cfg<0.381.0>:ns_audit_cfg:notify_memcached:170]Instruct memcached to reload audit config
[error_logger:info,2019-03-19T15:50:33.492Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.381.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2019-03-19T15:50:33.493Z,ns_1@127.0.0.1:<0.384.0>:ns_memcached:connect:1230]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2019-03-19T15:50:33.497Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.385.0>},
                       {name,ns_audit},
                       {mfargs,{ns_audit,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.508Z,ns_1@127.0.0.1:memcached_config_mgr<0.386.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:33.508Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.386.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:33.512Z,ns_1@127.0.0.1:<0.387.0>:ns_memcached_log_rotator:init:42]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2019-03-19T15:50:33.512Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.387.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.517Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.388.0>},
                       {name,testconditions_store},
                       {mfargs,{simple_store,start_link,[testconditions]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.520Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.390.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.523Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.392.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.523Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.391.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.524Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.389.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.548Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.393.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.550Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.397.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.555Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.399.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.556Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.400.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.557Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.402.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.567Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.403.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.567Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.405.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.573Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.406.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.574Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.408.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.574Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.410.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.578Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.411.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.581Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.413.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.582Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.413.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2019-03-19T15:50:33.582Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.413.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2019-03-19T15:50:33.588Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.417.0>},
                       {name,service_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_stats_children_sup},
                                services_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.591Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.419.0>},
                       {name,service_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [service_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.603Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.420.0>},
                       {name,service_status_keeper_index},
                       {mfargs,{service_index,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.618Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.423.0>},
                       {name,service_status_keeper_fts},
                       {mfargs,{service_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.621Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.426.0>},
                       {name,service_status_keeper_eventing},
                       {mfargs,{service_eventing,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.621Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.418.0>},
                       {name,service_status_keeper_sup},
                       {mfargs,{service_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.621Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.429.0>},
                       {name,service_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<services_stats_sup.0.41280346>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.622Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.416.0>},
                       {name,services_stats_sup},
                       {mfargs,{services_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.629Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.431.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.635Z,ns_1@127.0.0.1:ns_ports_setup<0.373.0>:ns_ports_setup:set_children:90]Monitor ns_child_ports_sup <12400.74.0>
[ns_server:debug,2019-03-19T15:50:33.635Z,ns_1@127.0.0.1:memcached_config_mgr<0.386.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2019-03-19T15:50:33.639Z,ns_1@127.0.0.1:<0.435.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.435.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2019-03-19T15:50:33.641Z,ns_1@127.0.0.1:memcached_config_mgr<0.386.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:33.643Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:50:33.644Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:50:33.644Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:50:33.644Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:50:33.644Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:50:33.644Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2019-03-19T15:50:33.644Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.432.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.657Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.439.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.657Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.438.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.663Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.440.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.678Z,ns_1@127.0.0.1:memcached_config_mgr<0.386.0>:memcached_config_mgr:init:79]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2019-03-19T15:50:33.716Z,ns_1@127.0.0.1:memcached_config_mgr<0.386.0>:memcached_config_mgr:init:82]activated memcached port server
[error_logger:info,2019-03-19T15:50:33.719Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.444.0>},
                       {name,leader_activities},
                       {mfargs,{leader_activities,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.725Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.445.0>},
                       {name,leader_lease_agent},
                       {mfargs,{leader_lease_agent,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.725Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.443.0>},
                       {name,leader_leases_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_leases_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.725Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.447.0>},
                       {name,leader_events},
                       {mfargs,{gen_event,start_link,[{local,leader_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.728Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.448.0>},
                       {name,leader_registry_server},
                       {mfargs,{leader_registry_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.736Z,ns_1@127.0.0.1:leader_registry_sup<0.446.0>:mb_master:check_master_takeover_needed:133]Sending master node question to the following nodes: []
[ns_server:debug,2019-03-19T15:50:33.736Z,ns_1@127.0.0.1:leader_registry_sup<0.446.0>:mb_master:check_master_takeover_needed:135]Got replies: []
[ns_server:debug,2019-03-19T15:50:33.736Z,ns_1@127.0.0.1:leader_registry_sup<0.446.0>:mb_master:check_master_takeover_needed:141]Was unable to discover master, not going to force mastership takeover
[user:info,2019-03-19T15:50:33.736Z,ns_1@127.0.0.1:mb_master<0.451.0>:mb_master:init:86]I'm the only node, so I'm the master.
[ns_server:debug,2019-03-19T15:50:33.736Z,ns_1@127.0.0.1:leader_registry<0.448.0>:leader_registry_server:handle_new_leader:241]New leader is 'ns_1@127.0.0.1'. Invalidating name cache.
[ns_server:debug,2019-03-19T15:50:33.747Z,ns_1@127.0.0.1:leader_lease_acquirer<0.454.0>:leader_utils:wait_cluster_is_55:54]Delaying start since cluster is not fully upgraded to 5.5 yet.
[error_logger:info,2019-03-19T15:50:33.747Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.454.0>},
                       {name,leader_lease_acquirer},
                       {mfargs,{leader_lease_acquirer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.757Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.456.0>:leader_utils:wait_cluster_is_55:54]Delaying start since cluster is not fully upgraded to 5.5 yet.
[error_logger:info,2019-03-19T15:50:33.757Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.456.0>},
                       {name,leader_quorum_nodes_manager},
                       {mfargs,{leader_quorum_nodes_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:33.779Z,ns_1@127.0.0.1:mb_master_sup<0.453.0>:misc:start_singleton:756]start_singleton(gen_server, ns_tick, [], []): started as <0.458.0> on 'ns_1@127.0.0.1'

[error_logger:info,2019-03-19T15:50:33.779Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.458.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.788Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.461.0>},
                       {name,ns_janitor_server},
                       {mfargs,{ns_janitor_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:33.791Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.460.0>:misc:start_singleton:756]start_singleton(gen_server, auto_reprovision, [], []): started as <0.462.0> on 'ns_1@127.0.0.1'

[error_logger:info,2019-03-19T15:50:33.791Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.462.0>},
                       {name,auto_reprovision},
                       {mfargs,{auto_reprovision,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.798Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[4,0]}]

[ns_server:info,2019-03-19T15:50:33.799Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [4,1]
[ns_server:debug,2019-03-19T15:50:33.799Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[4,1]},
 {set,{service_map,n1ql},[]},
 {set,{service_map,index},[]}]

[ns_server:info,2019-03-19T15:50:33.799Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [4,5]
[ns_server:debug,2019-03-19T15:50:33.799Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[4,5]},
 {set,{service_map,fts},[]},
 {set,{metakv,<<"/indexing/settings/config">>},
      <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>}]

[ns_server:info,2019-03-19T15:50:33.799Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [4,6]
[ns_server:debug,2019-03-19T15:50:33.799Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[4,6]}]

[ns_server:info,2019-03-19T15:50:33.800Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [5,0]
[ns_server:debug,2019-03-19T15:50:33.800Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[5,0]},
 {delete,roles_definitions},
 {delete,users_upgrade},
 {delete,read_only_user_creds},
 {set,buckets,[{configs,[]}]}]

[ns_server:info,2019-03-19T15:50:33.800Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [5,1]
[ns_server:debug,2019-03-19T15:50:33.800Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[5,1]},
 {set,client_cert_auth,[{state,"disable"},{prefixes,[]}]},
 {set,buckets,[{configs,[]}]}]

[ns_server:info,2019-03-19T15:50:33.807Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [5,5]
[ns_server:debug,2019-03-19T15:50:33.807Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[5,5]},
 {set,auto_failover_cfg,
      [{enabled,true},
       {timeout,120},
       {count,0},
       {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
       {failover_server_group,false},
       {max_count,1},
       {failed_over_server_groups,[]}]},
 {set,{metakv,<<"/query/settings/config">>},
      <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>},
 {set,{metakv,<<"/eventing/settings/config">>},<<"{\"ram_quota\":256}">>},
 {set,buckets,[{configs,[]}]},
 {delete,{rbac_upgrade,[5,5]}},
 {set,audit,
      [{enabled,[]},
       {disabled_users,[]},
       {auditd_enabled,false},
       {rotate_interval,86400},
       {rotate_size,20971520},
       {disabled,[]},
       {sync,[]},
       {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {set,quorum_nodes,['ns_1@127.0.0.1']},
 {set,scramsha_fallback_salt,<<153,243,183,226,93,180,216,77,176,217,18,64>>}]

[ns_server:info,2019-03-19T15:50:33.807Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_online_config_upgrader:do_upgrade_config:46]Performing online config upgrade to [6,0]
[ns_server:debug,2019-03-19T15:50:33.814Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:do_upgrade_config:728]Upgrading config by changes:
[{set,cluster_compat_version,[6,0]},
 {set,audit_decriptors,
      [{20480,
        [{name,<<"opened DCP connection">>},
         {description,<<"opened DCP connection">>},
         {enabled,true},
         {module,memcached}]},
       {20482,
        [{name,<<"external memcached bucket flush">>},
         {description,<<"External user flushed the content of a memcached bucket">>},
         {enabled,true},
         {module,memcached}]},
       {20483,
        [{name,<<"invalid packet">>},
         {description,<<"Rejected an invalid packet">>},
         {enabled,true},
         {module,memcached}]},
       {20485,
        [{name,<<"authentication succeeded">>},
         {description,<<"Authentication to the cluster succeeded">>},
         {enabled,false},
         {module,memcached}]},
       {20488,
        [{name,<<"document read">>},
         {description,<<"Document was read">>},
         {enabled,false},
         {module,memcached}]},
       {20489,
        [{name,<<"document locked">>},
         {description,<<"Document was locked">>},
         {enabled,false},
         {module,memcached}]},
       {20490,
        [{name,<<"document modify">>},
         {description,<<"Document was modified">>},
         {enabled,false},
         {module,memcached}]},
       {20491,
        [{name,<<"document delete">>},
         {description,<<"Document was deleted">>},
         {enabled,false},
         {module,memcached}]},
       {20492,
        [{name,<<"select bucket">>},
         {description,<<"The specified bucket was selected">>},
         {enabled,true},
         {module,memcached}]},
       {28672,
        [{name,<<"SELECT statement">>},
         {description,<<"A N1QL SELECT statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28673,
        [{name,<<"EXPLAIN statement">>},
         {description,<<"A N1QL EXPLAIN statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28674,
        [{name,<<"PREPARE statement">>},
         {description,<<"A N1QL PREPARE statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28675,
        [{name,<<"INFER statement">>},
         {description,<<"A N1QL INFER statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28676,
        [{name,<<"INSERT statement">>},
         {description,<<"A N1QL INSERT statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28677,
        [{name,<<"UPSERT statement">>},
         {description,<<"A N1QL UPSERT statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28678,
        [{name,<<"DELETE statement">>},
         {description,<<"A N1QL DELETE statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28679,
        [{name,<<"UPDATE statement">>},
         {description,<<"A N1QL UPDATE statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28680,
        [{name,<<"MERGE statement">>},
         {description,<<"A N1QL MERGE statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28681,
        [{name,<<"CREATE INDEX statement">>},
         {description,<<"A N1QL CREATE INDEX statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28682,
        [{name,<<"DROP INDEX statement">>},
         {description,<<"A N1QL DROP INDEX statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28683,
        [{name,<<"ALTER INDEX statement">>},
         {description,<<"A N1QL ALTER INDEX statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28684,
        [{name,<<"BUILD INDEX statement">>},
         {description,<<"A N1QL BUILD INDEX statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28685,
        [{name,<<"GRANT ROLE statement">>},
         {description,<<"A N1QL GRANT ROLE statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28686,
        [{name,<<"REVOKE ROLE statement">>},
         {description,<<"A N1QL REVOKE ROLE statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28687,
        [{name,<<"UNRECOGNIZED statement">>},
         {description,<<"An unrecognized statement was received by the N1QL query engine">>},
         {enabled,false},
         {module,n1ql}]},
       {28688,
        [{name,<<"CREATE PRIMARY INDEX statement">>},
         {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
         {enabled,false},
         {module,n1ql}]},
       {28689,
        [{name,<<"/admin/stats API request">>},
         {description,<<"An HTTP request was made to the API at /admin/stats.">>},
         {enabled,false},
         {module,n1ql}]},
       {28690,
        [{name,<<"/admin/vitals API request">>},
         {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
         {enabled,false},
         {module,n1ql}]},
       {28691,
        [{name,<<"/admin/prepareds API request">>},
         {description,<<"An HTTP request was made to the API at /admin/prepareds.">>},
         {enabled,false},
         {module,n1ql}]},
       {28692,
        [{name,<<"/admin/active_requests API request">>},
         {description,<<"An HTTP request was made to the API at /admin/active_requests.">>},
         {enabled,false},
         {module,n1ql}]},
       {28693,
        [{name,<<"/admin/indexes/prepareds API request">>},
         {description,<<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
         {enabled,false},
         {module,n1ql}]},
       {28694,
        [{name,<<"/admin/indexes/active_requests API request">>},
         {description,<<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
         {enabled,false},
         {module,n1ql}]},
       {28695,
        [{name,<<"/admin/indexes/completed_requests API request">>},
         {description,<<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
         {enabled,false},
         {module,n1ql}]},
       {28697,
        [{name,<<"/admin/ping API request">>},
         {description,<<"An HTTP request was made to the API at /admin/ping.">>},
         {enabled,false},
         {module,n1ql}]},
       {28698,
        [{name,<<"/admin/config API request">>},
         {description,<<"An HTTP request was made to the API at /admin/config.">>},
         {enabled,false},
         {module,n1ql}]},
       {28699,
        [{name,<<"/admin/ssl_cert API request">>},
         {description,<<"An HTTP request was made to the API at /admin/ssl_cert.">>},
         {enabled,false},
         {module,n1ql}]},
       {28700,
        [{name,<<"/admin/settings API request">>},
         {description,<<"An HTTP request was made to the API at /admin/settings.">>},
         {enabled,false},
         {module,n1ql}]},
       {28701,
        [{name,<<"/admin/clusters API request">>},
         {description,<<"An HTTP request was made to the API at /admin/clusters.">>},
         {enabled,false},
         {module,n1ql}]},
       {28702,
        [{name,<<"/admin/completed_requests API request">>},
         {description,<<"An HTTP request was made to the API at /admin/completed_requests.">>},
         {enabled,false},
         {module,n1ql}]},
       {32768,
        [{name,<<"Create Function">>},
         {description,<<"Eventing function definition was created or updated">>},
         {enabled,true},
         {module,eventing}]},
       {32769,
        [{name,<<"Delete Function">>},
         {description,<<"Eventing function definition was deleted">>},
         {enabled,true},
         {module,eventing}]},
       {32770,
        [{name,<<"Fetch Functions">>},
         {description,<<"Eventing function definition was read">>},
         {enabled,false},
         {module,eventing}]},
       {32771,
        [{name,<<"List Deployed">>},
         {description,<<"Eventing deployed functions list was read">>},
         {enabled,false},
         {module,eventing}]},
       {32772,
        [{name,<<"Fetch Drafts">>},
         {description,<<"Eventing function draft definitions were read">>},
         {enabled,false},
         {module,eventing}]},
       {32773,
        [{name,<<"Delete Drafts">>},
         {description,<<"Eventing function draft definitions were deleted">>},
         {enabled,true},
         {module,eventing}]},
       {32774,
        [{name,<<"Save Draft">>},
         {description,<<"Save a draft definition to the store">>},
         {enabled,true},
         {module,eventing}]},
       {32775,
        [{name,<<"Start Debug">>},
         {description,<<"Start eventing function debugger">>},
         {enabled,true},
         {module,eventing}]},
       {32776,
        [{name,<<"Stop Debug">>},
         {description,<<"Stop eventing function debugger">>},
         {enabled,true},
         {module,eventing}]},
       {32777,
        [{name,<<"Start Tracing">>},
         {description,<<"Start tracing eventing function execution">>},
         {enabled,true},
         {module,eventing}]},
       {32778,
        [{name,<<"Stop Tracing">>},
         {description,<<"Stop tracing eventing function execution">>},
         {enabled,true},
         {module,eventing}]},
       {32779,
        [{name,<<"Set Settings">>},
         {description,<<"Save settings for a given app">>},
         {enabled,true},
         {module,eventing}]},
       {32780,
        [{name,<<"Fetch Config">>},
         {description,<<"Get config for eventing">>},
         {enabled,false},
         {module,eventing}]},
       {32781,
        [{name,<<"Save Config">>},
         {description,<<"Save config for eventing">>},
         {enabled,true},
         {module,eventing}]},
       {32782,
        [{name,<<"Cleanup Eventing">>},
         {description,<<"Clears up app definitions and settings from metakv">>},
         {enabled,true},
         {module,eventing}]},
       {32783,
        [{name,<<"Get Settings">>},
         {description,<<"Get settings for a given app">>},
         {enabled,false},
         {module,eventing}]},
       {32784,
        [{name,<<"Import Functions">>},
         {description,<<"Import a list of functions">>},
         {enabled,false},
         {module,eventing}]},
       {32785,
        [{name,<<"Export Functions">>},
         {description,<<"Export the list of functions">>},
         {enabled,false},
         {module,eventing}]},
       {32786,
        [{name,<<"List Running">>},
         {description,<<"Eventing running function list was read">>},
         {enabled,false},
         {module,eventing}]},
       {36865,
        [{name,<<"Service configuration change">>},
         {description,<<"A successful service configuration change was made.">>},
         {enabled,true},
         {module,analytics}]},
       {36866,
        [{name,<<"Node configuration change">>},
         {description,<<"A successful node configuration change was made.">>},
         {enabled,true},
         {module,analytics}]}]}]

[ns_server:debug,2019-03-19T15:50:33.826Z,ns_1@127.0.0.1:ns_config_rep<0.267.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([audit,audit_decriptors,auto_failover_cfg,
                               buckets,client_cert_auth,
                               cluster_compat_version,quorum_nodes,
                               read_only_user_creds,roles_definitions,
                               scramsha_fallback_salt,users_upgrade,
                               {local_changes_count,
                                   <<"9bca6fc94f10ac3edc5b102bbb4437b5">>},
                               {metakv,<<"/eventing/settings/config">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {metakv,<<"/query/settings/config">>},
                               {rbac_upgrade,[5,5]},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql}]..)
[ns_server:warn,2019-03-19T15:50:33.827Z,ns_1@127.0.0.1:<0.473.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:33.827Z,ns_1@127.0.0.1:<0.437.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.386.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[ns_server:debug,2019-03-19T15:50:33.828Z,ns_1@127.0.0.1:<0.436.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.386.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:33.833Z,ns_1@127.0.0.1:leader_lease_acquirer<0.454.0>:leader_utils:wait_cluster_is_55_loop:78]Cluster upgraded to 5.5. Starting.
[ns_server:debug,2019-03-19T15:50:33.833Z,ns_1@127.0.0.1:compiled_roles_cache<0.207.0>:versioned_cache:handle_info:89]Flushing cache compiled_roles_cache due to version change from {undefined,
                                                                {0,4241168083},
                                                                false,[]} to {[6,
                                                                               0],
                                                                              {0,
                                                                               4241168083},
                                                                              false,
                                                                              []}
[ns_server:debug,2019-03-19T15:50:33.834Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.456.0>:leader_utils:wait_cluster_is_55_loop:78]Cluster upgraded to 5.5. Starting.
[ns_server:debug,2019-03-19T15:50:33.835Z,ns_1@127.0.0.1:memcached_permissions<0.255.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2019-03-19T15:50:33.835Z,ns_1@127.0.0.1:menelaus_ui_auth<0.322.0>:token_server:handle_cast:202]Purge tokens []
[ns_server:debug,2019-03-19T15:50:33.840Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit_decriptors ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {20480,
  [{name,<<"opened DCP connection">>},
   {description,<<"opened DCP connection">>},
   {enabled,true},
   {module,memcached}]},
 {20482,
  [{name,<<"external memcached bucket flush">>},
   {description,<<"External user flushed the content of a memcached bucket">>},
   {enabled,true},
   {module,memcached}]},
 {20483,
  [{name,<<"invalid packet">>},
   {description,<<"Rejected an invalid packet">>},
   {enabled,true},
   {module,memcached}]},
 {20485,
  [{name,<<"authentication succeeded">>},
   {description,<<"Authentication to the cluster succeeded">>},
   {enabled,false},
   {module,memcached}]},
 {20488,
  [{name,<<"document read">>},
   {description,<<"Document was read">>},
   {enabled,false},
   {module,memcached}]},
 {20489,
  [{name,<<"document locked">>},
   {description,<<"Document was locked">>},
   {enabled,false},
   {module,memcached}]},
 {20490,
  [{name,<<"document modify">>},
   {description,<<"Document was modified">>},
   {enabled,false},
   {module,memcached}]},
 {20491,
  [{name,<<"document delete">>},
   {description,<<"Document was deleted">>},
   {enabled,false},
   {module,memcached}]},
 {20492,
  [{name,<<"select bucket">>},
   {description,<<"The specified bucket was selected">>},
   {enabled,true},
   {module,memcached}]},
 {28672,
  [{name,<<"SELECT statement">>},
   {description,<<"A N1QL SELECT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28673,
  [{name,<<"EXPLAIN statement">>},
   {description,<<"A N1QL EXPLAIN statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28674,
  [{name,<<"PREPARE statement">>},
   {description,<<"A N1QL PREPARE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28675,
  [{name,<<"INFER statement">>},
   {description,<<"A N1QL INFER statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28676,
  [{name,<<"INSERT statement">>},
   {description,<<"A N1QL INSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28677,
  [{name,<<"UPSERT statement">>},
   {description,<<"A N1QL UPSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28678,
  [{name,<<"DELETE statement">>},
   {description,<<"A N1QL DELETE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28679,
  [{name,<<"UPDATE statement">>},
   {description,<<"A N1QL UPDATE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28680,
  [{name,<<"MERGE statement">>},
   {description,<<"A N1QL MERGE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28681,
  [{name,<<"CREATE INDEX statement">>},
   {description,<<"A N1QL CREATE INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28682,
  [{name,<<"DROP INDEX statement">>},
   {description,<<"A N1QL DROP INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28683,
  [{name,<<"ALTER INDEX statement">>},
   {description,<<"A N1QL ALTER INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28684,
  [{name,<<"BUILD INDEX statement">>},
   {description,<<"A N1QL BUILD INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28685,
  [{name,<<"GRANT ROLE statement">>},
   {description,<<"A N1QL GRANT ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28686,
  [{name,<<"REVOKE ROLE statement">>},
   {description,<<"A N1QL REVOKE ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28687,
  [{name,<<"UNRECOGNIZED statement">>},
   {description,<<"An unrecognized statement was received by the N1QL query engine">>},
   {enabled,false},
   {module,n1ql}]},
 {28688,
  [{name,<<"CREATE PRIMARY INDEX statement">>},
   {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28689,
  [{name,<<"/admin/stats API request">>},
   {description,<<"An HTTP request was made to the API at /admin/stats.">>},
   {enabled,false},
   {module,n1ql}]},
 {28690,
  [{name,<<"/admin/vitals API request">>},
   {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
   {enabled,false},
   {module,n1ql}]},
 {28691,
  [{name,<<"/admin/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28692,
  [{name,<<"/admin/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28693,
  [{name,<<"/admin/indexes/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28694,
  [{name,<<"/admin/indexes/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28695,
  [{name,<<"/admin/indexes/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28697,
  [{name,<<"/admin/ping API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ping.">>},
   {enabled,false},
   {module,n1ql}]},
 {28698,
  [{name,<<"/admin/config API request">>},
   {description,<<"An HTTP request was made to the API at /admin/config.">>},
   {enabled,false},
   {module,n1ql}]},
 {28699,
  [{name,<<"/admin/ssl_cert API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ssl_cert.">>},
   {enabled,false},
   {module,n1ql}]},
 {28700,
  [{name,<<"/admin/settings API request">>},
   {description,<<"An HTTP request was made to the API at /admin/settings.">>},
   {enabled,false},
   {module,n1ql}]},
 {28701,
  [{name,<<"/admin/clusters API request">>},
   {description,<<"An HTTP request was made to the API at /admin/clusters.">>},
   {enabled,false},
   {module,n1ql}]},
 {28702,
  [{name,<<"/admin/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {32768,
  [{name,<<"Create Function">>},
   {description,<<"Eventing function definition was created or updated">>},
   {enabled,true},
   {module,eventing}]},
 {32769,
  [{name,<<"Delete Function">>},
   {description,<<"Eventing function definition was deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32770,
  [{name,<<"Fetch Functions">>},
   {description,<<"Eventing function definition was read">>},
   {enabled,false},
   {module,eventing}]},
 {32771,
  [{name,<<"List Deployed">>},
   {description,<<"Eventing deployed functions list was read">>},
   {enabled,false},
   {module,eventing}]},
 {32772,
  [{name,<<"Fetch Drafts">>},
   {description,<<"Eventing function draft definitions were read">>},
   {enabled,false},
   {module,eventing}]},
 {32773,
  [{name,<<"Delete Drafts">>},
   {description,<<"Eventing function draft definitions were deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32774,
  [{name,<<"Save Draft">>},
   {description,<<"Save a draft definition to the store">>},
   {enabled,true},
   {module,eventing}]},
 {32775,
  [{name,<<"Start Debug">>},
   {description,<<"Start eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32776,
  [{name,<<"Stop Debug">>},
   {description,<<"Stop eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32777,
  [{name,<<"Start Tracing">>},
   {description,<<"Start tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32778,
  [{name,<<"Stop Tracing">>},
   {description,<<"Stop tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32779,
  [{name,<<"Set Settings">>},
   {description,<<"Save settings for a given app">>},
   {enabled,true},
   {module,eventing}]},
 {32780,
  [{name,<<"Fetch Config">>},
   {description,<<"Get config for eventing">>},
   {enabled,false},
   {module,eventing}]},
 {32781,
  [{name,<<"Save Config">>},
   {description,<<"Save config for eventing">>},
   {enabled,true},
   {module,eventing}]},
 {32782,
  [{name,<<"Cleanup Eventing">>},
   {description,<<"Clears up app definitions and settings from metakv">>},
   {enabled,true},
   {module,eventing}]},
 {32783,
  [{name,<<"Get Settings">>},
   {description,<<"Get settings for a given app">>},
   {enabled,false},
   {module,eventing}]},
 {32784,
  [{name,<<"Import Functions">>},
   {description,<<"Import a list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32785,
  [{name,<<"Export Functions">>},
   {description,<<"Export the list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32786,
  [{name,<<"List Running">>},
   {description,<<"Eventing running function list was read">>},
   {enabled,false},
   {module,eventing}]},
 {36865,
  [{name,<<"Service configuration change">>},
   {description,<<"A successful service configuration change was made.">>},
   {enabled,true},
   {module,analytics}]},
 {36866,
  [{name,<<"Node configuration change">>},
   {description,<<"A successful node configuration change was made.">>},
   {enabled,true},
   {module,analytics}]}]
[ns_server:debug,2019-03-19T15:50:33.840Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
scramsha_fallback_salt ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 <<153,243,183,226,93,180,216,77,176,217,18,64>>]
[ns_server:debug,2019-03-19T15:50:33.840Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{rbac_upgrade,[5,5]} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 '_deleted']
[ns_server:debug,2019-03-19T15:50:33.840Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/eventing/settings/config">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 <<"{\"ram_quota\":256}">>]
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/query/settings/config">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
client_cert_auth ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {state,"disable"},
 {prefixes,[]}]
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
users_upgrade ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 '_deleted']
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
roles_definitions ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 '_deleted']
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,fts} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}]
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,index} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}]
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}]
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cluster_compat_version ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{8,63720229833}}]},6,0]
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {enabled,[]},
 {disabled_users,[]},
 {auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
buckets ->
[[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{3,63720229833}}],{configs,[]}]
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
quorum_nodes ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2019-03-19T15:50:33.841Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
read_only_user_creds ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 '_deleted']
[ns_server:debug,2019-03-19T15:50:33.842Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2019-03-19T15:50:33.842Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"9bca6fc94f10ac3edc5b102bbb4437b5">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{3,63720229833}}]}]
[ns_server:debug,2019-03-19T15:50:33.842Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.456.0>:leader_quorum_nodes_manager:pull_config:114]Attempting to pull config from nodes:
[]
[ns_server:debug,2019-03-19T15:50:33.842Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_dets:handle_call:354]Suspended by process <0.255.0>
[ns_server:debug,2019-03-19T15:50:33.842Z,ns_1@127.0.0.1:memcached_permissions<0.255.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{user,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2019-03-19T15:50:33.842Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.456.0>:leader_quorum_nodes_manager:pull_config:119]Pulled config successfully.
[ns_server:debug,2019-03-19T15:50:33.842Z,ns_1@127.0.0.1:ns_config_rep<0.267.0>:ns_config_rep:handle_call:116]Got full synchronization request from 'ns_1@127.0.0.1'
[ns_server:debug,2019-03-19T15:50:33.842Z,ns_1@127.0.0.1:ns_config_rep<0.267.0>:ns_config_rep:handle_call:122]Fully synchronized config in 7 us
[user:warn,2019-03-19T15:50:33.842Z,ns_1@127.0.0.1:<0.463.0>:ns_orchestrator:consider_switching_compat_mode_dont_exit:925]Changed cluster compat mode from undefined to [6,0]
[ns_server:debug,2019-03-19T15:50:33.842Z,ns_1@127.0.0.1:users_storage<0.205.0>:replicated_dets:handle_call:361]Released by process <0.255.0>
[ns_server:info,2019-03-19T15:50:33.845Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.460.0>:misc:start_singleton:756]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.463.0> on 'ns_1@127.0.0.1'

[error_logger:error,2019-03-19T15:50:33.845Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.472.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:33.845Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.386.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:33.846Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.386.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.437.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 26639
  neighbours:

[error_logger:error,2019-03-19T15:50:33.846Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.473.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[error_logger:info,2019-03-19T15:50:33.849Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.463.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.849Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.460.0>},
                       {name,ns_orchestrator_child_sup},
                       {mfargs,{ns_orchestrator_child_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2019-03-19T15:50:33.853Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of rbac requested
[ns_server:warn,2019-03-19T15:50:33.866Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:33.866Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[ns_server:debug,2019-03-19T15:50:33.874Z,ns_1@127.0.0.1:<0.490.0>:auto_failover:init:211]init auto_failover.
[user:info,2019-03-19T15:50:33.874Z,ns_1@127.0.0.1:<0.490.0>:auto_failover:handle_call:242]Enabled auto-failover with timeout 120 and max count 1
[ns_server:debug,2019-03-19T15:50:33.875Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:514]Notify services [ssl_service,capi_ssl_service] about client_cert_auth change
[ns_server:debug,2019-03-19T15:50:33.875Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:525]Going to notify following services: [capi_ssl_service,ssl_service]
[ns_server:debug,2019-03-19T15:50:33.875Z,ns_1@127.0.0.1:<0.183.0>:restartable:loop:71]Restarting child <0.184.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
  Shutdown policy: 1000
  Caller: {<0.498.0>,#Ref<0.0.0.1662>}
[ns_server:debug,2019-03-19T15:50:33.875Z,ns_1@127.0.0.1:<0.183.0>:restartable:shutdown_child:120]Successfully terminated process <0.184.0>
[ns_server:info,2019-03-19T15:50:33.881Z,ns_1@127.0.0.1:<0.497.0>:ns_ssl_services_setup:notify_service:702]Successfully notified service capi_ssl_service
[ns_server:debug,2019-03-19T15:50:33.892Z,ns_1@127.0.0.1:leader_lease_agent<0.445.0>:leader_lease_agent:do_handle_acquire_lease:147]Granting lease to {lease_holder,<<"bcc4ea163e3b9013bc2d5d4fb73a72db">>,
                                'ns_1@127.0.0.1'} for 15000ms
[ns_server:debug,2019-03-19T15:50:33.895Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"9bca6fc94f10ac3edc5b102bbb4437b5">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{4,63720229833}}]}]
[ns_server:debug,2019-03-19T15:50:33.895Z,ns_1@127.0.0.1:ns_config_rep<0.267.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([auto_failover_cfg,
                               {local_changes_count,
                                   <<"9bca6fc94f10ac3edc5b102bbb4437b5">>}]..)
[ns_server:info,2019-03-19T15:50:33.895Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.459.0>:misc:start_singleton:756]start_singleton(gen_server, auto_failover, [], []): started as <0.490.0> on 'ns_1@127.0.0.1'

[ns_server:debug,2019-03-19T15:50:33.895Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:debug,2019-03-19T15:50:33.896Z,ns_1@127.0.0.1:<0.441.0>:restartable:start_child:98]Started child process <0.442.0>
  MFA: {leader_services_sup,start_link,[]}
[error_logger:info,2019-03-19T15:50:33.895Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.490.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.896Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.459.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.896Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.451.0>},
                       {name,mb_master},
                       {mfargs,{mb_master,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.897Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.446.0>},
                       {name,leader_registry_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_registry_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.897Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.441.0>},
                       {name,leader_services_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{leader_services_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.897Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.508.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.897Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.509.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:33.898Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2019-03-19T15:50:33.899Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2019-03-19T15:50:33.899Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2019-03-19T15:50:33.900Z,ns_1@127.0.0.1:<0.183.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[ns_server:debug,2019-03-19T15:50:33.901Z,ns_1@127.0.0.1:<0.183.0>:restartable:start_child:98]Started child process <0.510.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[ns_server:info,2019-03-19T15:50:33.901Z,ns_1@127.0.0.1:<0.498.0>:ns_ssl_services_setup:notify_service:702]Successfully notified service ssl_service
[ns_server:info,2019-03-19T15:50:33.901Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:handle_info:541]Succesfully notified services [ssl_service,capi_ssl_service]
[error_logger:info,2019-03-19T15:50:33.907Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.527.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.918Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.528.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2019-03-19T15:50:33.930Z,ns_1@127.0.0.1:<0.489.0>:leader_lease_acquire_worker:handle_fresh_lease_acquired:302]Acquired lease from node 'ns_1@127.0.0.1' (lease uuid: <<"bcc4ea163e3b9013bc2d5d4fb73a72db">>)
[error_logger:info,2019-03-19T15:50:33.943Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.531.0>},
                       {name,ns_server_monitor},
                       {mfargs,{ns_server_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.943Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.533.0>},
                       {name,service_monitor_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_monitor_children_sup},
                                health_monitor_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.944Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.534.0>},
                       {name,service_monitor_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<health_monitor_sup.0.81875396>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.950Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.542.0>},
                       {name,node_monitor},
                       {mfargs,{node_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.952Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.550.0>},
                       {name,node_status_analyzer},
                       {mfargs,{node_status_analyzer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.953Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[error_logger:info,2019-03-19T15:50:33.953Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.530.0>},
                       {name,health_monitor_sup},
                       {mfargs,{health_monitor_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2019-03-19T15:50:33.953Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.169.0>
[error_logger:error,2019-03-19T15:50:33.953Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.386.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[ns_server:debug,2019-03-19T15:50:33.953Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2019-03-19T15:50:33.953Z,ns_1@127.0.0.1:memcached_config_mgr<0.552.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:error,2019-03-19T15:50:33.953Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.386.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:33.953Z,ns_1@127.0.0.1:memcached_config_mgr<0.552.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2019-03-19T15:50:33.953Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.245.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2019-03-19T15:50:33.953Z,ns_1@127.0.0.1:<0.168.0>:restartable:start_child:98]Started child process <0.169.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2019-03-19T15:50:33.953Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.552.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T15:50:33.953Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.168.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T15:50:33.954Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2019-03-19T15:50:33.954Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:130]138: Entered child_loop
[ns_server:debug,2019-03-19T15:50:33.954Z,ns_1@127.0.0.1:memcached_config_mgr<0.552.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:33.957Z,ns_1@127.0.0.1:memcached_config_mgr<0.552.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:33.960Z,ns_1@127.0.0.1:memcached_config_mgr<0.552.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:33.961Z,ns_1@127.0.0.1:<0.556.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:33.961Z,ns_1@127.0.0.1:<0.553.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.552.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:33.961Z,ns_1@127.0.0.1:<0.554.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.552.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[error_logger:error,2019-03-19T15:50:33.961Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.555.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 143
  neighbours:

[error_logger:error,2019-03-19T15:50:33.962Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.552.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:33.962Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.552.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.554.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19090
  neighbours:

[error_logger:error,2019-03-19T15:50:33.962Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.552.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:33.962Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.552.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:33.962Z,ns_1@127.0.0.1:memcached_config_mgr<0.557.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:33.962Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.557.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.962Z,ns_1@127.0.0.1:memcached_config_mgr<0.557.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2019-03-19T15:50:33.963Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.556.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:33.963Z,ns_1@127.0.0.1:memcached_config_mgr<0.557.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:33.964Z,ns_1@127.0.0.1:memcached_config_mgr<0.557.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:33.967Z,ns_1@127.0.0.1:memcached_config_mgr<0.557.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:33.976Z,ns_1@127.0.0.1:<0.561.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:33.976Z,ns_1@127.0.0.1:<0.558.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.557.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:33.976Z,ns_1@127.0.0.1:<0.559.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.557.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[error_logger:error,2019-03-19T15:50:33.976Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.561.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[error_logger:error,2019-03-19T15:50:33.977Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.560.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:33.977Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.557.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:33.977Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.557.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.559.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 18954
  neighbours:

[error_logger:error,2019-03-19T15:50:33.977Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.557.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:33.977Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.557.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:33.978Z,ns_1@127.0.0.1:memcached_config_mgr<0.562.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:33.978Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.562.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:33.978Z,ns_1@127.0.0.1:memcached_config_mgr<0.562.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2019-03-19T15:50:33.986Z,ns_1@127.0.0.1:memcached_config_mgr<0.562.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:33.987Z,ns_1@127.0.0.1:memcached_config_mgr<0.562.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:33.991Z,ns_1@127.0.0.1:memcached_config_mgr<0.562.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:33.992Z,ns_1@127.0.0.1:<0.566.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2019-03-19T15:50:33.992Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.565.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[ns_server:debug,2019-03-19T15:50:33.992Z,ns_1@127.0.0.1:<0.563.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.562.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[error_logger:error,2019-03-19T15:50:33.992Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.562.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:33.993Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.562.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.564.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19011
  neighbours:

[error_logger:error,2019-03-19T15:50:33.993Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.562.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:33.993Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.562.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:33.993Z,ns_1@127.0.0.1:<0.564.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.562.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[ns_server:debug,2019-03-19T15:50:33.993Z,ns_1@127.0.0.1:memcached_config_mgr<0.567.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2019-03-19T15:50:33.993Z,ns_1@127.0.0.1:memcached_config_mgr<0.567.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2019-03-19T15:50:33.993Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.567.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:error,2019-03-19T15:50:33.993Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.566.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:33.994Z,ns_1@127.0.0.1:memcached_config_mgr<0.567.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:33.995Z,ns_1@127.0.0.1:memcached_config_mgr<0.567.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:33.997Z,ns_1@127.0.0.1:memcached_config_mgr<0.567.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:33.998Z,ns_1@127.0.0.1:<0.571.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2019-03-19T15:50:33.998Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.571.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[error_logger:error,2019-03-19T15:50:33.998Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.570.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 143
  neighbours:

[error_logger:error,2019-03-19T15:50:33.999Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.567.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:33.999Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.567.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.569.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 18944
  neighbours:

[error_logger:error,2019-03-19T15:50:33.999Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.567.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:33.999Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.567.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:33.999Z,ns_1@127.0.0.1:<0.569.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.567.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[ns_server:debug,2019-03-19T15:50:33.999Z,ns_1@127.0.0.1:<0.568.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.567.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.000Z,ns_1@127.0.0.1:memcached_config_mgr<0.572.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:34.000Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.572.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.000Z,ns_1@127.0.0.1:memcached_config_mgr<0.572.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2019-03-19T15:50:34.000Z,ns_1@127.0.0.1:memcached_config_mgr<0.572.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.001Z,ns_1@127.0.0.1:memcached_config_mgr<0.572.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.003Z,ns_1@127.0.0.1:memcached_config_mgr<0.572.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.004Z,ns_1@127.0.0.1:<0.576.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2019-03-19T15:50:34.004Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.576.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[error_logger:error,2019-03-19T15:50:34.004Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.575.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:34.005Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.572.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.005Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.572.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.574.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 18969
  neighbours:

[error_logger:error,2019-03-19T15:50:34.005Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.572.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.005Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.572.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:34.005Z,ns_1@127.0.0.1:<0.574.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.572.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[ns_server:debug,2019-03-19T15:50:34.005Z,ns_1@127.0.0.1:<0.573.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.572.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.005Z,ns_1@127.0.0.1:memcached_config_mgr<0.577.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:34.006Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.577.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.006Z,ns_1@127.0.0.1:memcached_config_mgr<0.577.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2019-03-19T15:50:34.006Z,ns_1@127.0.0.1:memcached_config_mgr<0.577.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.007Z,ns_1@127.0.0.1:memcached_config_mgr<0.577.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.011Z,ns_1@127.0.0.1:memcached_config_mgr<0.577.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.011Z,ns_1@127.0.0.1:<0.581.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.011Z,ns_1@127.0.0.1:<0.578.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.577.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.011Z,ns_1@127.0.0.1:<0.579.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.577.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[error_logger:error,2019-03-19T15:50:34.012Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.580.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 143
  neighbours:

[error_logger:error,2019-03-19T15:50:34.012Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.577.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.012Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.577.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.579.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 18973
  neighbours:

[error_logger:error,2019-03-19T15:50:34.012Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.577.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.012Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.577.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:34.013Z,ns_1@127.0.0.1:memcached_config_mgr<0.582.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:34.013Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.582.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.013Z,ns_1@127.0.0.1:memcached_config_mgr<0.582.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2019-03-19T15:50:34.013Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.581.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:34.013Z,ns_1@127.0.0.1:memcached_config_mgr<0.582.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.014Z,ns_1@127.0.0.1:memcached_config_mgr<0.582.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.017Z,ns_1@127.0.0.1:memcached_config_mgr<0.582.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.018Z,ns_1@127.0.0.1:<0.586.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.018Z,ns_1@127.0.0.1:<0.583.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.582.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.018Z,ns_1@127.0.0.1:<0.584.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.582.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[error_logger:error,2019-03-19T15:50:34.019Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.586.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[error_logger:error,2019-03-19T15:50:34.019Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.585.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:34.019Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.582.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.019Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.582.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.584.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 18981
  neighbours:

[error_logger:error,2019-03-19T15:50:34.019Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.582.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.020Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.582.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:34.020Z,ns_1@127.0.0.1:memcached_config_mgr<0.587.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:34.020Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.587.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.020Z,ns_1@127.0.0.1:memcached_config_mgr<0.587.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2019-03-19T15:50:34.020Z,ns_1@127.0.0.1:memcached_config_mgr<0.587.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.021Z,ns_1@127.0.0.1:memcached_config_mgr<0.587.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.023Z,ns_1@127.0.0.1:memcached_config_mgr<0.587.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.036Z,ns_1@127.0.0.1:<0.591.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.036Z,ns_1@127.0.0.1:<0.588.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.587.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.036Z,ns_1@127.0.0.1:<0.589.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.587.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[error_logger:error,2019-03-19T15:50:34.037Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.590.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 143
  neighbours:

[error_logger:error,2019-03-19T15:50:34.037Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.587.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.037Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.587.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.589.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 18977
  neighbours:

[error_logger:error,2019-03-19T15:50:34.037Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.587.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.037Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.587.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:34.037Z,ns_1@127.0.0.1:memcached_config_mgr<0.592.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:34.038Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.592.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.038Z,ns_1@127.0.0.1:memcached_config_mgr<0.592.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2019-03-19T15:50:34.038Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.591.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:34.038Z,ns_1@127.0.0.1:memcached_config_mgr<0.592.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.039Z,ns_1@127.0.0.1:memcached_config_mgr<0.592.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.043Z,ns_1@127.0.0.1:memcached_config_mgr<0.592.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.044Z,ns_1@127.0.0.1:<0.596.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.044Z,ns_1@127.0.0.1:<0.593.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.592.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.044Z,ns_1@127.0.0.1:<0.594.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.592.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[error_logger:error,2019-03-19T15:50:34.044Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.595.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:34.044Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.592.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.045Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.592.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.594.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19037
  neighbours:

[error_logger:error,2019-03-19T15:50:34.045Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.592.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.045Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.592.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:34.045Z,ns_1@127.0.0.1:memcached_config_mgr<0.597.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:34.045Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.597.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.045Z,ns_1@127.0.0.1:memcached_config_mgr<0.597.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2019-03-19T15:50:34.046Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.596.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:34.046Z,ns_1@127.0.0.1:memcached_config_mgr<0.597.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.047Z,ns_1@127.0.0.1:memcached_config_mgr<0.597.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.050Z,ns_1@127.0.0.1:memcached_config_mgr<0.597.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.051Z,ns_1@127.0.0.1:<0.601.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2019-03-19T15:50:34.051Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.600.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:34.052Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.597.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.052Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.597.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.599.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19024
  neighbours:

[error_logger:error,2019-03-19T15:50:34.052Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.597.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.052Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.597.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:34.052Z,ns_1@127.0.0.1:<0.599.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.597.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[ns_server:debug,2019-03-19T15:50:34.052Z,ns_1@127.0.0.1:<0.598.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.597.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[error_logger:error,2019-03-19T15:50:34.053Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.601.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:34.053Z,ns_1@127.0.0.1:memcached_config_mgr<0.602.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:34.053Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.602.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.053Z,ns_1@127.0.0.1:memcached_config_mgr<0.602.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2019-03-19T15:50:34.053Z,ns_1@127.0.0.1:memcached_config_mgr<0.602.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.054Z,ns_1@127.0.0.1:memcached_config_mgr<0.602.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.058Z,ns_1@127.0.0.1:memcached_config_mgr<0.602.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.059Z,ns_1@127.0.0.1:<0.606.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2019-03-19T15:50:34.059Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.605.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:34.059Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.602.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.060Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.602.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.604.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 18973
  neighbours:

[error_logger:error,2019-03-19T15:50:34.060Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.602.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.060Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.602.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:34.060Z,ns_1@127.0.0.1:<0.604.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.602.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[ns_server:debug,2019-03-19T15:50:34.060Z,ns_1@127.0.0.1:<0.603.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.602.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[error_logger:error,2019-03-19T15:50:34.061Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.606.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:34.061Z,ns_1@127.0.0.1:memcached_config_mgr<0.607.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2019-03-19T15:50:34.061Z,ns_1@127.0.0.1:memcached_config_mgr<0.607.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2019-03-19T15:50:34.061Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.607.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.061Z,ns_1@127.0.0.1:memcached_config_mgr<0.607.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.063Z,ns_1@127.0.0.1:memcached_config_mgr<0.607.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.065Z,ns_1@127.0.0.1:memcached_config_mgr<0.607.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.066Z,ns_1@127.0.0.1:<0.611.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.066Z,ns_1@127.0.0.1:<0.609.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.607.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[error_logger:error,2019-03-19T15:50:34.066Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.611.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[error_logger:error,2019-03-19T15:50:34.067Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.610.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:34.067Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.607.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.067Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.607.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.609.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19000
  neighbours:

[error_logger:error,2019-03-19T15:50:34.067Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.607.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[ns_server:debug,2019-03-19T15:50:34.067Z,ns_1@127.0.0.1:memcached_config_mgr<0.612.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:error,2019-03-19T15:50:34.067Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.607.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2019-03-19T15:50:34.067Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.612.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.068Z,ns_1@127.0.0.1:<0.608.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.607.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.068Z,ns_1@127.0.0.1:memcached_config_mgr<0.612.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2019-03-19T15:50:34.068Z,ns_1@127.0.0.1:memcached_config_mgr<0.612.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.069Z,ns_1@127.0.0.1:memcached_config_mgr<0.612.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.071Z,ns_1@127.0.0.1:memcached_config_mgr<0.612.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.072Z,ns_1@127.0.0.1:<0.616.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2019-03-19T15:50:34.072Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.616.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[error_logger:error,2019-03-19T15:50:34.072Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.615.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:34.072Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.612.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[ns_server:debug,2019-03-19T15:50:34.074Z,ns_1@127.0.0.1:<0.613.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.612.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.074Z,ns_1@127.0.0.1:<0.614.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.612.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[ns_server:debug,2019-03-19T15:50:34.074Z,ns_1@127.0.0.1:memcached_config_mgr<0.617.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2019-03-19T15:50:34.074Z,ns_1@127.0.0.1:memcached_config_mgr<0.617.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2019-03-19T15:50:34.074Z,ns_1@127.0.0.1:memcached_config_mgr<0.617.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.086Z,ns_1@127.0.0.1:memcached_config_mgr<0.617.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[error_logger:error,2019-03-19T15:50:34.087Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.612.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.614.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 18975
  neighbours:

[ns_server:warn,2019-03-19T15:50:34.088Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.088Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:error,2019-03-19T15:50:34.087Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.612.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.088Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.612.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2019-03-19T15:50:34.088Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.617.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.088Z,ns_1@127.0.0.1:memcached_config_mgr<0.617.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.097Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.097Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[ns_server:warn,2019-03-19T15:50:34.097Z,ns_1@127.0.0.1:<0.621.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.097Z,ns_1@127.0.0.1:<0.618.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.617.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.097Z,ns_1@127.0.0.1:<0.619.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.617.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[ns_server:debug,2019-03-19T15:50:34.098Z,ns_1@127.0.0.1:memcached_config_mgr<0.622.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2019-03-19T15:50:34.098Z,ns_1@127.0.0.1:memcached_config_mgr<0.622.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2019-03-19T15:50:34.098Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.621.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:34.099Z,ns_1@127.0.0.1:memcached_config_mgr<0.622.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[error_logger:error,2019-03-19T15:50:34.099Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.620.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:34.099Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.617.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.100Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.617.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.619.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19113
  neighbours:

[error_logger:error,2019-03-19T15:50:34.100Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.617.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.100Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.617.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2019-03-19T15:50:34.101Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.622.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.101Z,ns_1@127.0.0.1:memcached_config_mgr<0.622.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.105Z,ns_1@127.0.0.1:memcached_config_mgr<0.622.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.106Z,ns_1@127.0.0.1:<0.626.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.106Z,ns_1@127.0.0.1:<0.623.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.622.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.106Z,ns_1@127.0.0.1:<0.624.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.622.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[ns_server:debug,2019-03-19T15:50:34.106Z,ns_1@127.0.0.1:memcached_config_mgr<0.627.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2019-03-19T15:50:34.106Z,ns_1@127.0.0.1:memcached_config_mgr<0.627.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2019-03-19T15:50:34.106Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.625.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:34.107Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.622.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.107Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.622.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.624.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19125
  neighbours:

[error_logger:error,2019-03-19T15:50:34.107Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.622.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.107Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.622.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2019-03-19T15:50:34.108Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.627.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:error,2019-03-19T15:50:34.108Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.626.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:34.108Z,ns_1@127.0.0.1:memcached_config_mgr<0.627.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.109Z,ns_1@127.0.0.1:memcached_config_mgr<0.627.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.113Z,ns_1@127.0.0.1:memcached_config_mgr<0.627.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.114Z,ns_1@127.0.0.1:<0.631.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.114Z,ns_1@127.0.0.1:<0.629.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.627.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[ns_server:debug,2019-03-19T15:50:34.114Z,ns_1@127.0.0.1:memcached_config_mgr<0.632.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2019-03-19T15:50:34.114Z,ns_1@127.0.0.1:memcached_config_mgr<0.632.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2019-03-19T15:50:34.114Z,ns_1@127.0.0.1:<0.628.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.627.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[error_logger:error,2019-03-19T15:50:34.115Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.630.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:34.115Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.627.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.115Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.627.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.629.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 18948
  neighbours:

[error_logger:error,2019-03-19T15:50:34.115Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.627.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.115Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.627.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:info,2019-03-19T15:50:34.115Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.632.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:error,2019-03-19T15:50:34.115Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.631.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:34.116Z,ns_1@127.0.0.1:memcached_config_mgr<0.632.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.117Z,ns_1@127.0.0.1:memcached_config_mgr<0.632.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.119Z,ns_1@127.0.0.1:memcached_config_mgr<0.632.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.120Z,ns_1@127.0.0.1:<0.636.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.120Z,ns_1@127.0.0.1:<0.633.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.632.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.120Z,ns_1@127.0.0.1:<0.634.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.632.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[error_logger:error,2019-03-19T15:50:34.120Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.635.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 143
  neighbours:

[error_logger:error,2019-03-19T15:50:34.120Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.632.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.121Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.632.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.634.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 19090
  neighbours:

[error_logger:error,2019-03-19T15:50:34.121Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.632.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.121Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.632.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:34.121Z,ns_1@127.0.0.1:memcached_config_mgr<0.637.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:34.121Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.637.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.121Z,ns_1@127.0.0.1:memcached_config_mgr<0.637.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:error,2019-03-19T15:50:34.122Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.636.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:34.122Z,ns_1@127.0.0.1:memcached_config_mgr<0.637.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.123Z,ns_1@127.0.0.1:memcached_config_mgr<0.637.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.126Z,ns_1@127.0.0.1:memcached_config_mgr<0.637.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.127Z,ns_1@127.0.0.1:<0.641.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.127Z,ns_1@127.0.0.1:<0.638.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.637.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.127Z,ns_1@127.0.0.1:<0.639.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.637.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[error_logger:error,2019-03-19T15:50:34.127Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.641.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[error_logger:error,2019-03-19T15:50:34.127Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.640.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:34.127Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.637.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.128Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.637.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.639.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 18953
  neighbours:

[error_logger:error,2019-03-19T15:50:34.128Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.637.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.128Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.637.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:34.128Z,ns_1@127.0.0.1:memcached_config_mgr<0.642.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:34.128Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.642.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.128Z,ns_1@127.0.0.1:memcached_config_mgr<0.642.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2019-03-19T15:50:34.129Z,ns_1@127.0.0.1:memcached_config_mgr<0.642.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.130Z,ns_1@127.0.0.1:memcached_config_mgr<0.642.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.134Z,ns_1@127.0.0.1:memcached_config_mgr<0.642.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.135Z,ns_1@127.0.0.1:<0.646.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2019-03-19T15:50:34.135Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.645.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[ns_server:debug,2019-03-19T15:50:34.135Z,ns_1@127.0.0.1:<0.643.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.642.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[ns_server:debug,2019-03-19T15:50:34.135Z,ns_1@127.0.0.1:<0.644.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.642.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[error_logger:error,2019-03-19T15:50:34.135Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.642.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.136Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.642.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.644.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 18963
  neighbours:

[error_logger:error,2019-03-19T15:50:34.136Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.642.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.136Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.642.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[error_logger:error,2019-03-19T15:50:34.136Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.646.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:34.136Z,ns_1@127.0.0.1:memcached_config_mgr<0.647.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T15:50:34.136Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.647.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:34.136Z,ns_1@127.0.0.1:memcached_config_mgr<0.647.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2019-03-19T15:50:34.137Z,ns_1@127.0.0.1:memcached_config_mgr<0.647.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:34.138Z,ns_1@127.0.0.1:memcached_config_mgr<0.647.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:34.140Z,ns_1@127.0.0.1:memcached_config_mgr<0.647.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:warn,2019-03-19T15:50:34.141Z,ns_1@127.0.0.1:<0.651.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[error_logger:error,2019-03-19T15:50:34.141Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: async:-start/2-fun-0-/0
    pid: <0.650.0>
    registered_name: []
    exception exit: {raised,
                        {error,
                            {badmatch,{error,couldnt_connect_to_memcached}},
                            [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                             {async,'-async_init/4-fun-2-',3,
                                 [{file,"src/async.erl"},{line,208}]}]}}
      in function  async:handle_get_result/2 (src/async.erl, line 339)
    ancestors: [memcached_config_mgr,ns_server_sup,ns_server_nodes_sup,
                  <0.168.0>,ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: []
    dictionary: [{'$async_role',controller}]
    trap_exit: true
    status: running
    heap_size: 610
    stack_size: 27
    reductions: 149
  neighbours:

[error_logger:error,2019-03-19T15:50:34.141Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]** Generic server <0.647.0> terminating 
** Last message in was do_check
** When Server state == {state,<12400.81.0>,
                               <<"{\n  \"admin\": \"@ns_server\",\n  \"audit_file\": \"/opt/couchbase/var/lib/couchbase/config/audit.json\",\n  \"breakpad\": {\n    \"enabled\": true,\n    \"minidump_dir\": \"/opt/couchbase/var/lib/couchbase/crash\"\n  },\n  \"client_cert_auth\": {\n    \"state\": \"disable\"\n  },\n  \"connection_idle_time\": 0,\n  \"datatype_snappy\": false,\n  \"dedupe_nmvb_maps\": false,\n  \"interfaces\": [\n    {\n      \"host\": \"*\",\n      \"port\": 11210,\n      \"maxconn\": 30000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11209,\n      \"maxconn\": 5000,\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    },\n    {\n      \"host\": \"*\",\n      \"port\": 11207,\n      \"maxconn\": 30000,\n      \"ssl\": {\n        \"key\": \"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem\",\n        \"cert\": \"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem\"\n      },\n      \"ipv4\": \"required\",\n      \"ipv6\": \"optional\"\n    }\n  ],\n  \"logger\": {\n    \"filename\": \"/opt/couchbase/var/lib/couchbase/logs/memcached.log\",\n    \"cyclesize\": 10485760,\n    \"sleeptime\": 19\n  },\n  \"privilege_debug\": false,\n  \"rbac_file\": \"/opt/couchbase/var/lib/couchbase/config/memcached.rbac\",\n  \"root\": \"/opt/couchbase\",\n  \"scramsha_fallback_salt\": \"c2FsdA==\",\n  \"ssl_cipher_list\": \"HIGH\",\n  \"ssl_minimum_protocol\": \"tlsv1\",\n  \"tracing_enabled\": true,\n  \"verbosity\": 0,\n  \"xattr_enabled\": false\n}\n">>}
** Reason for termination == 
** {{badmatch,{error,couldnt_connect_to_memcached}},
    [{ns_memcached,'-config_validate/1-fun-0-',1,
                   [{file,"src/ns_memcached.erl"},{line,1474}]},
     {async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}

[error_logger:error,2019-03-19T15:50:34.142Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================CRASH REPORT=========================
  crasher:
    initial call: memcached_config_mgr:init/1
    pid: <0.647.0>
    registered_name: []
    exception exit: {{badmatch,{error,couldnt_connect_to_memcached}},
                     [{ns_memcached,'-config_validate/1-fun-0-',1,
                                    [{file,"src/ns_memcached.erl"},
                                     {line,1474}]},
                      {async,'-async_init/4-fun-2-',3,
                             [{file,"src/async.erl"},{line,208}]}]}
      in function  gen_server:init_it/6 (gen_server.erl, line 328)
    ancestors: [ns_server_sup,ns_server_nodes_sup,<0.168.0>,
                  ns_server_cluster_sup,<0.89.0>]
    messages: []
    links: [<0.245.0>,<0.649.0>]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 6772
    stack_size: 27
    reductions: 18945
  neighbours:

[error_logger:error,2019-03-19T15:50:34.142Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.647.0>,
                                         {error,
                                          {{badmatch,
                                            {error,
                                             couldnt_connect_to_memcached}},
                                           [{ns_memcached,
                                             '-config_validate/1-fun-0-',1,
                                             [{file,"src/ns_memcached.erl"},
                                              {line,1474}]},
                                            {async,'-async_init/4-fun-2-',3,
                                             [{file,"src/async.erl"},
                                              {line,208}]}]}}}

[error_logger:error,2019-03-19T15:50:34.142Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================SUPERVISOR REPORT=========================
     Supervisor: {local,ns_server_sup}
     Context:    child_terminated
     Reason:     {{badmatch,{error,couldnt_connect_to_memcached}},
                  [{ns_memcached,'-config_validate/1-fun-0-',1,
                                 [{file,"src/ns_memcached.erl"},{line,1474}]},
                   {async,'-async_init/4-fun-2-',3,
                          [{file,"src/async.erl"},{line,208}]}]}
     Offender:   [{pid,<0.647.0>},
                  {name,memcached_config_mgr},
                  {mfargs,{memcached_config_mgr,start_link,[]}},
                  {restart_type,{permanent,4}},
                  {shutdown,1000},
                  {child_type,worker}]


[ns_server:debug,2019-03-19T15:50:34.142Z,ns_1@127.0.0.1:<0.649.0>:ns_pubsub:do_subscribe_link:145]Parent process of subscription {ns_config_events,<0.647.0>} exited with reason {{badmatch,
                                                                                 {error,
                                                                                  couldnt_connect_to_memcached}},
                                                                                [{ns_memcached,
                                                                                  '-config_validate/1-fun-0-',
                                                                                  1,
                                                                                  [{file,
                                                                                    "src/ns_memcached.erl"},
                                                                                   {line,
                                                                                    1474}]},
                                                                                 {async,
                                                                                  '-async_init/4-fun-2-',
                                                                                  3,
                                                                                  [{file,
                                                                                    "src/async.erl"},
                                                                                   {line,
                                                                                    208}]}]}
[ns_server:debug,2019-03-19T15:50:34.142Z,ns_1@127.0.0.1:<0.648.0>:remote_monitors:handle_down:158]Caller of remote monitor <0.647.0> died with {{badmatch,
                                               {error,
                                                couldnt_connect_to_memcached}},
                                              [{ns_memcached,
                                                '-config_validate/1-fun-0-',1,
                                                [{file,"src/ns_memcached.erl"},
                                                 {line,1474}]},
                                               {async,'-async_init/4-fun-2-',
                                                3,
                                                [{file,"src/async.erl"},
                                                 {line,208}]}]}. Exiting
[error_logger:error,2019-03-19T15:50:34.142Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Error in process <0.651.0> on node 'ns_1@127.0.0.1' with exit value: {{badmatch,{error,couldnt_connect_to_memcached}},[{ns_memcached,'-config_validate/1-fun-0-',1,[{file,"src/ns_memcached.erl"},{line,1474}]},{async,'-async_init/4-fun-2-',3,[{file,"src/async.erl"},{line,208}]}]}


[ns_server:debug,2019-03-19T15:50:34.349Z,ns_1@127.0.0.1:compiled_roles_cache<0.207.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@",admin}
[ns_server:debug,2019-03-19T15:50:34.382Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.653.0>:json_rpc_connection:init:73]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.653.0>
[ns_server:warn,2019-03-19T15:50:34.407Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T15:50:34.407Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[ns_server:debug,2019-03-19T15:50:34.449Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.656.0>:json_rpc_connection:init:73]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.656.0>
[ns_server:debug,2019-03-19T15:50:34.449Z,ns_1@127.0.0.1:menelaus_cbauth<0.367.0>:menelaus_cbauth:handle_cast:102]Observed json rpc process {"goxdcr-cbauth",<0.656.0>} started
[ns_server:debug,2019-03-19T15:50:34.454Z,ns_1@127.0.0.1:compiled_roles_cache<0.207.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@goxdcr-cbauth",admin}
[ns_server:warn,2019-03-19T15:50:34.495Z,ns_1@127.0.0.1:<0.384.0>:ns_memcached:connect:1230]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2019-03-19T15:50:34.875Z,ns_1@127.0.0.1:<0.490.0>:auto_failover_logic:log_master_activity:170]Transitioned node {'ns_1@127.0.0.1',<<"9bca6fc94f10ac3edc5b102bbb4437b5">>} state new -> up
[ns_server:debug,2019-03-19T15:50:34.876Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:89]Refresh of [rbac,isasl] succeeded
[ns_server:debug,2019-03-19T15:50:35.506Z,ns_1@127.0.0.1:ns_audit_cfg<0.381.0>:ns_audit_cfg:write_audit_json:265]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{descriptors_path,
                                                                                <<"/opt/couchbase/etc/security">>},
                                                                               {version,
                                                                                2},
                                                                               {uuid,
                                                                                <<"18411111">>},
                                                                               {event_states,
                                                                                {[]}},
                                                                               {filtering_enabled,
                                                                                true},
                                                                               {disabled_userids,
                                                                                []},
                                                                               {auditd_enabled,
                                                                                false},
                                                                               {log_path,
                                                                                <<"/opt/couchbase/var/lib/couchbase/logs">>},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []}]
[ns_server:debug,2019-03-19T15:50:35.524Z,ns_1@127.0.0.1:ns_audit_cfg<0.381.0>:ns_audit_cfg:notify_memcached:170]Instruct memcached to reload audit config
[ns_server:debug,2019-03-19T15:50:38.143Z,ns_1@127.0.0.1:memcached_config_mgr<0.743.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2019-03-19T15:50:38.143Z,ns_1@127.0.0.1:memcached_config_mgr<0.743.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[error_logger:info,2019-03-19T15:50:38.143Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.743.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T15:50:38.143Z,ns_1@127.0.0.1:memcached_config_mgr<0.743.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.81.0>
[ns_server:debug,2019-03-19T15:50:38.147Z,ns_1@127.0.0.1:memcached_config_mgr<0.743.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[ns_server:debug,2019-03-19T15:50:38.152Z,ns_1@127.0.0.1:memcached_config_mgr<0.743.0>:memcached_config_mgr:init:85]found memcached port to be already active
[ns_server:debug,2019-03-19T15:50:38.163Z,ns_1@127.0.0.1:memcached_config_mgr<0.743.0>:memcached_config_mgr:apply_changed_memcached_config:163]New memcached config is hot-reloadable.
[ns_server:debug,2019-03-19T15:50:38.164Z,ns_1@127.0.0.1:memcached_config_mgr<0.743.0>:memcached_config_mgr:do_read_current_memcached_config:256]Got enoent while trying to read active memcached config from /opt/couchbase/var/lib/couchbase/config/memcached.json.prev
[user:info,2019-03-19T15:50:38.194Z,ns_1@127.0.0.1:memcached_config_mgr<0.743.0>:memcached_config_mgr:hot_reload_config:223]Hot-reloaded memcached.json for config change of the following keys: [<<"client_cert_auth">>,
                                                                      <<"datatype_snappy">>,
                                                                      <<"scramsha_fallback_salt">>,
                                                                      <<"xattr_enabled">>]
[ns_server:debug,2019-03-19T15:50:38.318Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.299.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2019-03-19T15:51:03.645Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:51:03.645Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:51:03.645Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:51:03.645Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:51:33.646Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:51:33.646Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:51:33.646Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:51:33.646Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:52:03.647Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:52:03.647Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:52:03.647Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:52:03.647Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:52:33.648Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:52:33.648Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:52:33.648Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:52:33.648Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:53:03.649Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:53:03.649Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:53:03.649Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:53:03.649Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:53:33.650Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:53:33.650Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:53:33.650Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:53:33.650Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:54:03.651Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:54:03.651Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:54:03.651Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:54:03.651Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:54:33.652Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:54:33.652Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:54:33.652Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:54:33.652Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:55:03.653Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:55:03.653Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:55:03.653Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:55:03.653Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:55:33.654Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:55:33.654Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:55:33.654Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:55:33.654Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:56:03.655Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:56:03.655Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:56:03.655Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:56:03.655Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:56:33.656Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:56:33.656Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:56:33.656Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:56:33.656Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:57:03.657Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:57:03.657Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:57:03.657Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:57:03.657Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:57:33.658Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:57:33.658Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:57:33.658Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:57:33.658Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:58:03.659Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:58:03.659Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:58:03.659Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:58:03.659Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:58:33.660Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:58:33.660Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:58:33.660Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:58:33.660Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:59:03.661Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:59:03.661Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:59:03.661Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:59:03.661Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:59:33.662Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:59:33.662Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T15:59:33.662Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T15:59:33.662Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:00:03.663Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:00:03.663Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:00:03.663Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:00:03.663Z,ns_1@127.0.0.1:compaction_new_daemon<0.432.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[error_logger:info,2019-03-19T16:11:21.130Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.131.0>},
                       {name,timer_server},
                       {mfargs,{timer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:21.412Z,nonode@nohost:<0.89.0>:ns_server:init_logging:150]Started & configured logging
[ns_server:info,2019-03-19T16:11:21.428Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_access,info},
 {disk_sink_opts,[{rotation,[{compress,true},
                             {size,41943040},
                             {num_files,10},
                             {buffer_size_max,52428800}]}]},
 {disk_sink_opts_json_rpc,[{rotation,[{compress,true},
                                      {size,41943040},
                                      {num_files,2},
                                      {buffer_size_max,52428800}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2019-03-19T16:11:21.428Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.428Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.428Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.428Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.428Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.428Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.428Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.428Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.428Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.428Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.428Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_json_rpc, which is given from command line
[ns_server:warn,2019-03-19T16:11:21.429Z,nonode@nohost:<0.89.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2019-03-19T16:11:21.443Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.138.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:21.448Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,9,125}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-6d69bef] [64-bit] [smp:2:2] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2019,3,19},{16,11,21}}},
               {memory,
                   [{total,110379408},
                    {processes,9524512},
                    {processes_used,9523424},
                    {system,100854896},
                    {atom,339441},
                    {atom_used,322567},
                    {binary,63096},
                    {code,7796127},
                    {ets,2241584}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,path_config,'ale_logger-metakv',
                    'ale_logger-rebalance','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-json_rpc',
                    'ale_logger-access',calendar,ale_default_formatter,
                    io_lib_fread,'ale_logger-ns_server','ale_logger-user',
                    'ale_logger-ns_doctor','ale_logger-cluster',
                    'ale_logger-xdcr',otp_internal,ns_log_sink,ale_disk_sink,
                    misc,couch_util,ns_server,filelib,cpu_sup,memsup,disksup,
                    os_mon,io,release_handler,overload,alarm_handler,sasl,
                    timer,tftp_sup,httpd_sup,httpc_handler_sup,httpc_cookie,
                    inets_trace,httpc_manager,httpc,httpc_profile_sup,
                    httpc_sup,ftp_sup,inets_sup,inets_app,ssl,lhttpc_manager,
                    lhttpc_sup,lhttpc,tls_connection_sup,ssl_session_cache,
                    ssl_pkix_db,ssl_manager,ssl_sup,ssl_app,crypto_server,
                    crypto_sup,crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_io,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","6.0.1-2037-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","6.0.1-2037-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,105},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [lhttpc_sup,code_server,ale_stats_events,
                    ns_server_cluster_sup,lhttpc_manager,
                    application_controller,ale,'sink-ns_log',httpd_sup,
                    release_handler,kernel_safe_sup,standard_error,ale_sup,
                    overload,error_logger,'sink-disk_json_rpc',alarm_handler,
                    ale_dynamic_sup,'sink-disk_metakv',timer_server,
                    standard_error_sup,'sink-disk_access_int',
                    'sink-disk_access',crypto_server,'sink-disk_reports',
                    crypto_sup,sasl_safe_sup,'sink-disk_stats',tftp_sup,
                    'sink-disk_xdcr',inet_db,init,os_mon_sup,rex,
                    'sink-disk_debug',tls_connection_sup,user,ssl_sup,
                    kernel_sup,cpu_sup,'sink-disk_error',global_name_server,
                    memsup,disksup,'sink-disk_default',httpc_sup,
                    file_server_2,ssl_manager,local_tasks,global_group,
                    httpc_profile_sup,httpc_manager,httpc_handler_sup,ftp_sup,
                    sasl_sup,erl_prim_loader,inets_sup]},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,2}]
[ns_server:info,2019-03-19T16:11:21.455Z,nonode@nohost:ns_server_cluster_sup<0.137.0>:log_os_info:start_link:27]Manifest:
["<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\" />",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\" />",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\" />",
 "  ","  <default remote=\"couchbase\" revision=\"master\" />","  ",
 "  <project groups=\"kv\" name=\"HdrHistogram_c\" path=\"third_party/HdrHistogram_c\" remote=\"couchbasedeps\" revision=\"d200fc0f68695d4aef1fad5c3c8cc55f8c033014\" upstream=\"refs/tags/0.9.7\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"analytics-dcp-client\" path=\"analytics/java-dcp-client\" revision=\"a5567811193b0cc3571fe94e42fc1b8a6a80bc5b\" upstream=\"alice\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"asterixdb\" path=\"analytics/asterixdb\" revision=\"5363b3338ac5886a3260d7eb2a9be250088ca07e\" upstream=\"alice\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"8b892819df78d1c34166a52eb076668e17ea3127\" upstream=\"alice\" />",
 "  <project groups=\"kv\" name=\"benchmark\" remote=\"couchbasedeps\" revision=\"9e3465560240ffb242b50a47cb7f19251a12ee42\" />",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\" />",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5cd1345cca3ed72f1e63d41d622fcda73e63fea8\" />",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"5d4917326972a5fe6f1e094ec439f66f69c92c3f\" />",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"f551b6d4f32bb920a83dd28c705bddd5de0d03b2\" />",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"4b158bb555a3297565afecf6fae675c74f1e47df\" />",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\" />",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\" />",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"39057a59b788c50aa32a5102a718ef910e893a59\" upstream=\"alice\">",
 "    <annotation name=\"RELEASE\" value=\"alice\" />",
 "    <annotation name=\"PRODUCT\" value=\"couchbase-server\" />",
 "    <annotation name=\"BLD_NUM\" value=\"2037\" />",
 "    <annotation name=\"VERSION\" value=\"6.0.1\" />","  </project>",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas\" path=\"goproj/src/github.com/couchbaselabs/cbas\" remote=\"couchbase-priv\" revision=\"cd8ad4f69909d3b804b1e2602045a1637e0316d7\" upstream=\"alice\" />",
 "  <project groups=\"notdefault,enterprise,analytics\" name=\"cbas-core\" path=\"analytics\" remote=\"couchbase-priv\" revision=\"f6eed2e053c11ee5fd0cd83122001dc2a56450df\" upstream=\"alice\" />",
 "  <project groups=\"analytics\" name=\"cbas-ui\" revision=\"a1c61e411517bbc2517401f636523dcc76d1e18d\" upstream=\"alice\" />",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"0df84c7e3c6d95ff435c12a3c08c6f064db11e97\" />",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"80d2ad8892d806f5103f602fec0d80adaa4b628f\" />",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"a33ad7b7000a9d8d237ba273c47cc100401a0fb0\" />",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"0a94f40b9080e0ecb11d3b7531a58c5e6a4a4465\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"19fecfe58921c162a31c156781bd2a512711f14d\" />",
 "  <project name=\"cbsummary\" path=\"goproj/src/github.com/couchbase/cbsummary\" revision=\"dbfa1c0d73f0e49f6f04e390f03de8f9a6cee769\" />",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"dcae66272b24600ae0005fa06b511cfae8914d3d\" />",
 "  <project name=\"cobra\" path=\"godeps/src/github.com/spf13/cobra\" remote=\"couchbasedeps\" revision=\"0f056af21f5f368e5b0646079d0094a2c64150f7\" />",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\" />",
 "  <project groups=\"notdefault,kv_ee,enterprise\" name=\"couch_rocks\" remote=\"couchbase-priv\" revision=\"75f37fa46bfe5e445dee077157303968a3e09126\" />",
 "  <project name=\"couchbase-cli\" revision=\"0db2826a55fa2fd6625a46422425427b8863403a\" upstream=\"alice\" />",
 "  <project name=\"couchdb\" revision=\"3c4ad2b96fd21587c9effdd4b663bb30a75ae455\" upstream=\"alice\" />",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"2ce6ce3597dd9437210446a861a3a881ca4bb248\" />",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"884e9b80cd388d56353e1282f26d79dd6a592f23\" upstream=\"vulcan\" />",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\" />",
 "  <project name=\"cuckoofilter\" path=\"godeps/src/github.com/seiflotfy/cuckoofilter\" remote=\"couchbasedeps\" revision=\"d04838794ab86926d32b124345777e55e6f43974\" />",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\" />",
 "  <project name=\"docloader\" path=\"goproj/src/github.com/couchbase/docloader\" revision=\"05067021a042a1b63e100a486afd7ebddab4c535\" />",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\" />",
 "  <project name=\"errors\" path=\"godeps/src/github.com/pkg/errors\" remote=\"couchbasedeps\" revision=\"30136e27e2ac8d167177e8a583aa4c3fea5be833\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"eventing\" path=\"goproj/src/github.com/couchbase/eventing\" revision=\"f6a7443859b5213ff4dfcdef7bb0bcd37363b9eb\" upstream=\"alice\" />",
 "  <project name=\"flatbuffers\" path=\"godeps/src/github.com/google/flatbuffers\" remote=\"couchbasedeps\" revision=\"1a8968225130caeddd16e227678e6f8af1926303\" />",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"562366039e50730282548b02c1a30d73f97cba27\" upstream=\"vulcan\" />",
 "  <project name=\"fwd\" path=\"godeps/src/github.com/philhofer/fwd\" remote=\"couchbasedeps\" revision=\"bb6d471dc95d4fe11e432687f8b70ff496cf3136\" />",
 "  <project name=\"geocouch\" revision=\"2a0e73f43451045f157640eec59ced72da18471f\" />",
 "  <project name=\"ghistogram\" path=\"godeps/src/github.com/couchbase/ghistogram\" revision=\"d910dd063dd68fb4d2a1ba344440f834ebb4ef62\" />",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\" />",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"9c0fc1f8003c1fb6b9bd6aec686eb6774d7e06ce\" upstream=\"alice\" />",
 "  <project name=\"go-curl\" path=\"godeps/src/github.com/andelf/go-curl\" remote=\"couchbasedeps\" revision=\"3b0453ce6faae42ab4d8cdb9ac1f93919c9d8d69\" upstream=\"20161221-couchbase\" />",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\" />",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\" />",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\" />",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\" />",
 "  <project name=\"go-sqlite3\" path=\"godeps/src/github.com/mattn/go-sqlite3\" remote=\"couchbasedeps\" revision=\"47fc4e5e9153645da45af6a86a5bce95e63a0f9e\" />",
 "  <project name=\"go-unsnap-stream\" path=\"godeps/src/github.com/glycerine/go-unsnap-stream\" remote=\"couchbasedeps\" revision=\"62a9a9eb44fd8932157b1a8ace2149eff5971af6\" />",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\" />",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"d2f15a425a9c8e4d8447e5f5b89ce14845f7fa05\" upstream=\"vulcan\" />",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\" />",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"699b13a51af5dd4f80ff3deedf41bba60debad32\" upstream=\"refs/tags/v1.3.7\" />",
 "  <project name=\"gocbconnstr\" path=\"godeps/src/gopkg.in/couchbaselabs/gocbconnstr.v1\" remote=\"couchbaselabs\" revision=\"710456e087a6d497e87f41d0a9d98d6a75672186\" />",
 "  <project name=\"gocbcore\" path=\"godeps/src/gopkg.in/couchbase/gocbcore.v7\" revision=\"a0d26c2d6f5de912499d35a5aba573006e5e036f\" upstream=\"refs/tags/v7.1.7\" />",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"aecdbe5a5a91f0688df7bdf260ca962178c06828\" upstream=\"vulcan\" />",
 "  <project name=\"gofarmhash\" path=\"godeps/src/github.com/leemcloughlin/gofarmhash\" remote=\"couchbasedeps\" revision=\"0a055c5b87a8c55ce83459cbf2776b563822a942\" />",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\" />",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\" />",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\" />",
 "  <project name=\"golang-tools\" path=\"godeps/src/golang.org/x/tools\" remote=\"couchbasedeps\" revision=\"a28dfb48e06b2296b66678872c2cb638f0304f20\" />",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\" />",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"e05ec3550789be1da2981787ef6444fef75e10bc\" upstream=\"vulcan\" />",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"c995daf62dbcd6da60d6a868bfeb0faf69ddadf5\" upstream=\"alice\" />",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\" />",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\" />",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\" />",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"f98adca8eb365032cab838ef4d99453931afa112\" upstream=\"vulcan\" />",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"bdc8bc82b7847138a59f27fd5cc6ce2d1d8f01c4\" upstream=\"alice\" />",
 "  <project groups=\"kv\" name=\"gsl-lite\" path=\"third_party/gsl-lite\" remote=\"couchbasedeps\" revision=\"57542c7e7ced375346e9ac55dad85b942cfad556\" upstream=\"refs/tags/v0.25.0\" />",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\" />",
 "  <project name=\"httprouter\" path=\"godeps/src/github.com/julienschmidt/httprouter\" remote=\"couchbasedeps\" revision=\"975b5c4c7c21c0e3d2764200bf2aa8e34657ae6e\" />",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"8443db9caeab1a2ab54ffb69130453e546cbd597\" upstream=\"alice\" />",
 "  <project name=\"json-iterator-go\" path=\"godeps/src/github.com/json-iterator/go\" remote=\"couchbasedeps\" revision=\"f7279a603edee96fe7764d3de9c6ff8cf9970994\" />",
 "  <project name=\"jsonx\" path=\"godeps/src/gopkg.in/couchbaselabs/jsonx.v1\" remote=\"couchbaselabs\" revision=\"5b7baa20429a46a5543ee259664cc86502738cad\" />",
 "  <project groups=\"kv\" name=\"kv_engine\" revision=\"94a16e416b1d1c1f744478b55ad278372e6bbfaf\" upstream=\"alice\" />",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"libcouchbase\" revision=\"081e8b16b991bf706eb77f8243935c6fba31b895\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"3681c2a912330352991ecdd642f257efe5b85518\" />",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\" />",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\" />",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\" />",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"956632ec1bc3e28276d00ee2f22c3202f06efb12\" />",
 "  <project name=\"mossScope\" path=\"godeps/src/github.com/couchbase/mossScope\" revision=\"abd3b58b422dbc2e9463a589d0f3d93441726e23\" />",
 "  <project name=\"mousetrap\" path=\"godeps/src/github.com/inconshreveable/mousetrap\" remote=\"couchbasedeps\" revision=\"76626ae9c91c4f2a10f34cad8ce83ea42c93bb75\" />",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"cd8da46b9b953800d430c8b0aa4667790727ed6f\" />",
 "  <project name=\"msgp\" path=\"godeps/src/github.com/tinylib/msgp\" remote=\"couchbasedeps\" revision=\"5bb5e1aed7ba5bcc93307153b020e7ffe79b0509\" />",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"043ee6597c29786140136a5747b6a886364f5282\" />",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"62685c2d7ca23c807425dca88b11a3e2323dab41\" />",
 "  <project name=\"nitro\" path=\"goproj/src/github.com/couchbase/nitro\" revision=\"f3bef3551997be504612a2d05a8b324b3bfdfe1b\" />",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\" />",
 "  <project name=\"ns_server\" revision=\"e6b9cafa227bcf74bc11550be5e3450cc9fc48ec\" upstream=\"alice\" />",
 "  <project name=\"opentracing-go\" path=\"godeps/src/github.com/opentracing/opentracing-go\" remote=\"couchbasedeps\" revision=\"1949ddbfd147afd4d964a9f00b24eb291e0e7c38\" />",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\" />",
 "  <project name=\"pflag\" path=\"godeps/src/github.com/spf13/pflag\" remote=\"couchbasedeps\" revision=\"a232f6d9f87afaaa08bafaff5da685f974b83313\" />",
 "  <project groups=\"kv\" name=\"phosphor\" revision=\"96501c57bb0fd61c85cba6f63101aed2bcf41d38\" />",
 "  <project name=\"pierrec-lz4\" path=\"godeps/src/github.com/pierrec/lz4\" remote=\"couchbasedeps\" revision=\"ed8d4cc3b461464e69798080a0092bd028910298\" />",
 "  <project name=\"pierrec-xxHash\" path=\"godeps/src/github.com/pierrec/xxHash\" remote=\"couchbasedeps\" revision=\"a0006b13c722f7f12368c00a3d3c2ae8a999a0c6\" />",
 "  <project groups=\"notdefault,enterprise\" name=\"plasma\" path=\"goproj/src/github.com/couchbase/plasma\" remote=\"couchbase-priv\" revision=\"53c7714a7ff072a76f202bc79be77b363c78aec8\" upstream=\"alice\" />",
 "  <project groups=\"kv\" name=\"platform\" revision=\"2fbe5179a2673a9275cd0906daa4b1cab38a3eb5\" />",
 "  <project groups=\"kv\" name=\"product-texts\" revision=\"8cf7d25a1dcb5434ea44983c0bed202fb9cc8351\" />",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\" />",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"152023ba183b1b1aacd862e2b48afa2907bad508\" upstream=\"alice\" />",
 "  <project name=\"query-ui\" revision=\"15a6461f437fe810e411a6613ec7c143991cd1c6\" upstream=\"alice\" />",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\" />",
 "  <project name=\"roaring\" path=\"godeps/src/github.com/RoaringBitmap/roaring\" remote=\"couchbasedeps\" revision=\"fe09428be4c233d726797a1380f7438f4f71a31a\" />",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"762005e7a34fd909a84586299f1dd457371d36ee\" />",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"73353fe6dad8f3d67409feefb9b17f90f6de917b\" />",
 "  <project name=\"snowballstem\" path=\"godeps/src/github.com/blevesearch/snowballstem\" remote=\"blevesearch\" revision=\"26b06a2c243d4f8ca5db3486f94409dd5b2a7467\" />",
 "  <project groups=\"kv\" name=\"spdlog\" path=\"third_party/spdlog\" remote=\"couchbasedeps\" revision=\"4fba14c79f356ae48d6141c561bf9fd7ba33fabd\" upstream=\"refs/tags/v0.14.0\" />",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\" />",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"c30c3d4c250e68e81c57aa1e8ae91ffd21243cdb\" />",
 "  <project name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\" />",
 "  <project name=\"testrunner\" revision=\"31738dbd28ca8a6460b6432da1f010b311b49e17\" upstream=\"alice\" />",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\" />",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"8625abafc3a6907dd43cce621939b4a09335ceed\" upstream=\"alice\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\" />",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\" />",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\" />",
 "    <copyfile dest=\".clang-format\" src=\"dot-clang-format\" />",
 "    <copyfile dest=\"third_party/CMakeLists.txt\" src=\"third-party-CMakeLists.txt\" />",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\" />",
 "  <project name=\"uuid\" path=\"godeps/src/github.com/google/uuid\" remote=\"couchbasedeps\" revision=\"dec09d789f3dba190787f8b4454c7d3c936fed9e\" />",
 "  <project name=\"vellum\" path=\"godeps/src/github.com/couchbase/vellum\" revision=\"0ceea4a37442f76199b9259840baf48d17af3c1a\" />",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"be41d2649d616c66f8dce2d9231c4be25e91db66\" upstream=\"alice\" />",
 "  <project name=\"zstd\" path=\"godeps/src/github.com/DataDog/zstd\" remote=\"couchbasedeps\" revision=\"aebefd9fcb99f22cd691ef778a12ed68f0e6a1ab\" />",
 "</manifest>"]

[error_logger:info,2019-03-19T16:11:21.497Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.139.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:21.501Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2019-03-19T16:11:21.502Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:read_address_config_from_path:159]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2019-03-19T16:11:21.503Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:init:243]ip config not found. Looks like we're brand new node
[error_logger:info,2019-03-19T16:11:21.503Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.143.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2019-03-19T16:11:21.504Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.142.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:21.830Z,nonode@nohost:dist_manager<0.141.0>:dist_manager:bringup:295]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2019-03-19T16:11:21.851Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.145.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:21.851Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.146.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:21.852Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.147.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:21.852Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:configure_net_kernel:339]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2019-03-19T16:11:21.852Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.144.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2019-03-19T16:11:21.856Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:save_node:227]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2019-03-19T16:11:21.880Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:bringup:309]Attempted to save node name to disk: ok
[ns_server:debug,2019-03-19T16:11:21.880Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:316]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2019-03-19T16:11:21.880Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T16:11:21.886Z,ns_1@127.0.0.1:dist_manager<0.141.0>:dist_manager:wait_for_node:328]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2019-03-19T16:11:21.887Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:21.898Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:21.900Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:21.903Z,ns_1@127.0.0.1:ns_config_sup<0.154.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2019-03-19T16:11:21.903Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.155.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:21.903Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.156.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:21.952Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1095]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2019-03-19T16:11:21.955Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1109]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2019-03-19T16:11:21.975Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1117]Here's full dynamic config we loaded:
[[{auto_failover_cfg,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
    {enabled,true},
    {timeout,120},
    {count,0},
    {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
    {failover_server_group,false},
    {max_count,1},
    {failed_over_server_groups,[]}]},
  {audit_decriptors,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
    {20480,
     [{name,<<"opened DCP connection">>},
      {description,<<"opened DCP connection">>},
      {enabled,true},
      {module,memcached}]},
    {20482,
     [{name,<<"external memcached bucket flush">>},
      {description,
       <<"External user flushed the content of a memcached bucket">>},
      {enabled,true},
      {module,memcached}]},
    {20483,
     [{name,<<"invalid packet">>},
      {description,<<"Rejected an invalid packet">>},
      {enabled,true},
      {module,memcached}]},
    {20485,
     [{name,<<"authentication succeeded">>},
      {description,<<"Authentication to the cluster succeeded">>},
      {enabled,false},
      {module,memcached}]},
    {20488,
     [{name,<<"document read">>},
      {description,<<"Document was read">>},
      {enabled,false},
      {module,memcached}]},
    {20489,
     [{name,<<"document locked">>},
      {description,<<"Document was locked">>},
      {enabled,false},
      {module,memcached}]},
    {20490,
     [{name,<<"document modify">>},
      {description,<<"Document was modified">>},
      {enabled,false},
      {module,memcached}]},
    {20491,
     [{name,<<"document delete">>},
      {description,<<"Document was deleted">>},
      {enabled,false},
      {module,memcached}]},
    {20492,
     [{name,<<"select bucket">>},
      {description,<<"The specified bucket was selected">>},
      {enabled,true},
      {module,memcached}]},
    {28672,
     [{name,<<"SELECT statement">>},
      {description,<<"A N1QL SELECT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28673,
     [{name,<<"EXPLAIN statement">>},
      {description,<<"A N1QL EXPLAIN statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28674,
     [{name,<<"PREPARE statement">>},
      {description,<<"A N1QL PREPARE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28675,
     [{name,<<"INFER statement">>},
      {description,<<"A N1QL INFER statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28676,
     [{name,<<"INSERT statement">>},
      {description,<<"A N1QL INSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28677,
     [{name,<<"UPSERT statement">>},
      {description,<<"A N1QL UPSERT statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28678,
     [{name,<<"DELETE statement">>},
      {description,<<"A N1QL DELETE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28679,
     [{name,<<"UPDATE statement">>},
      {description,<<"A N1QL UPDATE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28680,
     [{name,<<"MERGE statement">>},
      {description,<<"A N1QL MERGE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28681,
     [{name,<<"CREATE INDEX statement">>},
      {description,<<"A N1QL CREATE INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28682,
     [{name,<<"DROP INDEX statement">>},
      {description,<<"A N1QL DROP INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28683,
     [{name,<<"ALTER INDEX statement">>},
      {description,<<"A N1QL ALTER INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28684,
     [{name,<<"BUILD INDEX statement">>},
      {description,<<"A N1QL BUILD INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28685,
     [{name,<<"GRANT ROLE statement">>},
      {description,<<"A N1QL GRANT ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28686,
     [{name,<<"REVOKE ROLE statement">>},
      {description,<<"A N1QL REVOKE ROLE statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28687,
     [{name,<<"UNRECOGNIZED statement">>},
      {description,
       <<"An unrecognized statement was received by the N1QL query engine">>},
      {enabled,false},
      {module,n1ql}]},
    {28688,
     [{name,<<"CREATE PRIMARY INDEX statement">>},
      {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
      {enabled,false},
      {module,n1ql}]},
    {28689,
     [{name,<<"/admin/stats API request">>},
      {description,<<"An HTTP request was made to the API at /admin/stats.">>},
      {enabled,false},
      {module,n1ql}]},
    {28690,
     [{name,<<"/admin/vitals API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/vitals.">>},
      {enabled,false},
      {module,n1ql}]},
    {28691,
     [{name,<<"/admin/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28692,
     [{name,<<"/admin/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28693,
     [{name,<<"/admin/indexes/prepareds API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
      {enabled,false},
      {module,n1ql}]},
    {28694,
     [{name,<<"/admin/indexes/active_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28695,
     [{name,<<"/admin/indexes/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {28697,
     [{name,<<"/admin/ping API request">>},
      {description,<<"An HTTP request was made to the API at /admin/ping.">>},
      {enabled,false},
      {module,n1ql}]},
    {28698,
     [{name,<<"/admin/config API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/config.">>},
      {enabled,false},
      {module,n1ql}]},
    {28699,
     [{name,<<"/admin/ssl_cert API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
      {enabled,false},
      {module,n1ql}]},
    {28700,
     [{name,<<"/admin/settings API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/settings.">>},
      {enabled,false},
      {module,n1ql}]},
    {28701,
     [{name,<<"/admin/clusters API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/clusters.">>},
      {enabled,false},
      {module,n1ql}]},
    {28702,
     [{name,<<"/admin/completed_requests API request">>},
      {description,
       <<"An HTTP request was made to the API at /admin/completed_requests.">>},
      {enabled,false},
      {module,n1ql}]},
    {32768,
     [{name,<<"Create Function">>},
      {description,<<"Eventing function definition was created or updated">>},
      {enabled,true},
      {module,eventing}]},
    {32769,
     [{name,<<"Delete Function">>},
      {description,<<"Eventing function definition was deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32770,
     [{name,<<"Fetch Functions">>},
      {description,<<"Eventing function definition was read">>},
      {enabled,false},
      {module,eventing}]},
    {32771,
     [{name,<<"List Deployed">>},
      {description,<<"Eventing deployed functions list was read">>},
      {enabled,false},
      {module,eventing}]},
    {32772,
     [{name,<<"Fetch Drafts">>},
      {description,<<"Eventing function draft definitions were read">>},
      {enabled,false},
      {module,eventing}]},
    {32773,
     [{name,<<"Delete Drafts">>},
      {description,<<"Eventing function draft definitions were deleted">>},
      {enabled,true},
      {module,eventing}]},
    {32774,
     [{name,<<"Save Draft">>},
      {description,<<"Save a draft definition to the store">>},
      {enabled,true},
      {module,eventing}]},
    {32775,
     [{name,<<"Start Debug">>},
      {description,<<"Start eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32776,
     [{name,<<"Stop Debug">>},
      {description,<<"Stop eventing function debugger">>},
      {enabled,true},
      {module,eventing}]},
    {32777,
     [{name,<<"Start Tracing">>},
      {description,<<"Start tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32778,
     [{name,<<"Stop Tracing">>},
      {description,<<"Stop tracing eventing function execution">>},
      {enabled,true},
      {module,eventing}]},
    {32779,
     [{name,<<"Set Settings">>},
      {description,<<"Save settings for a given app">>},
      {enabled,true},
      {module,eventing}]},
    {32780,
     [{name,<<"Fetch Config">>},
      {description,<<"Get config for eventing">>},
      {enabled,false},
      {module,eventing}]},
    {32781,
     [{name,<<"Save Config">>},
      {description,<<"Save config for eventing">>},
      {enabled,true},
      {module,eventing}]},
    {32782,
     [{name,<<"Cleanup Eventing">>},
      {description,<<"Clears up app definitions and settings from metakv">>},
      {enabled,true},
      {module,eventing}]},
    {32783,
     [{name,<<"Get Settings">>},
      {description,<<"Get settings for a given app">>},
      {enabled,false},
      {module,eventing}]},
    {32784,
     [{name,<<"Import Functions">>},
      {description,<<"Import a list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32785,
     [{name,<<"Export Functions">>},
      {description,<<"Export the list of functions">>},
      {enabled,false},
      {module,eventing}]},
    {32786,
     [{name,<<"List Running">>},
      {description,<<"Eventing running function list was read">>},
      {enabled,false},
      {module,eventing}]},
    {36865,
     [{name,<<"Service configuration change">>},
      {description,<<"A successful service configuration change was made.">>},
      {enabled,true},
      {module,analytics}]},
    {36866,
     [{name,<<"Node configuration change">>},
      {description,<<"A successful node configuration change was made.">>},
      {enabled,true},
      {module,analytics}]}]},
  {scramsha_fallback_salt,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
    <<153,243,183,226,93,180,216,77,176,217,18,64>>]},
  {{rbac_upgrade,[5,5]},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
    '_deleted']},
  {{metakv,<<"/eventing/settings/config">>},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
    <<"{\"ram_quota\":256}">>]},
  {{metakv,<<"/query/settings/config">>},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
    <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
  {client_cert_auth,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
    {state,"disable"},
    {prefixes,[]}]},
  {users_upgrade,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
    '_deleted']},
  {roles_definitions,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
    '_deleted']},
  {{service_map,fts},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}]},
  {{service_map,index},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}]},
  {{service_map,n1ql},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}]},
  {cluster_compat_version,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{8,63720229833}}]},
    6,0]},
  {otp,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
    {cookie,{sanitized,<<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}}]},
  {cert_and_pkey,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229828}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFY1m8D7hCswwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA5YTE4NDJjYjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgOWExODQy\nY2IwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC+eKF5LWqGKFW4gli1\nVvKni+IUYrmY6/qUKhTwQlSYprAg7gSvzaseLfccoVJZbUu6D8O9+wn5/fM1CuJZ\njgCNaWx6D88s/oegh4eAUkqXjnivEkvja+niN7tXCOlABzyGA2+slBTER16Np3QS\nP61Kj6cr7vT5hMGzq/344LSd1kTOn/N4DuJZunNEYKy0sRAGrVwmzEJzxppfa40Q\nA6e9yNcBFdH9xwvA0O3XhLRVtpkKqT4xcnjlGG/w0SQ+iso21s/RL2KgqV2Z6UW7\n2Ys3SUKqSOCjV+Lj/rTbgAfIjg3t+3k42N73vAzqtR/TRYKJQMYO2Kb7rn7iQmSu\nlTSzAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCJNIcZKUhQgP2a\nCEmepx5xJM8cmK4SpqDuBCCUx5cujCLljvBU6c6eGrswyz3DsHQV39Yhv9GTIKdr\nL7VM7FQQAyN+7uTieoHVzEE3JCij7sE2VC96osL4nnCufMdYJiiBWYuBZi+VQxtq\nwO14FjFvadJ+LKo1vckNCgtuPxbc5ArlLuVZG59FrsQt4dh8W4zt7oyY1y9qgGlN\nlCxmcFstMUceCmht8XqbzCAmRjCS2hPp2RHrNuYr5hQWK4r5ncgzIRnYfbk+uncW\nMAbAfxOgKuKkUxdHZjlJ86CnGVi/so5GZkAK5sRpr7fkMeE/Haqx9tXYfknupDMh\nQFlSLZ8B\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
    {enabled,[]},
    {disabled_users,[]},
    {auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{3,63720229833}}]},
    {configs,[]}]},
  {cbas_memory_quota,1024},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
  {fts_memory_quota,256},
  {index_aware_rebalance_disabled,false},
  {log_redaction_default_cfg,[{redact_level,none}]},
  {max_bucket_count,10},
  {memcached,[]},
  {memory_quota,304},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {password_policy,[{min_length,6},{must_present,[]}]},
  {quorum_nodes,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
    'ns_1@127.0.0.1']},
  {read_only_user_creds,
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
    '_deleted']},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {rest,[{port,8091}]},
  {rest_creds,null},
  {secure_headers,[]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',cbas_admin_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9110]},
  {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9113]},
  {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9112]},
  {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9111]},
  {{node,'ns_1@127.0.0.1',cbas_cluster_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9115]},
  {{node,'ns_1@127.0.0.1',cbas_console_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9114]},
  {{node,'ns_1@127.0.0.1',cbas_data_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9116]},
  {{node,'ns_1@127.0.0.1',cbas_debug_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    -1]},
  {{node,'ns_1@127.0.0.1',cbas_http_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    8095]},
  {{node,'ns_1@127.0.0.1',cbas_messaging_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9118]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9119]},
  {{node,'ns_1@127.0.0.1',cbas_metadata_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9121]},
  {{node,'ns_1@127.0.0.1',cbas_parent_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9122]},
  {{node,'ns_1@127.0.0.1',cbas_replication_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9120]},
  {{node,'ns_1@127.0.0.1',cbas_result_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9117]},
  {{node,'ns_1@127.0.0.1',cbas_ssl_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    18095]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    {5,5,3}]},
  {{node,'ns_1@127.0.0.1',eventing_debug_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9140]},
  {{node,'ns_1@127.0.0.1',eventing_http_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    8096]},
  {{node,'ns_1@127.0.0.1',eventing_https_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    18096]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',fts_ssl_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    18094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_https_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    19102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"@ns_server"},
    {other_users,
     ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
      "@cbas"]},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},
           {port,port},
           {maxconn,maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
           {ipv4,<<"required">>},
           {ipv6,<<"optional">>}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {privilege_debug,privilege_debug},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {rbac_file,{"~s",[rbac_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps},
      {tracing_enabled,tracing_enabled},
      {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
      {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
      {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
      {logger,
       {[{filename,{"~s/~s",[log_path,log_prefix]}},
         {cyclesize,log_cyclesize},
         {sleeptime,log_sleeptime}]}}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {privilege_debug,false},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false},
    {tracing_enabled,true},
    {datatype_snappy,true}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    <<"9bca6fc94f10ac3edc5b102bbb4437b5">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    9998]},
  {{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
    false]},
  {{local_changes_count,<<"9bca6fc94f10ac3edc5b102bbb4437b5">>},
   [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{4,63720229833}}]}]}]]
[ns_server:info,2019-03-19T16:11:21.983Z,ns_1@127.0.0.1:ns_config<0.157.0>:ns_config:load_config:1138]Here's full dynamic config we loaded + static & default config:
[{{local_changes_count,<<"9bca6fc94f10ac3edc5b102bbb4437b5">>},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{4,63720229833}}]}]},
 {{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   false]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   <<"9bca6fc94f10ac3edc5b102bbb4437b5">>]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {privilege_debug,false},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false},
   {tracing_enabled,true},
   {datatype_snappy,true}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},
          {port,port},
          {maxconn,maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
          {ipv4,<<"required">>},
          {ipv6,<<"optional">>}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {privilege_debug,privilege_debug},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {rbac_file,{"~s",[rbac_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps},
     {tracing_enabled,tracing_enabled},
     {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
     {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
     {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
     {logger,
      {[{filename,{"~s/~s",[log_path,log_prefix]}},
        {cyclesize,log_cyclesize},
        {sleeptime,log_sleeptime}]}}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"@ns_server"},
   {other_users,
    ["@cbq-engine","@projector","@goxdcr","@index","@fts","@eventing",
     "@cbas"]},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_https_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   19102]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_ssl_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   18094]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',eventing_https_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   18096]},
 {{node,'ns_1@127.0.0.1',eventing_http_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   8096]},
 {{node,'ns_1@127.0.0.1',eventing_debug_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9140]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   {5,5,3}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',cbas_ssl_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   18095]},
 {{node,'ns_1@127.0.0.1',cbas_result_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9117]},
 {{node,'ns_1@127.0.0.1',cbas_replication_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9120]},
 {{node,'ns_1@127.0.0.1',cbas_parent_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9122]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9121]},
 {{node,'ns_1@127.0.0.1',cbas_metadata_callback_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9119]},
 {{node,'ns_1@127.0.0.1',cbas_messaging_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9118]},
 {{node,'ns_1@127.0.0.1',cbas_http_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   8095]},
 {{node,'ns_1@127.0.0.1',cbas_debug_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|-1]},
 {{node,'ns_1@127.0.0.1',cbas_data_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9116]},
 {{node,'ns_1@127.0.0.1',cbas_console_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9114]},
 {{node,'ns_1@127.0.0.1',cbas_cluster_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9115]},
 {{node,'ns_1@127.0.0.1',cbas_cc_http_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9111]},
 {{node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9112]},
 {{node,'ns_1@127.0.0.1',cbas_cc_client_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9113]},
 {{node,'ns_1@127.0.0.1',cbas_admin_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   9110]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":2,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {secure_headers,[]},
 {rest_creds,null},
 {rest,[{port,8091}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {read_only_user_creds,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
   '_deleted']},
 {quorum_nodes,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
   'ns_1@127.0.0.1']},
 {password_policy,[{min_length,6},{must_present,[]}]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memory_quota,304},
 {memcached,[]},
 {max_bucket_count,10},
 {log_redaction_default_cfg,[{redact_level,none}]},
 {index_aware_rebalance_disabled,false},
 {fts_memory_quota,256},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded,communication_issue]}]},
 {drop_request_memory_threshold_mib,undefined},
 {cbas_memory_quota,1024},
 {buckets,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{3,63720229833}}]},
   {configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_reprovision_cfg,[{enabled,true},{max_nodes,1},{count,0}]},
 {audit,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
   {enabled,[]},
   {disabled_users,[]},
   {auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {cert_and_pkey,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229828}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFY1m8D7hCswwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA5YTE4NDJjYjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgOWExODQy\nY2IwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC+eKF5LWqGKFW4gli1\nVvKni+IUYrmY6/qUKhTwQlSYprAg7gSvzaseLfccoVJZbUu6D8O9+wn5/fM1CuJZ\njgCNaWx6D88s/oegh4eAUkqXjnivEkvja+niN7tXCOlABzyGA2+slBTER16Np3QS\nP61Kj6cr7vT5hMGzq/344LSd1kTOn/N4DuJZunNEYKy0sRAGrVwmzEJzxppfa40Q\nA6e9yNcBFdH9xwvA0O3XhLRVtpkKqT4xcnjlGG/w0SQ+iso21s/RL2KgqV2Z6UW7\n2Ys3SUKqSOCjV+Lj/rTbgAfIjg3t+3k42N73vAzqtR/TRYKJQMYO2Kb7rn7iQmSu\nlTSzAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCJNIcZKUhQgP2a\nCEmepx5xJM8cmK4SpqDuBCCUx5cujCLljvBU6c6eGrswyz3DsHQV39Yhv9GTIKdr\nL7VM7FQQAyN+7uTieoHVzEE3JCij7sE2VC96osL4nnCufMdYJiiBWYuBZi+VQxtq\nwO14FjFvadJ+LKo1vckNCgtuPxbc5ArlLuVZG59FrsQt4dh8W4zt7oyY1y9qgGlN\nlCxmcFstMUceCmht8XqbzCAmRjCS2hPp2RHrNuYr5hQWK4r5ncgzIRnYfbk+uncW\nMAbAfxOgKuKkUxdHZjlJ86CnGVi/so5GZkAK5sRpr7fkMeE/Haqx9tXYfknupDMh\nQFlSLZ8B\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {otp,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
   {cookie,{sanitized,<<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}}]},
 {cluster_compat_version,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{8,63720229833}}]},
   6,0]},
 {{service_map,n1ql},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}]},
 {{service_map,index},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}]},
 {{service_map,fts},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}]},
 {roles_definitions,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
   '_deleted']},
 {users_upgrade,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
   '_deleted']},
 {client_cert_auth,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
   {state,"disable"},
   {prefixes,[]}]},
 {{metakv,<<"/query/settings/config">>},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
   <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]},
 {{metakv,<<"/eventing/settings/config">>},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
   <<"{\"ram_quota\":256}">>]},
 {{rbac_upgrade,[5,5]},
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
   '_deleted']},
 {scramsha_fallback_salt,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
   <<153,243,183,226,93,180,216,77,176,217,18,64>>]},
 {audit_decriptors,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
   {20480,
    [{name,<<"opened DCP connection">>},
     {description,<<"opened DCP connection">>},
     {enabled,true},
     {module,memcached}]},
   {20482,
    [{name,<<"external memcached bucket flush">>},
     {description,
      <<"External user flushed the content of a memcached bucket">>},
     {enabled,true},
     {module,memcached}]},
   {20483,
    [{name,<<"invalid packet">>},
     {description,<<"Rejected an invalid packet">>},
     {enabled,true},
     {module,memcached}]},
   {20485,
    [{name,<<"authentication succeeded">>},
     {description,<<"Authentication to the cluster succeeded">>},
     {enabled,false},
     {module,memcached}]},
   {20488,
    [{name,<<"document read">>},
     {description,<<"Document was read">>},
     {enabled,false},
     {module,memcached}]},
   {20489,
    [{name,<<"document locked">>},
     {description,<<"Document was locked">>},
     {enabled,false},
     {module,memcached}]},
   {20490,
    [{name,<<"document modify">>},
     {description,<<"Document was modified">>},
     {enabled,false},
     {module,memcached}]},
   {20491,
    [{name,<<"document delete">>},
     {description,<<"Document was deleted">>},
     {enabled,false},
     {module,memcached}]},
   {20492,
    [{name,<<"select bucket">>},
     {description,<<"The specified bucket was selected">>},
     {enabled,true},
     {module,memcached}]},
   {28672,
    [{name,<<"SELECT statement">>},
     {description,<<"A N1QL SELECT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28673,
    [{name,<<"EXPLAIN statement">>},
     {description,<<"A N1QL EXPLAIN statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28674,
    [{name,<<"PREPARE statement">>},
     {description,<<"A N1QL PREPARE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28675,
    [{name,<<"INFER statement">>},
     {description,<<"A N1QL INFER statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28676,
    [{name,<<"INSERT statement">>},
     {description,<<"A N1QL INSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28677,
    [{name,<<"UPSERT statement">>},
     {description,<<"A N1QL UPSERT statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28678,
    [{name,<<"DELETE statement">>},
     {description,<<"A N1QL DELETE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28679,
    [{name,<<"UPDATE statement">>},
     {description,<<"A N1QL UPDATE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28680,
    [{name,<<"MERGE statement">>},
     {description,<<"A N1QL MERGE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28681,
    [{name,<<"CREATE INDEX statement">>},
     {description,<<"A N1QL CREATE INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28682,
    [{name,<<"DROP INDEX statement">>},
     {description,<<"A N1QL DROP INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28683,
    [{name,<<"ALTER INDEX statement">>},
     {description,<<"A N1QL ALTER INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28684,
    [{name,<<"BUILD INDEX statement">>},
     {description,<<"A N1QL BUILD INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28685,
    [{name,<<"GRANT ROLE statement">>},
     {description,<<"A N1QL GRANT ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28686,
    [{name,<<"REVOKE ROLE statement">>},
     {description,<<"A N1QL REVOKE ROLE statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28687,
    [{name,<<"UNRECOGNIZED statement">>},
     {description,
      <<"An unrecognized statement was received by the N1QL query engine">>},
     {enabled,false},
     {module,n1ql}]},
   {28688,
    [{name,<<"CREATE PRIMARY INDEX statement">>},
     {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
     {enabled,false},
     {module,n1ql}]},
   {28689,
    [{name,<<"/admin/stats API request">>},
     {description,<<"An HTTP request was made to the API at /admin/stats.">>},
     {enabled,false},
     {module,n1ql}]},
   {28690,
    [{name,<<"/admin/vitals API request">>},
     {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
     {enabled,false},
     {module,n1ql}]},
   {28691,
    [{name,<<"/admin/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28692,
    [{name,<<"/admin/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28693,
    [{name,<<"/admin/indexes/prepareds API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
     {enabled,false},
     {module,n1ql}]},
   {28694,
    [{name,<<"/admin/indexes/active_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28695,
    [{name,<<"/admin/indexes/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {28697,
    [{name,<<"/admin/ping API request">>},
     {description,<<"An HTTP request was made to the API at /admin/ping.">>},
     {enabled,false},
     {module,n1ql}]},
   {28698,
    [{name,<<"/admin/config API request">>},
     {description,<<"An HTTP request was made to the API at /admin/config.">>},
     {enabled,false},
     {module,n1ql}]},
   {28699,
    [{name,<<"/admin/ssl_cert API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/ssl_cert.">>},
     {enabled,false},
     {module,n1ql}]},
   {28700,
    [{name,<<"/admin/settings API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/settings.">>},
     {enabled,false},
     {module,n1ql}]},
   {28701,
    [{name,<<"/admin/clusters API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/clusters.">>},
     {enabled,false},
     {module,n1ql}]},
   {28702,
    [{name,<<"/admin/completed_requests API request">>},
     {description,
      <<"An HTTP request was made to the API at /admin/completed_requests.">>},
     {enabled,false},
     {module,n1ql}]},
   {32768,
    [{name,<<"Create Function">>},
     {description,<<"Eventing function definition was created or updated">>},
     {enabled,true},
     {module,eventing}]},
   {32769,
    [{name,<<"Delete Function">>},
     {description,<<"Eventing function definition was deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32770,
    [{name,<<"Fetch Functions">>},
     {description,<<"Eventing function definition was read">>},
     {enabled,false},
     {module,eventing}]},
   {32771,
    [{name,<<"List Deployed">>},
     {description,<<"Eventing deployed functions list was read">>},
     {enabled,false},
     {module,eventing}]},
   {32772,
    [{name,<<"Fetch Drafts">>},
     {description,<<"Eventing function draft definitions were read">>},
     {enabled,false},
     {module,eventing}]},
   {32773,
    [{name,<<"Delete Drafts">>},
     {description,<<"Eventing function draft definitions were deleted">>},
     {enabled,true},
     {module,eventing}]},
   {32774,
    [{name,<<"Save Draft">>},
     {description,<<"Save a draft definition to the store">>},
     {enabled,true},
     {module,eventing}]},
   {32775,
    [{name,<<"Start Debug">>},
     {description,<<"Start eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32776,
    [{name,<<"Stop Debug">>},
     {description,<<"Stop eventing function debugger">>},
     {enabled,true},
     {module,eventing}]},
   {32777,
    [{name,<<"Start Tracing">>},
     {description,<<"Start tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32778,
    [{name,<<"Stop Tracing">>},
     {description,<<"Stop tracing eventing function execution">>},
     {enabled,true},
     {module,eventing}]},
   {32779,
    [{name,<<"Set Settings">>},
     {description,<<"Save settings for a given app">>},
     {enabled,true},
     {module,eventing}]},
   {32780,
    [{name,<<"Fetch Config">>},
     {description,<<"Get config for eventing">>},
     {enabled,false},
     {module,eventing}]},
   {32781,
    [{name,<<"Save Config">>},
     {description,<<"Save config for eventing">>},
     {enabled,true},
     {module,eventing}]},
   {32782,
    [{name,<<"Cleanup Eventing">>},
     {description,<<"Clears up app definitions and settings from metakv">>},
     {enabled,true},
     {module,eventing}]},
   {32783,
    [{name,<<"Get Settings">>},
     {description,<<"Get settings for a given app">>},
     {enabled,false},
     {module,eventing}]},
   {32784,
    [{name,<<"Import Functions">>},
     {description,<<"Import a list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32785,
    [{name,<<"Export Functions">>},
     {description,<<"Export the list of functions">>},
     {enabled,false},
     {module,eventing}]},
   {32786,
    [{name,<<"List Running">>},
     {description,<<"Eventing running function list was read">>},
     {enabled,false},
     {module,eventing}]},
   {36865,
    [{name,<<"Service configuration change">>},
     {description,<<"A successful service configuration change was made.">>},
     {enabled,true},
     {module,analytics}]},
   {36866,
    [{name,<<"Node configuration change">>},
     {description,<<"A successful node configuration change was made.">>},
     {enabled,true},
     {module,analytics}]}]},
 {auto_failover_cfg,
  [{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
   {enabled,true},
   {timeout,120},
   {count,0},
   {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
   {failover_server_group,false},
   {max_count,1},
   {failed_over_server_groups,[]}]}]
[error_logger:info,2019-03-19T16:11:21.991Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.157.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:21.993Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.163.0>},
                       {name,ns_config_remote},
                       {mfargs,{ns_config_replica,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:21.995Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.164.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:21.995Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:21.998Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.166.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:22.000Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.167.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:22.015Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.170.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:22.019Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2019-03-19T16:11:22.020Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.171.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:22.020Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.172.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:22.024Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.173.0>},
                       {name,memcached_refresh},
                       {mfargs,{memcached_refresh,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:22.026Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.175.0>},
                       {name,ssl_service_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ssl_service_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:22.056Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.176.0>:ns_ssl_services_setup:init:416]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2019-03-19T16:11:22.137Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.176.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:22.151Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2019-03-19T16:11:22.151Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2019-03-19T16:11:22.151Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2019-03-19T16:11:22.152Z,ns_1@127.0.0.1:<0.178.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[ns_server:debug,2019-03-19T16:11:22.183Z,ns_1@127.0.0.1:<0.178.0>:restartable:start_child:98]Started child process <0.179.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2019-03-19T16:11:22.183Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.178.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:22.183Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.174.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:22.184Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.197.0>},
                       {name,user_storage_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,user_storage_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:22.194Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.199.0>},
                       {name,users_replicator},
                       {mfargs,{menelaus_users,start_replicator,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:22.196Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:55]Start waiting for startup
[ns_server:debug,2019-03-19T16:11:22.199Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_storage:anounce_startup:69]Announce my startup to <0.199.0>
[ns_server:debug,2019-03-19T16:11:22.199Z,ns_1@127.0.0.1:users_replicator<0.199.0>:replicated_storage:wait_for_startup:58]Received replicated storage registration from <0.200.0>
[ns_server:debug,2019-03-19T16:11:22.202Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:open:212]Opening file "/opt/couchbase/var/lib/couchbase/config/users.dets"
[error_logger:info,2019-03-19T16:11:22.202Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_storage_sup}
             started: [{pid,<0.200.0>},
                       {name,users_storage},
                       {mfargs,{menelaus_users,start_storage,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:22.202Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.198.0>},
                       {name,users_storage_sup},
                       {mfargs,{users_storage_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2019-03-19T16:11:22.214Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:init:44]Starting versioned cache compiled_roles_cache
[error_logger:info,2019-03-19T16:11:22.214Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,users_sup}
             started: [{pid,<0.202.0>},
                       {name,compiled_roles_cache},
                       {mfargs,{menelaus_roles,start_compiled_roles_cache,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:22.214Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.196.0>},
                       {name,users_sup},
                       {mfargs,{users_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:22.221Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.206.0>},
                       {name,dets_sup},
                       {mfargs,{dets_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:22.221Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.207.0>},
                       {name,dets},
                       {mfargs,{dets_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:22.256Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:convert_docs_to_55_in_dets:243]Checking for pre 5.5 records in dets: users_storage
[ns_server:debug,2019-03-19T16:11:22.257Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,'$1','_','$2'},
                                      [],
                                      [{{'$1','$2'}}]}],
                                    100}
[ns_server:debug,2019-03-19T16:11:22.257Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:init_after_ack:204]Loading 0 items, 299 words took 0ms
[ns_server:debug,2019-03-19T16:11:22.259Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.210.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:141]Waiting for ns_couchdb node to start
[error_logger:info,2019-03-19T16:11:22.259Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.205.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:22.259Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T16:11:22.260Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.213.0>,shutdown}}
[error_logger:info,2019-03-19T16:11:22.260Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T16:11:22.260Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[ns_server:debug,2019-03-19T16:11:22.262Z,ns_1@127.0.0.1:users_replicator<0.199.0>:doc_replicator:loop:60]doing replicate_newnodes_docs
[error_logger:info,2019-03-19T16:11:22.461Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T16:11:22.461Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.216.0>,shutdown}}
[error_logger:info,2019-03-19T16:11:22.461Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T16:11:22.462Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T16:11:22.663Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T16:11:22.663Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.219.0>,shutdown}}
[error_logger:info,2019-03-19T16:11:22.663Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T16:11:22.663Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T16:11:22.864Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T16:11:22.864Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.222.0>,shutdown}}
[error_logger:info,2019-03-19T16:11:22.864Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T16:11:22.864Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T16:11:23.065Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T16:11:23.076Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.225.0>,shutdown}}
[error_logger:info,2019-03-19T16:11:23.076Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T16:11:23.076Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T16:11:23.277Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T16:11:23.278Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.228.0>,shutdown}}
[error_logger:info,2019-03-19T16:11:23.278Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T16:11:23.278Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T16:11:23.479Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T16:11:23.480Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.231.0>,shutdown}}
[error_logger:info,2019-03-19T16:11:23.480Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T16:11:23.480Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T16:11:23.681Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T16:11:23.681Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T16:11:23.681Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.234.0>,shutdown}}
[error_logger:info,2019-03-19T16:11:23.682Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T16:11:23.882Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T16:11:23.883Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T16:11:23.883Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.237.0>,shutdown}}
[error_logger:info,2019-03-19T16:11:23.883Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T16:11:24.084Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2019-03-19T16:11:24.085Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.240.0>,shutdown}}
[error_logger:info,2019-03-19T16:11:24.085Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T16:11:24.085Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2019-03-19T16:11:24.286Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2019-03-19T16:11:24.320Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2019-03-19T16:11:24.524Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2019-03-19T16:11:24.725Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2019-03-19T16:11:24.926Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2019-03-19T16:11:25.127Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[ns_server:debug,2019-03-19T16:11:25.328Z,ns_1@127.0.0.1:<0.211.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:155]ns_couchdb is not ready: false
[error_logger:info,2019-03-19T16:11:25.880Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.251.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:26.080Z,ns_1@127.0.0.1:ns_couchdb_port<0.205.0>:ns_port_server:log:223]ns_couchdb<0.205.0>: Apache CouchDB v4.5.1-109-g3c4ad2b (LogLevel=info) is starting.

[ns_server:info,2019-03-19T16:11:26.342Z,ns_1@127.0.0.1:ns_couchdb_port<0.205.0>:ns_port_server:log:223]ns_couchdb<0.205.0>: Apache CouchDB has started. Time to relax.

[error_logger:info,2019-03-19T16:11:26.416Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.210.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.96617950>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:26.438Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:ns_storage_conf:setup_db_and_ix_paths:47]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2019-03-19T16:11:26.446Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.254.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.447Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.255.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:26.448Z,ns_1@127.0.0.1:ns_server_sup<0.253.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2019-03-19T16:11:26.450Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.256.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.451Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.257.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.470Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.258.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.470Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.259.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:26.496Z,ns_1@127.0.0.1:memcached_passwords<0.260.0>:memcached_cfg:init:62]Init config writer for memcached_passwords, "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2019-03-19T16:11:26.496Z,ns_1@127.0.0.1:memcached_passwords<0.260.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2019-03-19T16:11:26.566Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.260.0>
[ns_server:debug,2019-03-19T16:11:26.566Z,ns_1@127.0.0.1:memcached_passwords<0.260.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2019-03-19T16:11:26.566Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.260.0>
[ns_server:debug,2019-03-19T16:11:26.579Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[error_logger:info,2019-03-19T16:11:26.579Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.260.0>},
                       {name,memcached_passwords},
                       {mfargs,{memcached_passwords,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2019-03-19T16:11:26.598Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T16:11:26.598Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [isasl] failed. Retry in 1000 ms.
[ns_server:debug,2019-03-19T16:11:26.598Z,ns_1@127.0.0.1:memcached_permissions<0.263.0>:memcached_cfg:init:62]Init config writer for memcached_permissions, "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2019-03-19T16:11:26.598Z,ns_1@127.0.0.1:memcached_permissions<0.263.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/config/memcached.rbac"
[ns_server:debug,2019-03-19T16:11:26.602Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.263.0>
[ns_server:debug,2019-03-19T16:11:26.602Z,ns_1@127.0.0.1:memcached_permissions<0.263.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{user,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2019-03-19T16:11:26.602Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.263.0>
[ns_server:debug,2019-03-19T16:11:26.608Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of rbac requested
[error_logger:info,2019-03-19T16:11:26.608Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.263.0>},
                       {name,memcached_permissions},
                       {mfargs,{memcached_permissions,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.608Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.266.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2019-03-19T16:11:26.609Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T16:11:26.609Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2019-03-19T16:11:26.611Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.268.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:26.611Z,ns_1@127.0.0.1:ns_node_disco<0.269.0>:ns_node_disco:init:130]Initting ns_node_disco with []
[ns_server:debug,2019-03-19T16:11:26.611Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[user:info,2019-03-19T16:11:26.611Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:127]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>} from cluster
[ns_server:debug,2019-03-19T16:11:26.611Z,ns_1@127.0.0.1:<0.270.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[ns_server:debug,2019-03-19T16:11:26.613Z,ns_1@127.0.0.1:<0.270.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[error_logger:info,2019-03-19T16:11:26.614Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.269.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.616Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.271.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:26.617Z,ns_1@127.0.0.1:ns_couchdb_port<0.205.0>:ns_port_server:log:223]ns_couchdb<0.205.0>: 172: Booted. Waiting for shutdown request

[error_logger:info,2019-03-19T16:11:26.618Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.272.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.620Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.273.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:26.620Z,ns_1@127.0.0.1:ns_config_rep<0.274.0>:ns_config_rep:init:69]init pulling
[ns_server:debug,2019-03-19T16:11:26.620Z,ns_1@127.0.0.1:ns_config_rep<0.274.0>:ns_config_rep:init:71]init pushing
[ns_server:debug,2019-03-19T16:11:26.649Z,ns_1@127.0.0.1:ns_config_rep<0.274.0>:ns_config_rep:init:75]init reannouncing
[ns_server:debug,2019-03-19T16:11:26.650Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:versioned_cache:handle_info:89]Flushing cache compiled_roles_cache due to version change from undefined to {[6,
                                                                              0],
                                                                             {0,
                                                                              243123544},
                                                                             false,
                                                                             []}
[ns_server:debug,2019-03-19T16:11:26.650Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2019-03-19T16:11:26.650Z,ns_1@127.0.0.1:ns_config_events<0.155.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2019-03-19T16:11:26.651Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2019-03-19T16:11:26.651Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {enabled,[]},
 {disabled_users,[]},
 {auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2019-03-19T16:11:26.652Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2019-03-19T16:11:26.652Z,ns_1@127.0.0.1:ns_cookie_manager<0.152.0>:ns_cookie_manager:do_cookie_sync:106]ns_cookie_manager do_cookie_sync
[ns_server:debug,2019-03-19T16:11:26.652Z,ns_1@127.0.0.1:<0.282.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[ns_server:debug,2019-03-19T16:11:26.652Z,ns_1@127.0.0.1:<0.283.0>:ns_node_disco:do_nodes_wanted_updated_fun:216]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[ns_server:debug,2019-03-19T16:11:26.652Z,ns_1@127.0.0.1:<0.282.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[ns_server:debug,2019-03-19T16:11:26.652Z,ns_1@127.0.0.1:<0.283.0>:ns_node_disco:do_nodes_wanted_updated_fun:222]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}
[ns_server:debug,2019-03-19T16:11:26.654Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
audit_decriptors ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {20480,
  [{name,<<"opened DCP connection">>},
   {description,<<"opened DCP connection">>},
   {enabled,true},
   {module,memcached}]},
 {20482,
  [{name,<<"external memcached bucket flush">>},
   {description,<<"External user flushed the content of a memcached bucket">>},
   {enabled,true},
   {module,memcached}]},
 {20483,
  [{name,<<"invalid packet">>},
   {description,<<"Rejected an invalid packet">>},
   {enabled,true},
   {module,memcached}]},
 {20485,
  [{name,<<"authentication succeeded">>},
   {description,<<"Authentication to the cluster succeeded">>},
   {enabled,false},
   {module,memcached}]},
 {20488,
  [{name,<<"document read">>},
   {description,<<"Document was read">>},
   {enabled,false},
   {module,memcached}]},
 {20489,
  [{name,<<"document locked">>},
   {description,<<"Document was locked">>},
   {enabled,false},
   {module,memcached}]},
 {20490,
  [{name,<<"document modify">>},
   {description,<<"Document was modified">>},
   {enabled,false},
   {module,memcached}]},
 {20491,
  [{name,<<"document delete">>},
   {description,<<"Document was deleted">>},
   {enabled,false},
   {module,memcached}]},
 {20492,
  [{name,<<"select bucket">>},
   {description,<<"The specified bucket was selected">>},
   {enabled,true},
   {module,memcached}]},
 {28672,
  [{name,<<"SELECT statement">>},
   {description,<<"A N1QL SELECT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28673,
  [{name,<<"EXPLAIN statement">>},
   {description,<<"A N1QL EXPLAIN statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28674,
  [{name,<<"PREPARE statement">>},
   {description,<<"A N1QL PREPARE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28675,
  [{name,<<"INFER statement">>},
   {description,<<"A N1QL INFER statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28676,
  [{name,<<"INSERT statement">>},
   {description,<<"A N1QL INSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28677,
  [{name,<<"UPSERT statement">>},
   {description,<<"A N1QL UPSERT statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28678,
  [{name,<<"DELETE statement">>},
   {description,<<"A N1QL DELETE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28679,
  [{name,<<"UPDATE statement">>},
   {description,<<"A N1QL UPDATE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28680,
  [{name,<<"MERGE statement">>},
   {description,<<"A N1QL MERGE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28681,
  [{name,<<"CREATE INDEX statement">>},
   {description,<<"A N1QL CREATE INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28682,
  [{name,<<"DROP INDEX statement">>},
   {description,<<"A N1QL DROP INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28683,
  [{name,<<"ALTER INDEX statement">>},
   {description,<<"A N1QL ALTER INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28684,
  [{name,<<"BUILD INDEX statement">>},
   {description,<<"A N1QL BUILD INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28685,
  [{name,<<"GRANT ROLE statement">>},
   {description,<<"A N1QL GRANT ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28686,
  [{name,<<"REVOKE ROLE statement">>},
   {description,<<"A N1QL REVOKE ROLE statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28687,
  [{name,<<"UNRECOGNIZED statement">>},
   {description,<<"An unrecognized statement was received by the N1QL query engine">>},
   {enabled,false},
   {module,n1ql}]},
 {28688,
  [{name,<<"CREATE PRIMARY INDEX statement">>},
   {description,<<"A N1QL CREATE PRIMARY INDEX statement was executed">>},
   {enabled,false},
   {module,n1ql}]},
 {28689,
  [{name,<<"/admin/stats API request">>},
   {description,<<"An HTTP request was made to the API at /admin/stats.">>},
   {enabled,false},
   {module,n1ql}]},
 {28690,
  [{name,<<"/admin/vitals API request">>},
   {description,<<"An HTTP request was made to the API at /admin/vitals.">>},
   {enabled,false},
   {module,n1ql}]},
 {28691,
  [{name,<<"/admin/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28692,
  [{name,<<"/admin/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28693,
  [{name,<<"/admin/indexes/prepareds API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/prepareds.">>},
   {enabled,false},
   {module,n1ql}]},
 {28694,
  [{name,<<"/admin/indexes/active_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/active_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28695,
  [{name,<<"/admin/indexes/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/indexes/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {28697,
  [{name,<<"/admin/ping API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ping.">>},
   {enabled,false},
   {module,n1ql}]},
 {28698,
  [{name,<<"/admin/config API request">>},
   {description,<<"An HTTP request was made to the API at /admin/config.">>},
   {enabled,false},
   {module,n1ql}]},
 {28699,
  [{name,<<"/admin/ssl_cert API request">>},
   {description,<<"An HTTP request was made to the API at /admin/ssl_cert.">>},
   {enabled,false},
   {module,n1ql}]},
 {28700,
  [{name,<<"/admin/settings API request">>},
   {description,<<"An HTTP request was made to the API at /admin/settings.">>},
   {enabled,false},
   {module,n1ql}]},
 {28701,
  [{name,<<"/admin/clusters API request">>},
   {description,<<"An HTTP request was made to the API at /admin/clusters.">>},
   {enabled,false},
   {module,n1ql}]},
 {28702,
  [{name,<<"/admin/completed_requests API request">>},
   {description,<<"An HTTP request was made to the API at /admin/completed_requests.">>},
   {enabled,false},
   {module,n1ql}]},
 {32768,
  [{name,<<"Create Function">>},
   {description,<<"Eventing function definition was created or updated">>},
   {enabled,true},
   {module,eventing}]},
 {32769,
  [{name,<<"Delete Function">>},
   {description,<<"Eventing function definition was deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32770,
  [{name,<<"Fetch Functions">>},
   {description,<<"Eventing function definition was read">>},
   {enabled,false},
   {module,eventing}]},
 {32771,
  [{name,<<"List Deployed">>},
   {description,<<"Eventing deployed functions list was read">>},
   {enabled,false},
   {module,eventing}]},
 {32772,
  [{name,<<"Fetch Drafts">>},
   {description,<<"Eventing function draft definitions were read">>},
   {enabled,false},
   {module,eventing}]},
 {32773,
  [{name,<<"Delete Drafts">>},
   {description,<<"Eventing function draft definitions were deleted">>},
   {enabled,true},
   {module,eventing}]},
 {32774,
  [{name,<<"Save Draft">>},
   {description,<<"Save a draft definition to the store">>},
   {enabled,true},
   {module,eventing}]},
 {32775,
  [{name,<<"Start Debug">>},
   {description,<<"Start eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32776,
  [{name,<<"Stop Debug">>},
   {description,<<"Stop eventing function debugger">>},
   {enabled,true},
   {module,eventing}]},
 {32777,
  [{name,<<"Start Tracing">>},
   {description,<<"Start tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32778,
  [{name,<<"Stop Tracing">>},
   {description,<<"Stop tracing eventing function execution">>},
   {enabled,true},
   {module,eventing}]},
 {32779,
  [{name,<<"Set Settings">>},
   {description,<<"Save settings for a given app">>},
   {enabled,true},
   {module,eventing}]},
 {32780,
  [{name,<<"Fetch Config">>},
   {description,<<"Get config for eventing">>},
   {enabled,false},
   {module,eventing}]},
 {32781,
  [{name,<<"Save Config">>},
   {description,<<"Save config for eventing">>},
   {enabled,true},
   {module,eventing}]},
 {32782,
  [{name,<<"Cleanup Eventing">>},
   {description,<<"Clears up app definitions and settings from metakv">>},
   {enabled,true},
   {module,eventing}]},
 {32783,
  [{name,<<"Get Settings">>},
   {description,<<"Get settings for a given app">>},
   {enabled,false},
   {module,eventing}]},
 {32784,
  [{name,<<"Import Functions">>},
   {description,<<"Import a list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32785,
  [{name,<<"Export Functions">>},
   {description,<<"Export the list of functions">>},
   {enabled,false},
   {module,eventing}]},
 {32786,
  [{name,<<"List Running">>},
   {description,<<"Eventing running function list was read">>},
   {enabled,false},
   {module,eventing}]},
 {36865,
  [{name,<<"Service configuration change">>},
   {description,<<"A successful service configuration change was made.">>},
   {enabled,true},
   {module,analytics}]},
 {36866,
  [{name,<<"Node configuration change">>},
   {description,<<"A successful node configuration change was made.">>},
   {enabled,true},
   {module,analytics}]}]
[ns_server:debug,2019-03-19T16:11:26.654Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[ns_server:debug,2019-03-19T16:11:26.654Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_reprovision_cfg ->
[{enabled,true},{max_nodes,1},{count,0}]
[ns_server:debug,2019-03-19T16:11:26.654Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2019-03-19T16:11:26.654Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
buckets ->
[[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{3,63720229833}}],{configs,[]}]
[ns_server:debug,2019-03-19T16:11:26.654Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cbas_memory_quota ->
1024
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cert_and_pkey ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229828}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFY1m8D7hCswwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA5YTE4NDJjYjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgOWExODQy\nY2IwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC+eKF5LWqGKFW4gli1\nVvKni+IUYrmY6/qUKhTwQlSYprAg7gSvzaseLfccoVJZbUu6D8O9+wn5/fM1CuJZ\njgCNaWx6D88s/oegh4eAUkqXjnivEkv"...>>,
  <<"*****">>}]
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
client_cert_auth ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {state,"disable"},
 {prefixes,[]}]
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
cluster_compat_version ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{8,63720229833}}]},6,0]
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded,communication_issue]}]
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
fts_memory_quota ->
256
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
log_redaction_default_cfg ->
[{redact_level,none}]
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
max_bucket_count ->
10
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memcached ->
[]
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
memory_quota ->
304
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
otp ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {cookie,{sanitized,<<"BRMf+Ng5e7JBsA9Sn6MvDLomBJ5wdGopAzag88p1COc=">>}}]
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
password_policy ->
[{min_length,6},{must_present,[]}]
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
quorum_nodes ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
read_only_user_creds ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 '_deleted']
[ns_server:debug,2019-03-19T16:11:26.655Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
remote_clusters ->
[]
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest ->
[{port,8091}]
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
rest_creds ->
null
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
roles_definitions ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 '_deleted']
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
scramsha_fallback_salt ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 <<153,243,183,226,93,180,216,77,176,217,18,64>>]
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
secure_headers ->
[]
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:memcached_passwords<0.260.0>:memcached_cfg:write_cfg:118]Writing config file for: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
users_upgrade ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 '_deleted']
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"9bca6fc94f10ac3edc5b102bbb4437b5">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{4,63720229833}}]}]
[ns_server:debug,2019-03-19T16:11:26.656Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/eventing/settings/config">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 <<"{\"ram_quota\":256}">>]
[ns_server:debug,2019-03-19T16:11:26.657Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2019-03-19T16:11:26.657Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{metakv,<<"/query/settings/config">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 <<"{\"query.settings.curl_whitelist\":{\"all_access\":false,\"allowed_urls\":[],\"disallowed_urls\":[]},\"query.settings.tmp_space_dir\":\"/opt/couchbase/var/lib/couchbase/tmp\",\"query.settings.tmp_space_size\":5120}">>]
[ns_server:debug,2019-03-19T16:11:26.657Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{rbac_upgrade,[5,5]} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}|
 '_deleted']
[ns_server:debug,2019-03-19T16:11:26.657Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2019-03-19T16:11:26.657Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2019-03-19T16:11:26.657Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,fts} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}]
[ns_server:debug,2019-03-19T16:11:26.657Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,index} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}]
[ns_server:debug,2019-03-19T16:11:26.657Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]}]
[ns_server:debug,2019-03-19T16:11:26.657Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}]
[ns_server:debug,2019-03-19T16:11:26.657Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|8092]
[ns_server:debug,2019-03-19T16:11:26.657Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_admin_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9110]
[ns_server:debug,2019-03-19T16:11:26.657Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_client_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9113]
[ns_server:debug,2019-03-19T16:11:26.658Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_cluster_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9112]
[ns_server:debug,2019-03-19T16:11:26.658Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cc_http_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9111]
[ns_server:debug,2019-03-19T16:11:26.658Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_cluster_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9115]
[ns_server:debug,2019-03-19T16:11:26.658Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_console_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9114]
[ns_server:debug,2019-03-19T16:11:26.658Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_data_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9116]
[ns_server:debug,2019-03-19T16:11:26.658Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_debug_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|-1]
[ns_server:debug,2019-03-19T16:11:26.658Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_http_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|8095]
[ns_server:debug,2019-03-19T16:11:26.658Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_messaging_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9118]
[ns_server:debug,2019-03-19T16:11:26.658Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_callback_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9119]
[ns_server:debug,2019-03-19T16:11:26.659Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_metadata_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9121]
[ns_server:debug,2019-03-19T16:11:26.659Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_parent_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9122]
[ns_server:debug,2019-03-19T16:11:26.659Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_replication_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9120]
[ns_server:debug,2019-03-19T16:11:26.659Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_result_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9117]
[ns_server:debug,2019-03-19T16:11:26.659Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',cbas_ssl_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|18095]
[ns_server:debug,2019-03-19T16:11:26.659Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2019-03-19T16:11:26.659Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
 {5,5,3}]
[ns_server:debug,2019-03-19T16:11:26.659Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_debug_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9140]
[ns_server:debug,2019-03-19T16:11:26.659Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_http_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|8096]
[ns_server:debug,2019-03-19T16:11:26.659Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',eventing_https_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|18096]
[ns_server:debug,2019-03-19T16:11:26.660Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|8094]
[ns_server:debug,2019-03-19T16:11:26.660Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',fts_ssl_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|18094]
[ns_server:debug,2019-03-19T16:11:26.660Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9100]
[ns_server:debug,2019-03-19T16:11:26.660Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9102]
[ns_server:debug,2019-03-19T16:11:26.660Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_https_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|19102]
[ns_server:debug,2019-03-19T16:11:26.660Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9101]
[ns_server:debug,2019-03-19T16:11:26.660Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9104]
[ns_server:debug,2019-03-19T16:11:26.660Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9103]
[ns_server:debug,2019-03-19T16:11:26.660Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9105]
[ns_server:debug,2019-03-19T16:11:26.660Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|true]
[ns_server:debug,2019-03-19T16:11:26.660Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2019-03-19T16:11:26.660Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|true]
[ns_server:debug,2019-03-19T16:11:26.661Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
 active]
[ns_server:debug,2019-03-19T16:11:26.661Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"@ns_server"},
 {other_users,["@cbq-engine","@projector","@goxdcr","@index","@fts",
               "@eventing","@cbas"]},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {rbac_file,"/opt/couchbase/var/lib/couchbase/config/memcached.rbac"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2019-03-19T16:11:26.661Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},
        {port,port},
        {maxconn,maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}},
        {ipv4,<<"required">>},
        {ipv6,<<"optional">>}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {client_cert_auth,{memcached_config_mgr,client_cert_auth,[]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {privilege_debug,privilege_debug},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {rbac_file,{"~s",[rbac_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps},
   {tracing_enabled,tracing_enabled},
   {datatype_snappy,{memcached_config_mgr,is_snappy_enabled,[]}},
   {xattr_enabled,{memcached_config_mgr,is_enabled,[[5,0]]}},
   {scramsha_fallback_salt,{memcached_config_mgr,get_fallback_salt,[]}},
   {logger,
    {[{filename,{"~s/~s",[log_path,log_prefix]}},
      {cyclesize,log_cyclesize},
      {sleeptime,log_sleeptime}]}}]}]
[ns_server:debug,2019-03-19T16:11:26.662Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {privilege_debug,false},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false},
 {tracing_enabled,true},
 {datatype_snappy,true}]
[ns_server:debug,2019-03-19T16:11:26.662Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2019-03-19T16:11:26.662Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2019-03-19T16:11:26.662Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}]
[ns_server:debug,2019-03-19T16:11:26.662Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9999]
[ns_server:debug,2019-03-19T16:11:26.662Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|8093]
[ns_server:debug,2019-03-19T16:11:26.662Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2019-03-19T16:11:26.662Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|18092]
[ns_server:debug,2019-03-19T16:11:26.662Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|18093]
[ns_server:debug,2019-03-19T16:11:26.662Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|18091]
[ns_server:debug,2019-03-19T16:11:26.662Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|
 <<"9bca6fc94f10ac3edc5b102bbb4437b5">>]
[ns_server:debug,2019-03-19T16:11:26.663Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|9998]
[ns_server:debug,2019-03-19T16:11:26.663Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{node,'ns_1@127.0.0.1',{project_intact,is_vulnerable}} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229827}}]}|false]
[error_logger:info,2019-03-19T16:11:26.736Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.274.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:26.737Z,ns_1@127.0.0.1:ns_config_rep<0.274.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([alert_limits,audit,audit_decriptors,
                               auto_failover_cfg,auto_reprovision_cfg,
                               autocompaction,buckets,cbas_memory_quota,
                               cert_and_pkey,client_cert_auth,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,
                               index_aware_rebalance_disabled,
                               log_redaction_default_cfg,max_bucket_count,
                               memcached,memory_quota,nodes_wanted,otp,
                               password_policy,quorum_nodes,
                               read_only_user_creds,remote_clusters,
                               replication,rest,rest_creds,roles_definitions,
                               scramsha_fallback_salt,secure_headers,
                               server_groups,set_view_update_daemon,
                               users_upgrade,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"9bca6fc94f10ac3edc5b102bbb4437b5">>},
                               {metakv,<<"/eventing/settings/config">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {metakv,<<"/query/settings/config">>},
                               {rbac_upgrade,[5,5]},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',cbas_admin_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_client_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_cc_http_port},
                               {node,'ns_1@127.0.0.1',cbas_cluster_port},
                               {node,'ns_1@127.0.0.1',cbas_console_port},
                               {node,'ns_1@127.0.0.1',cbas_data_port},
                               {node,'ns_1@127.0.0.1',cbas_debug_port},
                               {node,'ns_1@127.0.0.1',cbas_http_port},
                               {node,'ns_1@127.0.0.1',cbas_messaging_port},
                               {node,'ns_1@127.0.0.1',
                                   cbas_metadata_callback_port},
                               {node,'ns_1@127.0.0.1',cbas_metadata_port},
                               {node,'ns_1@127.0.0.1',cbas_parent_port},
                               {node,'ns_1@127.0.0.1',cbas_replication_port},
                               {node,'ns_1@127.0.0.1',cbas_result_port},
                               {node,'ns_1@127.0.0.1',cbas_ssl_port}]..)
[error_logger:info,2019-03-19T16:11:26.738Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.267.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:26.741Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.290.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:26.746Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:354]Suspended by process <0.260.0>
[ns_server:debug,2019-03-19T16:11:26.746Z,ns_1@127.0.0.1:memcached_passwords<0.260.0>:replicated_dets:select_from_dets_locked:399]Starting select with {users_storage,[{{docv2,{auth,'_'},'_','_'},[],['$_']}],
                                    100}
[ns_server:debug,2019-03-19T16:11:26.746Z,ns_1@127.0.0.1:users_storage<0.200.0>:replicated_dets:handle_call:361]Released by process <0.260.0>
[ns_server:debug,2019-03-19T16:11:26.761Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_cast:55]Refresh of isasl requested
[ns_server:warn,2019-03-19T16:11:26.766Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T16:11:26.766Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[error_logger:info,2019-03-19T16:11:26.766Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.292.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.767Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.295.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.767Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.296.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:26.773Z,ns_1@127.0.0.1:ns_log_events<0.266.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2019-03-19T16:11:26.773Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.298.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.773Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.297.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:26.773Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.299.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.776Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.300.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.789Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.302.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.790Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.306.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.790Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.301.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:26.797Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.311.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:26.799Z,ns_1@127.0.0.1:ns_heart<0.302.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2019-03-19T16:11:26.800Z,ns_1@127.0.0.1:ns_heart<0.302.0>:ns_heart:grab_latest_stats:263]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,116}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,259}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,282}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,250}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,187}]}]}}

[error_logger:info,2019-03-19T16:11:26.816Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.313.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:26.816Z,ns_1@127.0.0.1:<0.309.0>:restartable:start_child:98]Started child process <0.310.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2019-03-19T16:11:26.817Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.309.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:26.817Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.316.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.822Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.317.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.822Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.318.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.822Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.319.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.823Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.320.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.837Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.322.0>},
                       {name,query_settings_manager},
                       {mfargs,{query_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.841Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.324.0>},
                       {name,eventing_settings_manager},
                       {mfargs,{eventing_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.841Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.326.0>},
                       {name,audit_events},
                       {mfargs,{gen_event,start_link,[{local,audit_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.867Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.329.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.867Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.331.0>},
                       {name,scram_sha},
                       {mfargs,{scram_sha,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:26.870Z,ns_1@127.0.0.1:ns_heart<0.302.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2019-03-19T16:11:26.871Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.332.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:26.874Z,ns_1@127.0.0.1:ns_heart<0.302.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:45]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2019-03-19T16:11:26.878Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.334.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.888Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.335.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.888Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.336.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:26.890Z,ns_1@127.0.0.1:menelaus_sup<0.327.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for cbas

[ns_server:info,2019-03-19T16:11:26.891Z,ns_1@127.0.0.1:menelaus_sup<0.327.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for eventing

[ns_server:info,2019-03-19T16:11:26.891Z,ns_1@127.0.0.1:menelaus_sup<0.327.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for fts

[ns_server:info,2019-03-19T16:11:26.891Z,ns_1@127.0.0.1:menelaus_sup<0.327.0>:menelaus_pluggable_ui:validate_plugin_spec:135]Loaded pluggable UI specification for n1ql

[error_logger:info,2019-03-19T16:11:26.891Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.337.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.898Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.356.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.910Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.357.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.920Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.358.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.938Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.359.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2019-03-19T16:11:26.939Z,ns_1@127.0.0.1:ns_server_sup<0.253.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "6.0.1-2037-enterprise".
[error_logger:info,2019-03-19T16:11:26.939Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.327.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:26.939Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.365.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.943Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.369.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:26.943Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.370.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.31986353>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:26.944Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.368.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2019-03-19T16:11:26.968Z,ns_1@127.0.0.1:ns_ports_setup<0.365.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr]
[error_logger:info,2019-03-19T16:11:26.974Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.372.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:26.974Z,ns_1@127.0.0.1:ns_audit_cfg<0.373.0>:ns_audit_cfg:write_audit_json:265]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{descriptors_path,
                                                                                <<"/opt/couchbase/etc/security">>},
                                                                               {version,
                                                                                2},
                                                                               {uuid,
                                                                                <<"18411111">>},
                                                                               {event_states,
                                                                                {[]}},
                                                                               {filtering_enabled,
                                                                                true},
                                                                               {disabled_userids,
                                                                                []},
                                                                               {auditd_enabled,
                                                                                false},
                                                                               {log_path,
                                                                                <<"/opt/couchbase/var/lib/couchbase/logs">>},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []}]
[ns_server:debug,2019-03-19T16:11:26.998Z,ns_1@127.0.0.1:ns_audit_cfg<0.373.0>:ns_audit_cfg:notify_memcached:170]Instruct memcached to reload audit config
[error_logger:info,2019-03-19T16:11:26.998Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.373.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2019-03-19T16:11:26.999Z,ns_1@127.0.0.1:<0.376.0>:ns_memcached:connect:1230]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2019-03-19T16:11:27.003Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.377.0>},
                       {name,ns_audit},
                       {mfargs,{ns_audit,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:27.005Z,ns_1@127.0.0.1:memcached_config_mgr<0.378.0>:memcached_config_mgr:init:46]waiting for completion of initial ns_ports_setup round
[error_logger:info,2019-03-19T16:11:27.005Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:27.026Z,ns_1@127.0.0.1:<0.379.0>:ns_memcached_log_rotator:init:42]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2019-03-19T16:11:27.027Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.379.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.031Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.380.0>},
                       {name,testconditions_store},
                       {mfargs,{simple_store,start_link,[testconditions]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.033Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.382.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.035Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.384.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.035Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.383.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:27.035Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.381.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:27.057Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.385.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.059Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.389.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.064Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.391.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.076Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.392.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.077Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.394.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.077Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.395.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.078Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.397.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.101Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.398.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.101Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.400.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.102Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.402.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.116Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.403.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.130Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.405.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:27.130Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.405.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2019-03-19T16:11:27.131Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.405.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2019-03-19T16:11:27.135Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.409.0>},
                       {name,service_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_stats_children_sup},
                                services_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:27.138Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.411.0>},
                       {name,service_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [service_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.156Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.412.0>},
                       {name,service_status_keeper_index},
                       {mfargs,{service_index,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.160Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.415.0>},
                       {name,service_status_keeper_fts},
                       {mfargs,{service_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.174Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_status_keeper_sup}
             started: [{pid,<0.418.0>},
                       {name,service_status_keeper_eventing},
                       {mfargs,{service_eventing,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.174Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.410.0>},
                       {name,service_status_keeper_sup},
                       {mfargs,{service_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:27.174Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,services_stats_sup}
             started: [{pid,<0.421.0>},
                       {name,service_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<services_stats_sup.0.41280346>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.175Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.408.0>},
                       {name,services_stats_sup},
                       {mfargs,{services_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:27.181Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.423.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:27.192Z,ns_1@127.0.0.1:<0.426.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.426.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2019-03-19T16:11:27.197Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:11:27.197Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:11:27.197Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:11:27.197Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:11:27.197Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:11:27.197Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2019-03-19T16:11:27.197Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.424.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.217Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.428.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.217Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.427.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:27.219Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.429.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:27.240Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.306.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2019-03-19T16:11:27.243Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.446.0>},
                       {name,leader_activities},
                       {mfargs,{leader_activities,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:27.246Z,ns_1@127.0.0.1:ns_ports_setup<0.365.0>:ns_ports_setup:set_children:90]Monitor ns_child_ports_sup <12400.74.0>
[ns_server:debug,2019-03-19T16:11:27.246Z,ns_1@127.0.0.1:memcached_config_mgr<0.378.0>:memcached_config_mgr:init:48]ns_ports_setup seems to be ready
[ns_server:debug,2019-03-19T16:11:27.262Z,ns_1@127.0.0.1:memcached_config_mgr<0.378.0>:memcached_config_mgr:find_port_pid_loop:124]Found memcached port <12400.80.0>
[ns_server:warn,2019-03-19T16:11:27.278Z,ns_1@127.0.0.1:leader_lease_agent<0.450.0>:leader_lease_agent:maybe_recover_persisted_lease:397]Found persisted lease [{node,'ns_1@127.0.0.1'},
                       {uuid,<<"bcc4ea163e3b9013bc2d5d4fb73a72db">>},
                       {time_left,15000},
                       {status,active}]
[error_logger:info,2019-03-19T16:11:27.278Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_leases_sup}
             started: [{pid,<0.450.0>},
                       {name,leader_lease_agent},
                       {mfargs,{leader_lease_agent,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.278Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.432.0>},
                       {name,leader_leases_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_leases_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:27.278Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.454.0>},
                       {name,leader_events},
                       {mfargs,{gen_event,start_link,[{local,leader_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.296Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.455.0>},
                       {name,leader_registry_server},
                       {mfargs,{leader_registry_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:27.302Z,ns_1@127.0.0.1:leader_registry_sup<0.453.0>:mb_master:check_master_takeover_needed:133]Sending master node question to the following nodes: []
[ns_server:debug,2019-03-19T16:11:27.302Z,ns_1@127.0.0.1:leader_registry_sup<0.453.0>:mb_master:check_master_takeover_needed:135]Got replies: []
[ns_server:debug,2019-03-19T16:11:27.302Z,ns_1@127.0.0.1:leader_registry_sup<0.453.0>:mb_master:check_master_takeover_needed:141]Was unable to discover master, not going to force mastership takeover
[user:info,2019-03-19T16:11:27.302Z,ns_1@127.0.0.1:mb_master<0.458.0>:mb_master:init:86]I'm the only node, so I'm the master.
[ns_server:debug,2019-03-19T16:11:27.303Z,ns_1@127.0.0.1:leader_registry<0.455.0>:leader_registry_server:handle_new_leader:241]New leader is 'ns_1@127.0.0.1'. Invalidating name cache.
[ns_server:debug,2019-03-19T16:11:27.304Z,ns_1@127.0.0.1:memcached_config_mgr<0.378.0>:memcached_config_mgr:init:79]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2019-03-19T16:11:27.326Z,ns_1@127.0.0.1:memcached_config_mgr<0.378.0>:memcached_config_mgr:init:82]activated memcached port server
[ns_server:info,2019-03-19T16:11:27.327Z,ns_1@127.0.0.1:ns_couchdb_port<0.205.0>:ns_port_server:log:223]ns_couchdb<0.205.0>: working as port

[error_logger:info,2019-03-19T16:11:27.341Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.461.0>},
                       {name,leader_lease_acquirer},
                       {mfargs,{leader_lease_acquirer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:27.346Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.465.0>:leader_quorum_nodes_manager:pull_config:114]Attempting to pull config from nodes:
[]
[error_logger:info,2019-03-19T16:11:27.346Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.465.0>},
                       {name,leader_quorum_nodes_manager},
                       {mfargs,{leader_quorum_nodes_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:27.347Z,ns_1@127.0.0.1:leader_quorum_nodes_manager<0.465.0>:leader_quorum_nodes_manager:pull_config:119]Pulled config successfully.
[ns_server:warn,2019-03-19T16:11:27.376Z,ns_1@127.0.0.1:<0.464.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"bcc4ea163e3b9013bc2d5d4fb73a72db">>} (valid for 14901ms)
[ns_server:info,2019-03-19T16:11:27.382Z,ns_1@127.0.0.1:mb_master_sup<0.460.0>:misc:start_singleton:756]start_singleton(gen_server, ns_tick, [], []): started as <0.473.0> on 'ns_1@127.0.0.1'

[error_logger:info,2019-03-19T16:11:27.382Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.473.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.396Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.476.0>},
                       {name,ns_janitor_server},
                       {mfargs,{ns_janitor_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:27.417Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.475.0>:misc:start_singleton:756]start_singleton(gen_server, auto_reprovision, [], []): started as <0.477.0> on 'ns_1@127.0.0.1'

[error_logger:info,2019-03-19T16:11:27.418Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.477.0>},
                       {name,auto_reprovision},
                       {mfargs,{auto_reprovision,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2019-03-19T16:11:27.418Z,ns_1@127.0.0.1:ns_orchestrator_child_sup<0.475.0>:misc:start_singleton:756]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.478.0> on 'ns_1@127.0.0.1'

[error_logger:info,2019-03-19T16:11:27.418Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_child_sup}
             started: [{pid,<0.478.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.418Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.475.0>},
                       {name,ns_orchestrator_child_sup},
                       {mfargs,{ns_orchestrator_child_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2019-03-19T16:11:27.427Z,ns_1@127.0.0.1:<0.480.0>:auto_failover:init:211]init auto_failover.
[user:info,2019-03-19T16:11:27.428Z,ns_1@127.0.0.1:<0.480.0>:auto_failover:handle_call:242]Enabled auto-failover with timeout 120 and max count 1
[ns_server:info,2019-03-19T16:11:27.434Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.474.0>:misc:start_singleton:756]start_singleton(gen_server, auto_failover, [], []): started as <0.480.0> on 'ns_1@127.0.0.1'

[error_logger:info,2019-03-19T16:11:27.434Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.480.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2019-03-19T16:11:27.434Z,ns_1@127.0.0.1:ns_config_rep<0.274.0>:ns_config_rep:do_push_keys:330]Replicating some config keys ([auto_failover_cfg,
                               {local_changes_count,
                                   <<"9bca6fc94f10ac3edc5b102bbb4437b5">>}]..)
[ns_server:debug,2019-03-19T16:11:27.434Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
{local_changes_count,<<"9bca6fc94f10ac3edc5b102bbb4437b5">>} ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{5,63720231087}}]}]
[ns_server:debug,2019-03-19T16:11:27.435Z,ns_1@127.0.0.1:ns_config_log<0.164.0>:ns_config_log:log_common:227]config change:
auto_failover_cfg ->
[{'_vclock',[{<<"9bca6fc94f10ac3edc5b102bbb4437b5">>,{1,63720229833}}]},
 {enabled,true},
 {timeout,120},
 {count,0},
 {failover_on_data_disk_issues,[{enabled,false},{timePeriod,120}]},
 {failover_server_group,false},
 {max_count,1},
 {failed_over_server_groups,[]}]
[error_logger:info,2019-03-19T16:11:27.435Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.474.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:27.435Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_registry_sup}
             started: [{pid,<0.458.0>},
                       {name,mb_master},
                       {mfargs,{mb_master,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:27.435Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,leader_services_sup}
             started: [{pid,<0.453.0>},
                       {name,leader_registry_sup},
                       {mfargs,
                           {leader_services_sup,start_link,
                               [leader_registry_sup]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2019-03-19T16:11:27.435Z,ns_1@127.0.0.1:<0.430.0>:restartable:start_child:98]Started child process <0.431.0>
  MFA: {leader_services_sup,start_link,[]}
[error_logger:info,2019-03-19T16:11:27.435Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.430.0>},
                       {name,leader_services_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{leader_services_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:27.435Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.488.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.438Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.489.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.469Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.490.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.473Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.491.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.497Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.494.0>},
                       {name,ns_server_monitor},
                       {mfargs,{ns_server_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.498Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.496.0>},
                       {name,service_monitor_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_monitor_children_sup},
                                health_monitor_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:27.498Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.497.0>},
                       {name,service_monitor_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<health_monitor_sup.0.81875396>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.501Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.505.0>},
                       {name,node_monitor},
                       {mfargs,{node_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.507Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,health_monitor_sup}
             started: [{pid,<0.513.0>},
                       {name,node_status_analyzer},
                       {mfargs,{node_status_analyzer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2019-03-19T16:11:27.507Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.493.0>},
                       {name,health_monitor_sup},
                       {mfargs,{health_monitor_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2019-03-19T16:11:27.508Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[ns_server:debug,2019-03-19T16:11:27.508Z,ns_1@127.0.0.1:menelaus_barrier<0.171.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.169.0>
[error_logger:info,2019-03-19T16:11:27.508Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.253.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2019-03-19T16:11:27.508Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.169.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2019-03-19T16:11:27.508Z,ns_1@127.0.0.1:<0.168.0>:restartable:start_child:98]Started child process <0.169.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2019-03-19T16:11:27.508Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.168.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2019-03-19T16:11:27.508Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2019-03-19T16:11:27.508Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:130]138: Entered child_loop
[ns_server:warn,2019-03-19T16:11:27.599Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T16:11:27.599Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[ns_server:warn,2019-03-19T16:11:27.611Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T16:11:27.611Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[ns_server:warn,2019-03-19T16:11:27.767Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:ns_memcached:connect:1227]Unable to connect: {error,{badmatch,{error,econnrefused}}}.
[ns_server:debug,2019-03-19T16:11:27.767Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:93]Refresh of [rbac,isasl] failed. Retry in 1000 ms.
[ns_server:debug,2019-03-19T16:11:27.948Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@",admin}
[ns_server:debug,2019-03-19T16:11:27.972Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.516.0>:json_rpc_connection:init:73]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.516.0>
[ns_server:warn,2019-03-19T16:11:28.000Z,ns_1@127.0.0.1:<0.376.0>:ns_memcached:connect:1230]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2019-03-19T16:11:28.061Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.519.0>:json_rpc_connection:init:73]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.519.0>
[ns_server:debug,2019-03-19T16:11:28.061Z,ns_1@127.0.0.1:menelaus_cbauth<0.359.0>:menelaus_cbauth:handle_cast:102]Observed json rpc process {"goxdcr-cbauth",<0.519.0>} started
[ns_server:debug,2019-03-19T16:11:28.078Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {"@goxdcr-cbauth",admin}
[ns_server:debug,2019-03-19T16:11:28.430Z,ns_1@127.0.0.1:<0.480.0>:auto_failover_logic:log_master_activity:170]Transitioned node {'ns_1@127.0.0.1',<<"9bca6fc94f10ac3edc5b102bbb4437b5">>} state new -> up
[ns_server:debug,2019-03-19T16:11:28.609Z,ns_1@127.0.0.1:memcached_refresh<0.173.0>:memcached_refresh:handle_info:89]Refresh of [rbac,isasl] succeeded
[ns_server:debug,2019-03-19T16:11:31.791Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.306.0>:goxdcr_rest:get_from_goxdcr:137]Goxdcr is temporary not available. Return empty list.
[ns_server:warn,2019-03-19T16:11:42.278Z,ns_1@127.0.0.1:<0.464.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"bcc4ea163e3b9013bc2d5d4fb73a72db">>} (valid for 0ms)
[ns_server:warn,2019-03-19T16:11:42.278Z,ns_1@127.0.0.1:<0.464.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"bcc4ea163e3b9013bc2d5d4fb73a72db">>} (valid for 0ms)
[ns_server:warn,2019-03-19T16:11:42.278Z,ns_1@127.0.0.1:<0.464.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"bcc4ea163e3b9013bc2d5d4fb73a72db">>} (valid for 0ms)
[ns_server:warn,2019-03-19T16:11:42.278Z,ns_1@127.0.0.1:<0.464.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"bcc4ea163e3b9013bc2d5d4fb73a72db">>} (valid for 0ms)
[ns_server:warn,2019-03-19T16:11:42.278Z,ns_1@127.0.0.1:<0.464.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"bcc4ea163e3b9013bc2d5d4fb73a72db">>} (valid for 0ms)
[ns_server:warn,2019-03-19T16:11:42.278Z,ns_1@127.0.0.1:<0.464.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"bcc4ea163e3b9013bc2d5d4fb73a72db">>} (valid for 0ms)
[ns_server:warn,2019-03-19T16:11:42.278Z,ns_1@127.0.0.1:<0.464.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"bcc4ea163e3b9013bc2d5d4fb73a72db">>} (valid for 0ms)
[ns_server:warn,2019-03-19T16:11:42.278Z,ns_1@127.0.0.1:<0.464.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"bcc4ea163e3b9013bc2d5d4fb73a72db">>} (valid for 0ms)
[ns_server:warn,2019-03-19T16:11:42.279Z,ns_1@127.0.0.1:<0.464.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"bcc4ea163e3b9013bc2d5d4fb73a72db">>} (valid for 0ms)
[ns_server:debug,2019-03-19T16:11:42.279Z,ns_1@127.0.0.1:leader_lease_agent<0.450.0>:leader_lease_agent:handle_lease_expired:284]Lease held by {lease_holder,<<"bcc4ea163e3b9013bc2d5d4fb73a72db">>,
                            'ns_1@127.0.0.1'} expired. Starting expirer.
[ns_server:warn,2019-03-19T16:11:42.279Z,ns_1@127.0.0.1:<0.464.0>:leader_lease_acquire_worker:handle_lease_already_acquired:232]Failed to acquire lease from 'ns_1@127.0.0.1' because its already taken by {'ns_1@127.0.0.1',
                                                                            <<"bcc4ea163e3b9013bc2d5d4fb73a72db">>} (valid for 0ms)
[ns_server:debug,2019-03-19T16:11:42.282Z,ns_1@127.0.0.1:leader_lease_agent<0.450.0>:leader_lease_agent:do_handle_acquire_lease:147]Granting lease to {lease_holder,<<"6c43fe566a60721f80cdeabb94d09d31">>,
                                'ns_1@127.0.0.1'} for 15000ms
[ns_server:info,2019-03-19T16:11:42.303Z,ns_1@127.0.0.1:<0.464.0>:leader_lease_acquire_worker:handle_fresh_lease_acquired:302]Acquired lease from node 'ns_1@127.0.0.1' (lease uuid: <<"6c43fe566a60721f80cdeabb94d09d31">>)
[ns_server:debug,2019-03-19T16:11:57.198Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:11:57.198Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:11:57.198Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:11:57.198Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:12:01.436Z,ns_1@127.0.0.1:compiled_roles_cache<0.202.0>:menelaus_roles:build_compiled_roles:822]Compile roles for user {[],wrong_token}
[error_logger:info,2019-03-19T16:12:20.260Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
       alarm_handler: {set,{system_memory_high_watermark,[]}}

[ns_server:debug,2019-03-19T16:12:27.199Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:12:27.199Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:12:27.199Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:12:27.199Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:12:57.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:12:57.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:12:57.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:12:57.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:13:27.201Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:13:27.201Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:13:27.201Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:13:27.201Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:13:57.202Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:13:57.202Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:13:57.202Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:13:57.202Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:14:27.203Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:14:27.203Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:14:27.203Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:14:27.203Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:14:57.204Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:14:57.204Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:14:57.204Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:14:57.204Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:15:27.205Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:15:27.205Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:15:27.205Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:15:27.205Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:15:57.206Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:15:57.206Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2019-03-19T16:15:57.206Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1308]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2019-03-19T16:15:57.206Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
